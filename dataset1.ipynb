{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hardik1408/CS771/blob/hardik/emoticon_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkxlTXck4JxY"
      },
      "source": [
        "## loading the files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x3jZxolZMRsN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Load the CSV files\n",
        "train_df = pd.read_csv('/Users/namangupta/Desktop/771/mini-project-1/datasets/train/train_emoticon.csv')\n",
        "validation_df = pd.read_csv('/Users/namangupta/Desktop/771/mini-project-1/datasets/valid/valid_emoticon.csv')\n",
        "\n",
        "# Assuming the CSV files have 'emojis' and 'label' columns\n",
        "train_texts = train_df['input_emoticon'].values\n",
        "train_labels = train_df['label'].values\n",
        "\n",
        "validation_texts = validation_df['input_emoticon'].values\n",
        "validation_labels = validation_df['label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Observing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_train = []\n",
        "for i in train_texts:\n",
        "    total_train += i\n",
        "\n",
        "emoji_freq = dict()\n",
        "for i in total_train:\n",
        "    if i in emoji_freq:\n",
        "        emoji_freq[i] += 1\n",
        "    else:\n",
        "        emoji_freq[i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['😛', '🛐', '😑', '😣', '🙯', '🚼', '🙼']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emoji_0_1 = dict()\n",
        "\n",
        "for i in emoji_freq:\n",
        "    emoji_0_1[i] = (0,0)\n",
        "\n",
        "for i in emoji_freq:\n",
        "    for j in range(len(train_texts)):\n",
        "        if i in train_texts[j]:\n",
        "            if train_labels[j] == 1:\n",
        "                emoji_0_1[i] = (emoji_0_1[i][0], emoji_0_1[i][1]+1)\n",
        "            else:\n",
        "                emoji_0_1[i] = (emoji_0_1[i][0]+1, emoji_0_1[i][1])\n",
        "\n",
        "emoji_0_1\n",
        "\n",
        "mannnyyy = []\n",
        "for i in emoji_0_1:\n",
        "    if emoji_0_1[i] == (3576, 3504):\n",
        "        mannnyyy.append(i)\n",
        "\n",
        "mannnyyy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We find that in every row these 7 emoticons appear!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3576, 3505, 0)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ss0 = 0\n",
        "ss1 = 1\n",
        "snd = 0\n",
        "\n",
        "for i in range(len(train_texts)):\n",
        "    j = train_texts[i]\n",
        "    for em in mannnyyy:\n",
        "        if em in j:\n",
        "            pass\n",
        "        else:\n",
        "            snd += 1\n",
        "            break\n",
        "    else:\n",
        "        if train_labels[i] == 0:\n",
        "            ss0 += 1\n",
        "        else:\n",
        "            ss1 += 1\n",
        "    \n",
        "ss0, ss1, snd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({10}, {10})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l1 = []\n",
        "l0 = []\n",
        "\n",
        "for i in range(len(train_texts)):\n",
        "    s = []\n",
        "    for idx in range(len(train_texts[i])):\n",
        "        j = train_texts[i][idx]\n",
        "        if j in mannnyyy:\n",
        "            s.append((j, idx))\n",
        "\n",
        "    if train_labels[i] == 1:\n",
        "        l1.append(len(s))\n",
        "    else:\n",
        "        l0.append(len(s))\n",
        "\n",
        "set(l1), set(l0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also, these 7 emoticons make up exactly 10/13 of every given string (Be it train or validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_texts_mod = []\n",
        "\n",
        "for i in train_texts:\n",
        "    s = ''\n",
        "    for j in i:\n",
        "        if j not in mannnyyy:\n",
        "            s += j\n",
        "    train_texts_mod.append(s)\n",
        "\n",
        "train_texts_mod = np.array(train_texts_mod, dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_texts_mod = []\n",
        "\n",
        "for i in validation_texts:\n",
        "    s = ''\n",
        "    for j in i:\n",
        "        if j not in mannnyyy:\n",
        "            s += j\n",
        "    validation_texts_mod.append(s)\n",
        "\n",
        "validation_texts_mod = np.array(validation_texts_mod, dtype=object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use 'train_text_mod' and 'validation_text_mod' -> which are just a 3 length string for every element (rather than 13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us9r2ho04M5N"
      },
      "source": [
        "## preprocessing on input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KWUvSmeJjS6Q"
      },
      "outputs": [],
      "source": [
        "#  Tokenize and pad the emoji sequences\n",
        "tokenizer = Tokenizer(char_level=True)  # Tokenizing each emoji as a character\n",
        "tokenizer.fit_on_texts(train_texts)  # Fit only on training data\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts_mod)\n",
        "validation_sequences = tokenizer.texts_to_sequences(validation_texts_mod)\n",
        "\n",
        "# Pad the sequences to the same length\n",
        "max_len = max([len(seq) for seq in train_sequences])  # Maximum sequence length in train data\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "validation_padded = pad_sequences(validation_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Convert labels into numeric format if they are not (if necessary)\n",
        "train_labels = train_labels.astype(int)\n",
        "validation_labels = validation_labels.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbJTSlT44Qhh"
      },
      "source": [
        "## dividing data for the task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nhvob_QQkWzq"
      },
      "outputs": [],
      "source": [
        "x_train_100 = train_padded\n",
        "y_train_100 = train_labels\n",
        "# prompt: take only 80% of the training dataset\n",
        "\n",
        "train_size_80 = int(len(x_train_100) * 0.8)\n",
        "x_train_80 = x_train_100[:train_size_80]\n",
        "y_train_80 = y_train_100[:train_size_80]\n",
        "# prompt: take only 60% of training data\n",
        "\n",
        "# Shuffle the indices of the training data\n",
        "indices = np.arange(len(x_train_100))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calculate the number of samples for 60% of the data\n",
        "train_size_60_random = int(len(x_train_100) * 0.6)\n",
        "\n",
        "# Select the shuffled indices for the 60% split\n",
        "x_train_60 = x_train_100[indices[:train_size_60_random]]\n",
        "y_train_60 = y_train_100[indices[:train_size_60_random]]\n",
        "\n",
        "indices = np.arange(len(x_train_100))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calculate the number of samples for 60% of the data\n",
        "train_size_40_random = int(len(x_train_100) * 0.4)\n",
        "\n",
        "# Select the shuffled indices for the 60% split\n",
        "x_train_40 = x_train_100[indices[:train_size_40_random]]\n",
        "y_train_40 = y_train_100[indices[:train_size_40_random]]\n",
        "\n",
        "indices = np.arange(len(x_train_100))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calculate the number of samples for 60% of the data\n",
        "train_size_20_random = int(len(x_train_100) * 0.2)\n",
        "\n",
        "# Select the shuffled indices for the 60% split\n",
        "x_train_20 = x_train_100[indices[:train_size_20_random]]\n",
        "y_train_20 = y_train_100[indices[:train_size_20_random]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gleGdU3HkvXp"
      },
      "source": [
        "### model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "R36oQLIbkxWD",
        "outputId": "2cd49fca-73b8-4f20-e36b-dd3170442896"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opm-L1rY4cVG"
      },
      "source": [
        "### 100%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq1r6hsyjq8m",
        "outputId": "822860ab-78ab-4e3a-fddd-5f2e34bd7529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5103 - loss: 0.6931 - val_accuracy: 0.7362 - val_loss: 0.6658\n",
            "Epoch 2/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8159 - loss: 0.4296 - val_accuracy: 0.9100 - val_loss: 0.3536\n",
            "Epoch 3/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8810 - loss: 0.2946 - val_accuracy: 0.9202 - val_loss: 0.1957\n",
            "Epoch 4/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8873 - loss: 0.2590 - val_accuracy: 0.9223 - val_loss: 0.1882\n",
            "Epoch 5/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.2268 - val_accuracy: 0.9284 - val_loss: 0.1649\n",
            "Epoch 6/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2155 - val_accuracy: 0.8957 - val_loss: 0.2169\n",
            "Epoch 7/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2038 - val_accuracy: 0.9468 - val_loss: 0.1203\n",
            "Epoch 8/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.1840 - val_accuracy: 0.9611 - val_loss: 0.1059\n",
            "Epoch 9/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.1878 - val_accuracy: 0.9632 - val_loss: 0.0973\n",
            "Epoch 10/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.1683 - val_accuracy: 0.9611 - val_loss: 0.0976\n",
            "Epoch 11/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9336 - loss: 0.1534 - val_accuracy: 0.9693 - val_loss: 0.0953\n",
            "Epoch 12/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9382 - loss: 0.1459 - val_accuracy: 0.9550 - val_loss: 0.0947\n",
            "Epoch 13/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.1364 - val_accuracy: 0.9652 - val_loss: 0.0847\n",
            "Epoch 14/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.1394 - val_accuracy: 0.9571 - val_loss: 0.0889\n",
            "Epoch 15/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.1336 - val_accuracy: 0.9775 - val_loss: 0.0681\n",
            "Epoch 16/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9587 - loss: 0.0979 - val_accuracy: 0.9755 - val_loss: 0.0643\n",
            "Epoch 17/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9580 - loss: 0.1034 - val_accuracy: 0.9693 - val_loss: 0.0796\n",
            "Epoch 18/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.0854 - val_accuracy: 0.9693 - val_loss: 0.0599\n",
            "Epoch 19/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.0862 - val_accuracy: 0.9836 - val_loss: 0.0567\n",
            "Epoch 20/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9687 - loss: 0.0804 - val_accuracy: 0.9755 - val_loss: 0.0526\n",
            "Epoch 21/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9663 - loss: 0.0813 - val_accuracy: 0.9693 - val_loss: 0.0598\n",
            "Epoch 22/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0640 - val_accuracy: 0.9775 - val_loss: 0.0527\n",
            "Epoch 23/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0693 - val_accuracy: 0.9755 - val_loss: 0.0476\n",
            "Epoch 24/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9760 - loss: 0.0676 - val_accuracy: 0.9755 - val_loss: 0.0500\n",
            "Epoch 25/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0718 - val_accuracy: 0.9714 - val_loss: 0.0524\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.9725 - loss: 0.0429\n",
            "Validation Accuracy: 0.9714\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_100, y_train_100, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "accuracy_100perc = accuracy\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,720</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │         \u001b[38;5;34m1,720\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │         \u001b[38;5;34m1,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,224\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,173</span> (86.62 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,173\u001b[0m (86.62 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,369</span> (28.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,369\u001b[0m (28.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,740</span> (57.58 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m14,740\u001b[0m (57.58 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print the model summary for reference\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcvCDYi-4e_W"
      },
      "source": [
        "### 80%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5089 - loss: 0.6932 - val_accuracy: 0.4847 - val_loss: 0.6848\n",
            "Epoch 2/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7840 - loss: 0.5113 - val_accuracy: 0.7853 - val_loss: 0.4950\n",
            "Epoch 3/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8660 - loss: 0.3171 - val_accuracy: 0.8650 - val_loss: 0.3003\n",
            "Epoch 4/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8838 - loss: 0.2808 - val_accuracy: 0.9080 - val_loss: 0.2075\n",
            "Epoch 5/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8869 - loss: 0.2772 - val_accuracy: 0.9100 - val_loss: 0.1679\n",
            "Epoch 6/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.2331 - val_accuracy: 0.9162 - val_loss: 0.1783\n",
            "Epoch 7/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2138 - val_accuracy: 0.9448 - val_loss: 0.1318\n",
            "Epoch 8/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2116 - val_accuracy: 0.9489 - val_loss: 0.1310\n",
            "Epoch 9/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2109 - val_accuracy: 0.9387 - val_loss: 0.1305\n",
            "Epoch 10/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.1774 - val_accuracy: 0.9632 - val_loss: 0.1058\n",
            "Epoch 11/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.1819 - val_accuracy: 0.9530 - val_loss: 0.1171\n",
            "Epoch 12/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9242 - loss: 0.1892 - val_accuracy: 0.9468 - val_loss: 0.1311\n",
            "Epoch 13/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.1867 - val_accuracy: 0.9468 - val_loss: 0.1238\n",
            "Epoch 14/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.1779 - val_accuracy: 0.9489 - val_loss: 0.1132\n",
            "Epoch 15/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9242 - loss: 0.1881 - val_accuracy: 0.9530 - val_loss: 0.1126\n",
            "Epoch 16/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.2034 - val_accuracy: 0.9673 - val_loss: 0.1045\n",
            "Epoch 17/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.1593 - val_accuracy: 0.9530 - val_loss: 0.1222\n",
            "Epoch 18/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9327 - loss: 0.1612 - val_accuracy: 0.9591 - val_loss: 0.0932\n",
            "Epoch 19/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.1555 - val_accuracy: 0.9591 - val_loss: 0.1097\n",
            "Epoch 20/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9333 - loss: 0.1711 - val_accuracy: 0.9632 - val_loss: 0.0958\n",
            "Epoch 21/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9376 - loss: 0.1498 - val_accuracy: 0.9448 - val_loss: 0.1137\n",
            "Epoch 22/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.1633 - val_accuracy: 0.9571 - val_loss: 0.0988\n",
            "Epoch 23/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9360 - loss: 0.1602 - val_accuracy: 0.9632 - val_loss: 0.0964\n",
            "Epoch 24/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.1436 - val_accuracy: 0.9652 - val_loss: 0.0912\n",
            "Epoch 25/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1242 - val_accuracy: 0.9611 - val_loss: 0.0916\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.9657 - loss: 0.0889\n",
            "Validation Accuracy: 0.9611\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_80, y_train_80, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "accuracy_80perc = accuracy\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqguxm-p4gov"
      },
      "source": [
        "### 60%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5081 - loss: 0.6934 - val_accuracy: 0.5153 - val_loss: 0.6903\n",
            "Epoch 2/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7382 - loss: 0.5474 - val_accuracy: 0.8344 - val_loss: 0.5156\n",
            "Epoch 3/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 0.3032 - val_accuracy: 0.8793 - val_loss: 0.3536\n",
            "Epoch 4/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.2508 - val_accuracy: 0.9080 - val_loss: 0.2387\n",
            "Epoch 5/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.2395 - val_accuracy: 0.9059 - val_loss: 0.2079\n",
            "Epoch 6/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2173 - val_accuracy: 0.9100 - val_loss: 0.1867\n",
            "Epoch 7/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.2187 - val_accuracy: 0.9182 - val_loss: 0.1674\n",
            "Epoch 8/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2259 - val_accuracy: 0.9448 - val_loss: 0.1376\n",
            "Epoch 9/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2109 - val_accuracy: 0.9346 - val_loss: 0.1349\n",
            "Epoch 10/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.1844 - val_accuracy: 0.9407 - val_loss: 0.1320\n",
            "Epoch 11/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9307 - loss: 0.1726 - val_accuracy: 0.9489 - val_loss: 0.1208\n",
            "Epoch 12/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9377 - loss: 0.1653 - val_accuracy: 0.9366 - val_loss: 0.1275\n",
            "Epoch 13/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.1620 - val_accuracy: 0.9530 - val_loss: 0.1095\n",
            "Epoch 14/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.1767 - val_accuracy: 0.9652 - val_loss: 0.1056\n",
            "Epoch 15/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.1542 - val_accuracy: 0.9468 - val_loss: 0.1146\n",
            "Epoch 16/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9361 - loss: 0.1652 - val_accuracy: 0.9550 - val_loss: 0.0996\n",
            "Epoch 17/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.1421 - val_accuracy: 0.9468 - val_loss: 0.1034\n",
            "Epoch 18/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9379 - loss: 0.1586 - val_accuracy: 0.9632 - val_loss: 0.0979\n",
            "Epoch 19/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.1194 - val_accuracy: 0.9591 - val_loss: 0.0956\n",
            "Epoch 20/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9371 - loss: 0.1636 - val_accuracy: 0.9591 - val_loss: 0.1045\n",
            "Epoch 21/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.1369 - val_accuracy: 0.9530 - val_loss: 0.1107\n",
            "Epoch 22/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9449 - loss: 0.1348 - val_accuracy: 0.9611 - val_loss: 0.0943\n",
            "Epoch 23/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9538 - loss: 0.1218 - val_accuracy: 0.9489 - val_loss: 0.1055\n",
            "Epoch 24/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9392 - loss: 0.1499 - val_accuracy: 0.9591 - val_loss: 0.0990\n",
            "Epoch 25/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9463 - loss: 0.1312 - val_accuracy: 0.9632 - val_loss: 0.0969\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.9553 - loss: 0.0955\n",
            "Validation Accuracy: 0.9632\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_60, y_train_60, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "accuracy_60perc = accuracy\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf0pR68U4iPA"
      },
      "source": [
        "### 40%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4973 - loss: 0.6932 - val_accuracy: 0.4847 - val_loss: 0.6945\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5067 - loss: 0.6937 - val_accuracy: 0.4847 - val_loss: 0.6932\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6431 - loss: 0.6543 - val_accuracy: 0.7873 - val_loss: 0.6206\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8093 - loss: 0.4318 - val_accuracy: 0.8446 - val_loss: 0.5100\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8626 - loss: 0.3380 - val_accuracy: 0.8671 - val_loss: 0.3977\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8624 - loss: 0.3357 - val_accuracy: 0.8834 - val_loss: 0.3129\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.2744 - val_accuracy: 0.8446 - val_loss: 0.2993\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2623 - val_accuracy: 0.9059 - val_loss: 0.2167\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9037 - loss: 0.2455 - val_accuracy: 0.9182 - val_loss: 0.1927\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8894 - loss: 0.2564 - val_accuracy: 0.9182 - val_loss: 0.1958\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.2009 - val_accuracy: 0.9243 - val_loss: 0.1686\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.1892 - val_accuracy: 0.8814 - val_loss: 0.2364\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2276 - val_accuracy: 0.9325 - val_loss: 0.1498\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2090 - val_accuracy: 0.9407 - val_loss: 0.1492\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2238 - val_accuracy: 0.9223 - val_loss: 0.1836\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.1845 - val_accuracy: 0.9202 - val_loss: 0.1679\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9330 - loss: 0.1752 - val_accuracy: 0.9243 - val_loss: 0.1537\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.1855 - val_accuracy: 0.9305 - val_loss: 0.1507\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.1568 - val_accuracy: 0.9305 - val_loss: 0.1403\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.1551 - val_accuracy: 0.9305 - val_loss: 0.1539\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.1782 - val_accuracy: 0.9284 - val_loss: 0.1328\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.1608 - val_accuracy: 0.9489 - val_loss: 0.1142\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9490 - loss: 0.1405 - val_accuracy: 0.9489 - val_loss: 0.1191\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.1744 - val_accuracy: 0.9427 - val_loss: 0.1232\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.1585 - val_accuracy: 0.9366 - val_loss: 0.1418\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.9373 - loss: 0.1413\n",
            "Validation Accuracy: 0.9366\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_40, y_train_40, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "\n",
        "accuracy_40perc = accuracy\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhxS-SEE4jmq"
      },
      "source": [
        "### 20%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5346 - loss: 0.6923 - val_accuracy: 0.5153 - val_loss: 0.6926\n",
            "Epoch 2/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5863 - loss: 0.6823 - val_accuracy: 0.5460 - val_loss: 0.6904\n",
            "Epoch 3/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6938 - loss: 0.6304 - val_accuracy: 0.6605 - val_loss: 0.6716\n",
            "Epoch 4/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.4510 - val_accuracy: 0.7751 - val_loss: 0.6100\n",
            "Epoch 5/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8729 - loss: 0.3198 - val_accuracy: 0.8016 - val_loss: 0.5465\n",
            "Epoch 6/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.3093 - val_accuracy: 0.8323 - val_loss: 0.5016\n",
            "Epoch 7/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2562 - val_accuracy: 0.8303 - val_loss: 0.4610\n",
            "Epoch 8/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2497 - val_accuracy: 0.8405 - val_loss: 0.4199\n",
            "Epoch 9/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2320 - val_accuracy: 0.8282 - val_loss: 0.4086\n",
            "Epoch 10/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2019 - val_accuracy: 0.8344 - val_loss: 0.3800\n",
            "Epoch 11/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2294 - val_accuracy: 0.8446 - val_loss: 0.3612\n",
            "Epoch 12/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2105 - val_accuracy: 0.8548 - val_loss: 0.3521\n",
            "Epoch 13/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.2002 - val_accuracy: 0.8425 - val_loss: 0.3588\n",
            "Epoch 14/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9330 - loss: 0.1864 - val_accuracy: 0.8589 - val_loss: 0.3393\n",
            "Epoch 15/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9372 - loss: 0.1656 - val_accuracy: 0.8569 - val_loss: 0.3492\n",
            "Epoch 16/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9384 - loss: 0.1582 - val_accuracy: 0.8487 - val_loss: 0.3567\n",
            "Epoch 17/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.1978 - val_accuracy: 0.8466 - val_loss: 0.3773\n",
            "Epoch 18/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9514 - loss: 0.1380 - val_accuracy: 0.8671 - val_loss: 0.3422\n",
            "Epoch 19/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9344 - loss: 0.1688 - val_accuracy: 0.8405 - val_loss: 0.4749\n",
            "Epoch 20/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.1986 - val_accuracy: 0.8548 - val_loss: 0.4123\n",
            "Epoch 21/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.1436 - val_accuracy: 0.8507 - val_loss: 0.4445\n",
            "Epoch 22/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.1408 - val_accuracy: 0.8691 - val_loss: 0.3698\n",
            "Epoch 23/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9398 - loss: 0.1638 - val_accuracy: 0.8569 - val_loss: 0.3942\n",
            "Epoch 24/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.1684 - val_accuracy: 0.8691 - val_loss: 0.3403\n",
            "Epoch 25/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9551 - loss: 0.1378 - val_accuracy: 0.8548 - val_loss: 0.3546\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.8468 - loss: 0.3490\n",
            "Validation Accuracy: 0.8548\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_20, y_train_20, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "\n",
        "accuracy_20perc = accuracy\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "-dSUVFednPSD",
        "outputId": "04cc19e4-a9a7-426f-db58-3537c798b7c2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the accuracy values for each training data percentage stored in a list\n",
        "training_data_percentages = [20, 40, 60, 80, 100]\n",
        "accuracies = [accuracy_20perc, accuracy_40perc, accuracy_60perc, accuracy_80perc, accuracy_100perc]  # Replace with your actual accuracy values\n",
        "\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(training_data_percentages, accuracies, marker='o')\n",
        "plt.xlabel('Percentage of Training Data Used')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Accuracy vs. Training Data Percentage')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c6SLKGoMju9",
        "outputId": "dd7994bf-97ce-4ebc-ded1-dc47a8973b46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))  # Embedding layer\n",
        "model.add(LSTM(16))  # LSTM layer with 16 units\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpjqkVnOMkKl",
        "outputId": "c75031e3-e74d-4fde-b319-c9977a1757d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5613 - loss: 0.6840 - val_accuracy: 0.8773 - val_loss: 0.4230\n",
            "Epoch 2/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9064 - loss: 0.3156 - val_accuracy: 0.9468 - val_loss: 0.1590\n",
            "Epoch 3/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9571 - loss: 0.1445 - val_accuracy: 0.9571 - val_loss: 0.1198\n",
            "Epoch 4/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9681 - loss: 0.1026 - val_accuracy: 0.9652 - val_loss: 0.0967\n",
            "Epoch 5/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.9769 - loss: 0.0836 - val_accuracy: 0.9652 - val_loss: 0.0845\n",
            "Epoch 6/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9797 - loss: 0.0707 - val_accuracy: 0.9755 - val_loss: 0.0723\n",
            "Epoch 7/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.9812 - loss: 0.0627 - val_accuracy: 0.9775 - val_loss: 0.0660\n",
            "Epoch 8/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.9840 - loss: 0.0550 - val_accuracy: 0.9714 - val_loss: 0.0625\n",
            "Epoch 9/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.9849 - loss: 0.0466 - val_accuracy: 0.9857 - val_loss: 0.0529\n",
            "Epoch 10/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.9896 - loss: 0.0423 - val_accuracy: 0.9836 - val_loss: 0.0474\n",
            "Epoch 11/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9894 - loss: 0.0412 - val_accuracy: 0.9816 - val_loss: 0.0482\n",
            "Epoch 12/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.9929 - loss: 0.0338 - val_accuracy: 0.9734 - val_loss: 0.0461\n",
            "Epoch 13/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.9907 - loss: 0.0314 - val_accuracy: 0.9836 - val_loss: 0.0421\n",
            "Epoch 14/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.9913 - loss: 0.0307 - val_accuracy: 0.9816 - val_loss: 0.0416\n",
            "Epoch 15/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9899 - loss: 0.0307 - val_accuracy: 0.9775 - val_loss: 0.0454\n",
            "Epoch 16/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9914 - loss: 0.0290 - val_accuracy: 0.9755 - val_loss: 0.0557\n",
            "Epoch 17/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9955 - loss: 0.0248 - val_accuracy: 0.9857 - val_loss: 0.0400\n",
            "Epoch 18/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9940 - loss: 0.0224 - val_accuracy: 0.9816 - val_loss: 0.0410\n",
            "Epoch 19/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9950 - loss: 0.0208 - val_accuracy: 0.9816 - val_loss: 0.0433\n",
            "Epoch 20/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.9975 - loss: 0.0160 - val_accuracy: 0.9796 - val_loss: 0.0428\n",
            "Epoch 21/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.9944 - loss: 0.0186 - val_accuracy: 0.9796 - val_loss: 0.0374\n",
            "Epoch 22/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9948 - loss: 0.0180 - val_accuracy: 0.9796 - val_loss: 0.0484\n",
            "Epoch 23/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.9958 - loss: 0.0160 - val_accuracy: 0.9796 - val_loss: 0.0444\n",
            "Epoch 24/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.9974 - loss: 0.0148 - val_accuracy: 0.9796 - val_loss: 0.0467\n",
            "Epoch 25/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9974 - loss: 0.0120 - val_accuracy: 0.9857 - val_loss: 0.0486\n",
            "Epoch 26/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9964 - loss: 0.0148 - val_accuracy: 0.9816 - val_loss: 0.0482\n",
            "Epoch 27/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9972 - loss: 0.0114 - val_accuracy: 0.9877 - val_loss: 0.0381\n",
            "Epoch 28/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9969 - loss: 0.0115 - val_accuracy: 0.9796 - val_loss: 0.0510\n",
            "Epoch 29/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9982 - loss: 0.0106 - val_accuracy: 0.9836 - val_loss: 0.0440\n",
            "Epoch 30/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9978 - loss: 0.0096 - val_accuracy: 0.9775 - val_loss: 0.0560\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9784 - loss: 0.0649\n",
            "Validation Accuracy: 0.977505087852478\n"
          ]
        }
      ],
      "source": [
        "# Train the model using the training data and validate on the validation set\n",
        "model.fit(train_padded, train_labels, epochs=30, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "print(f'Validation Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,720</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │         \u001b[38;5;34m1,720\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,013</span> (39.12 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,013\u001b[0m (39.12 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,337</span> (13.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,337\u001b[0m (13.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,676</span> (26.08 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,676\u001b[0m (26.08 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n94odYqLNmjj",
        "outputId": "2a17f712-4ae2-4d93-b9e3-4804a47657b5"
      },
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5922 - loss: 0.6399 - val_accuracy: 0.8937 - val_loss: 0.3960\n",
            "Epoch 2/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8494 - loss: 0.3335 - val_accuracy: 0.9202 - val_loss: 0.2024\n",
            "Epoch 3/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8749 - loss: 0.2862 - val_accuracy: 0.9387 - val_loss: 0.1517\n",
            "Epoch 4/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8870 - loss: 0.2572 - val_accuracy: 0.9366 - val_loss: 0.1494\n",
            "Epoch 5/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.2447 - val_accuracy: 0.9530 - val_loss: 0.1533\n",
            "Epoch 6/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2299 - val_accuracy: 0.9632 - val_loss: 0.1308\n",
            "Epoch 7/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.2157 - val_accuracy: 0.9387 - val_loss: 0.1374\n",
            "Epoch 8/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.2435 - val_accuracy: 0.9550 - val_loss: 0.1335\n",
            "Epoch 9/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2129 - val_accuracy: 0.9673 - val_loss: 0.1208\n",
            "Epoch 10/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2036 - val_accuracy: 0.9591 - val_loss: 0.1208\n",
            "Epoch 11/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2123 - val_accuracy: 0.9468 - val_loss: 0.1413\n",
            "Epoch 12/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.1838 - val_accuracy: 0.9509 - val_loss: 0.1115\n",
            "Epoch 13/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9277 - loss: 0.1886 - val_accuracy: 0.9734 - val_loss: 0.0947\n",
            "Epoch 14/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9345 - loss: 0.1665 - val_accuracy: 0.9611 - val_loss: 0.0980\n",
            "Epoch 15/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9449 - loss: 0.1368 - val_accuracy: 0.9693 - val_loss: 0.0937\n",
            "Epoch 16/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.1333 - val_accuracy: 0.9673 - val_loss: 0.0849\n",
            "Epoch 17/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.1228 - val_accuracy: 0.9427 - val_loss: 0.1161\n",
            "Epoch 18/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1278 - val_accuracy: 0.9550 - val_loss: 0.0999\n",
            "Epoch 19/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9564 - loss: 0.1071 - val_accuracy: 0.9611 - val_loss: 0.0828\n",
            "Epoch 20/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9548 - loss: 0.1133 - val_accuracy: 0.9550 - val_loss: 0.0851\n",
            "Epoch 21/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9646 - loss: 0.1036 - val_accuracy: 0.9755 - val_loss: 0.0613\n",
            "Epoch 22/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9626 - loss: 0.0959 - val_accuracy: 0.9734 - val_loss: 0.0650\n",
            "Epoch 23/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9664 - loss: 0.0848 - val_accuracy: 0.9714 - val_loss: 0.0732\n",
            "Epoch 24/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9609 - loss: 0.1035 - val_accuracy: 0.9734 - val_loss: 0.0618\n",
            "Epoch 25/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9629 - loss: 0.0948 - val_accuracy: 0.9755 - val_loss: 0.0575\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1666c70d0>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Train the model using the train set and validate on the validation set\n",
        "model.fit(train_padded, train_labels, epochs=25, batch_size=16, validation_data=(validation_padded, validation_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,720</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_10                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_11                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │         \u001b[38;5;34m1,720\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_10                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │         \u001b[38;5;34m1,088\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_11                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,224\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,173</span> (86.62 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,173\u001b[0m (86.62 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,369</span> (28.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,369\u001b[0m (28.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,740</span> (57.58 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m14,740\u001b[0m (57.58 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfxGjdppPGSF",
        "outputId": "b11276c0-e90d-489d-9b55-4573d8fe49d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9768 - loss: 0.0552\n",
            "Validation Accuracy: 0.9755\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('./models/dataset1.keras')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
