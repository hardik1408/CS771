{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hardik1408/CS771/blob/hardik/emoticon_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "x3jZxolZMRsN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Load the CSV files\n",
        "train_df = pd.read_csv('mini-project-1/datasets/train/train_emoticon.csv')\n",
        "validation_df = pd.read_csv('mini-project-1/datasets/valid/valid_emoticon.csv')\n",
        "test_df = pd.read_csv('mini-project-1/datasets/test/test_emoticon.csv')\n",
        "\n",
        "# Assuming the CSV files have 'emojis' and 'label' columns\n",
        "train_texts = train_df['input_emoticon'].values\n",
        "train_labels = train_df['label'].values\n",
        "\n",
        "validation_texts = validation_df['input_emoticon'].values\n",
        "validation_labels = validation_df['label'].values\n",
        "\n",
        "test_texts = test_df['input_emoticon'].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking how the data is made up, its distribution, frequencies etc.\n",
        "\n",
        "1) How many unique emoticons? ----- (214)\n",
        "2) We observe - 7 emoticons occur in every string, making 10/13 of the string.\n",
        "3) Only 3 emoticons, other than the 7 discussed, are present in each string.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique emoticons:  214\n"
          ]
        }
      ],
      "source": [
        "total_train = [] # A list of all the emoticons\n",
        "for i in train_texts:\n",
        "    total_train += i\n",
        "\n",
        "emoji_freq = dict() # Each emoticon mapped to its frequency of occurence\n",
        "for i in total_train:\n",
        "    if i in emoji_freq:\n",
        "        emoji_freq[i] += 1\n",
        "    else:\n",
        "        emoji_freq[i] = 1\n",
        "\n",
        "print('Total unique emoticons: ', len(emoji_freq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'😛': (3576, 3504),\n",
              " '🛐': (3576, 3504),\n",
              " '😻': (81, 82),\n",
              " '😑': (3576, 3504),\n",
              " '😣': (3576, 3504),\n",
              " '🙠': (19, 44),\n",
              " '🙯': (3576, 3504),\n",
              " '🚼': (3576, 3504),\n",
              " '😒': (83, 82),\n",
              " '🙼': (3576, 3504),\n",
              " '😪': (80, 83),\n",
              " '🚅': (34, 34),\n",
              " '😹': (81, 79),\n",
              " '🚡': (82, 80),\n",
              " '🙲': (39, 33),\n",
              " '🛑': (80, 83),\n",
              " '🙐': (79, 77),\n",
              " '🙪': (31, 19),\n",
              " '🛆': (84, 84),\n",
              " '🚟': (76, 79),\n",
              " '🙋': (27, 18),\n",
              " '🚧': (35, 37),\n",
              " '🚜': (79, 85),\n",
              " '🙕': (81, 80),\n",
              " '🚥': (29, 23),\n",
              " '😬': (82, 81),\n",
              " '🚄': (79, 76),\n",
              " '🚔': (27, 34),\n",
              " '🛓': (83, 76),\n",
              " '\\U0001f6dc': (32, 23),\n",
              " '😚': (81, 76),\n",
              " '🚠': (85, 81),\n",
              " '🙷': (22, 30),\n",
              " '😍': (81, 82),\n",
              " '😿': (80, 81),\n",
              " '🙚': (25, 24),\n",
              " '😸': (79, 79),\n",
              " '😯': (38, 42),\n",
              " '🙒': (84, 79),\n",
              " '🚙': (31, 24),\n",
              " '🚴': (32, 35),\n",
              " '😴': (81, 80),\n",
              " '🚂': (36, 30),\n",
              " '😦': (78, 82),\n",
              " '🙨': (83, 82),\n",
              " '🛝': (36, 25),\n",
              " '😉': (84, 79),\n",
              " '😵': (26, 20),\n",
              " '🚃': (83, 79),\n",
              " '😘': (28, 22),\n",
              " '😊': (84, 78),\n",
              " '😌': (34, 34),\n",
              " '🙧': (41, 29),\n",
              " '🚍': (82, 77),\n",
              " '😢': (83, 82),\n",
              " '🚵': (34, 23),\n",
              " '😩': (85, 82),\n",
              " '😠': (27, 30),\n",
              " '🛡': (78, 81),\n",
              " '😰': (27, 22),\n",
              " '🚏': (80, 82),\n",
              " '🚗': (30, 28),\n",
              " '🙸': (81, 81),\n",
              " '🚌': (76, 84),\n",
              " '😓': (80, 81),\n",
              " '🚲': (44, 29),\n",
              " '😆': (80, 79),\n",
              " '🛌': (83, 84),\n",
              " '😺': (38, 27),\n",
              " '🙍': (79, 78),\n",
              " '😳': (28, 28),\n",
              " '🚦': (84, 77),\n",
              " '😏': (26, 31),\n",
              " '🙏': (82, 82),\n",
              " '🚯': (82, 82),\n",
              " '🙊': (80, 82),\n",
              " '😤': (27, 39),\n",
              " '🙀': (83, 74),\n",
              " '🛔': (38, 25),\n",
              " '🚷': (81, 80),\n",
              " '🛈': (29, 23),\n",
              " '🛋': (78, 80),\n",
              " '\\U0001f6db': (78, 80),\n",
              " '🚊': (32, 42),\n",
              " '🛀': (85, 80),\n",
              " '🚒': (45, 29),\n",
              " '🙟': (78, 81),\n",
              " '😧': (35, 34),\n",
              " '🚰': (80, 81),\n",
              " '🙬': (84, 81),\n",
              " '🚳': (34, 29),\n",
              " '🛏': (82, 83),\n",
              " '🛍': (81, 81),\n",
              " '😨': (26, 20),\n",
              " '😗': (31, 27),\n",
              " '🙈': (29, 36),\n",
              " '😱': (80, 80),\n",
              " '🚆': (24, 27),\n",
              " '🛖': (79, 79),\n",
              " '\\U0001f6d8': (77, 81),\n",
              " '🙔': (33, 29),\n",
              " '🚱': (23, 18),\n",
              " '🚮': (38, 27),\n",
              " '🙁': (26, 29),\n",
              " '🙽': (81, 82),\n",
              " '🚾': (84, 81),\n",
              " '🚣': (83, 81),\n",
              " '🙇': (25, 32),\n",
              " '😎': (37, 25),\n",
              " '🚿': (81, 81),\n",
              " '🚎': (26, 27),\n",
              " '🙄': (80, 81),\n",
              " '🛎': (29, 29),\n",
              " '😁': (80, 82),\n",
              " '🙅': (79, 80),\n",
              " '🚕': (20, 41),\n",
              " '🙫': (83, 80),\n",
              " '😮': (82, 79),\n",
              " '🙳': (44, 31),\n",
              " '🙩': (81, 82),\n",
              " '🚁': (82, 81),\n",
              " '🙦': (34, 35),\n",
              " '😼': (24, 25),\n",
              " '🛄': (80, 81),\n",
              " '😋': (82, 78),\n",
              " '😖': (31, 29),\n",
              " '😞': (31, 26),\n",
              " '🙙': (31, 32),\n",
              " '🛇': (84, 82),\n",
              " '🙤': (48, 31),\n",
              " '😶': (85, 82),\n",
              " '🛉': (34, 23),\n",
              " '🙾': (33, 16),\n",
              " '🚀': (27, 40),\n",
              " '😲': (34, 22),\n",
              " '🚓': (24, 36),\n",
              " '🙶': (31, 23),\n",
              " '🛒': (25, 31),\n",
              " '🚑': (29, 19),\n",
              " '🙎': (81, 79),\n",
              " '🛂': (84, 79),\n",
              " '🚭': (25, 28),\n",
              " '🙑': (26, 39),\n",
              " '🚚': (24, 28),\n",
              " '🚛': (38, 37),\n",
              " '🙱': (31, 37),\n",
              " '😕': (81, 80),\n",
              " '🙗': (17, 23),\n",
              " '🚇': (84, 82),\n",
              " '🛅': (77, 80),\n",
              " '🚽': (81, 85),\n",
              " '🚩': (25, 29),\n",
              " '😅': (81, 78),\n",
              " '🙜': (30, 27),\n",
              " '🙹': (22, 30),\n",
              " '🚶': (26, 30),\n",
              " '🙘': (20, 34),\n",
              " '😷': (39, 15),\n",
              " '🛟': (82, 82),\n",
              " '😾': (30, 32),\n",
              " '😥': (81, 83),\n",
              " '😔': (83, 80),\n",
              " '🚐': (30, 32),\n",
              " '🚺': (80, 77),\n",
              " '🚉': (31, 32),\n",
              " '🙰': (25, 34),\n",
              " '😜': (41, 34),\n",
              " '🙌': (29, 32),\n",
              " '🙉': (29, 29),\n",
              " '😂': (21, 33),\n",
              " '🚫': (31, 25),\n",
              " '😡': (83, 83),\n",
              " '🙛': (84, 80),\n",
              " '🙖': (28, 29),\n",
              " '😙': (33, 32),\n",
              " '🙿': (36, 29),\n",
              " '🙮': (85, 82),\n",
              " '😟': (40, 30),\n",
              " '🙆': (25, 29),\n",
              " '😀': (26, 25),\n",
              " '😐': (35, 29),\n",
              " '😫': (31, 31),\n",
              " '😇': (82, 80),\n",
              " '🛞': (22, 31),\n",
              " '🛗': (26, 29),\n",
              " '🚈': (24, 33),\n",
              " '🙣': (26, 29),\n",
              " '🚝': (81, 83),\n",
              " '🚨': (30, 25),\n",
              " '🚞': (27, 29),\n",
              " '😃': (23, 26),\n",
              " '😽': (33, 24),\n",
              " '🚸': (26, 30),\n",
              " '🚖': (25, 20),\n",
              " '😭': (25, 30),\n",
              " '🙢': (82, 79),\n",
              " '🚤': (36, 25),\n",
              " '\\U0001f6d9': (80, 83),\n",
              " '🙥': (25, 27),\n",
              " '😄': (34, 22),\n",
              " '🚪': (26, 27),\n",
              " '🚹': (19, 31),\n",
              " '🙞': (29, 28),\n",
              " '😝': (26, 42),\n",
              " '🙴': (23, 32),\n",
              " '🚘': (35, 35),\n",
              " '🙓': (25, 20),\n",
              " '🙃': (31, 29),\n",
              " '🚢': (34, 36),\n",
              " '🛁': (26, 37),\n",
              " '🛊': (23, 35),\n",
              " '🛕': (30, 25),\n",
              " '🚋': (31, 30),\n",
              " '🙻': (29, 38)}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emoji_0_1 = dict()\n",
        "\n",
        "for i in emoji_freq:\n",
        "    emoji_0_1[i] = (0,0)\n",
        "\n",
        "for i in emoji_freq:\n",
        "    for j in range(len(train_texts)):\n",
        "        if i in train_texts[j]:\n",
        "            if train_labels[j] == 1:\n",
        "                emoji_0_1[i] = (emoji_0_1[i][0], emoji_0_1[i][1]+1)\n",
        "            else:\n",
        "                emoji_0_1[i] = (emoji_0_1[i][0]+1, emoji_0_1[i][1])\n",
        "\n",
        "emoji_0_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['😛', '🛐', '😑', '😣', '🙯', '🚼', '🙼']"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "most_frequent_emojis = []\n",
        "for i in emoji_0_1:\n",
        "    if emoji_0_1[i] == (3576, 3504):\n",
        "        most_frequent_emojis.append(i)\n",
        "\n",
        "most_frequent_emojis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We find that in every row these 7 emoticons appear!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also, these 7 emoticons make up exactly 10/13 of every given string (Be it train or validation)\n",
        "\n",
        "So, we make modified datasets ie. 'train_texts_mod', 'validation_texts_mod', and 'test_texts_mod', which omit the 7 most \n",
        "occuring emoticons. So all these 3 modified lists have 3 length string elements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modifying the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_texts_mod = []\n",
        "\n",
        "for i in train_texts:\n",
        "    s = ''\n",
        "    for j in i:\n",
        "        if j not in most_frequent_emojis:\n",
        "            s += j\n",
        "    train_texts_mod.append(s)\n",
        "\n",
        "train_texts_mod = np.array(train_texts_mod, dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_texts_mod = []\n",
        "\n",
        "for i in validation_texts:\n",
        "    s = ''\n",
        "    for j in i:\n",
        "        if j not in most_frequent_emojis:\n",
        "            s += j\n",
        "    validation_texts_mod.append(s)\n",
        "\n",
        "validation_texts_mod = np.array(validation_texts_mod, dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_texts_mod = []\n",
        "\n",
        "for i in test_texts:\n",
        "    s = ''\n",
        "    for j in i:\n",
        "        if j not in most_frequent_emojis:\n",
        "            s += j\n",
        "    test_texts_mod.append(s)\n",
        "\n",
        "test_texts_mod = np.array(test_texts_mod, dtype=object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us9r2ho04M5N"
      },
      "source": [
        "# Preprocessing on input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "KWUvSmeJjS6Q"
      },
      "outputs": [],
      "source": [
        "#  Tokenize and pad the emoji sequences\n",
        "tokenizer = Tokenizer(char_level=True)  # Tokenizing each emoji as a character\n",
        "tokenizer.fit_on_texts(train_texts)  # Fit only on training data\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts_mod)\n",
        "validation_sequences = tokenizer.texts_to_sequences(validation_texts_mod)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts_mod)\n",
        "\n",
        "# Pad the sequences to the same length\n",
        "max_len = max([len(seq) for seq in train_sequences])  # Maximum sequence length in train data\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "validation_padded = pad_sequences(validation_sequences, maxlen=max_len, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Convert labels into numeric format if they are not (if necessary)\n",
        "train_labels = train_labels.astype(int)\n",
        "validation_labels = validation_labels.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbJTSlT44Qhh"
      },
      "source": [
        "### Dividing data for the task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "nhvob_QQkWzq"
      },
      "outputs": [],
      "source": [
        "x_train_100 = train_padded\n",
        "y_train_100 = train_labels\n",
        "# prompt: take only 80% of the training dataset\n",
        "\n",
        "train_size_80 = int(len(x_train_100) * 0.8)\n",
        "x_train_80 = x_train_100[:train_size_80]\n",
        "y_train_80 = y_train_100[:train_size_80]\n",
        "# prompt: take only 60% of training data\n",
        "\n",
        "# Shuffle the indices of the training data\n",
        "indices = np.arange(len(x_train_100))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calculate the number of samples for 60% of the data\n",
        "train_size_60_random = int(len(x_train_100) * 0.6)\n",
        "\n",
        "# Select the shuffled indices for the 60% split\n",
        "x_train_60 = x_train_100[indices[:train_size_60_random]]\n",
        "y_train_60 = y_train_100[indices[:train_size_60_random]]\n",
        "\n",
        "indices = np.arange(len(x_train_100))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calculate the number of samples for 60% of the data\n",
        "train_size_40_random = int(len(x_train_100) * 0.4)\n",
        "\n",
        "# Select the shuffled indices for the 60% split\n",
        "x_train_40 = x_train_100[indices[:train_size_40_random]]\n",
        "y_train_40 = y_train_100[indices[:train_size_40_random]]\n",
        "\n",
        "indices = np.arange(len(x_train_100))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calculate the number of samples for 60% of the data\n",
        "train_size_20_random = int(len(x_train_100) * 0.2)\n",
        "\n",
        "# Select the shuffled indices for the 60% split\n",
        "x_train_20 = x_train_100[indices[:train_size_20_random]]\n",
        "y_train_20 = y_train_100[indices[:train_size_20_random]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gleGdU3HkvXp"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "R36oQLIbkxWD",
        "outputId": "2cd49fca-73b8-4f20-e36b-dd3170442896"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opm-L1rY4cVG"
      },
      "source": [
        "### Training with 100% data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq1r6hsyjq8m",
        "outputId": "822860ab-78ab-4e3a-fddd-5f2e34bd7529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5233 - loss: 0.6898 - val_accuracy: 0.8057 - val_loss: 0.6259\n",
            "Epoch 2/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.3871 - val_accuracy: 0.8957 - val_loss: 0.3405\n",
            "Epoch 3/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8895 - loss: 0.2738 - val_accuracy: 0.8793 - val_loss: 0.2407\n",
            "Epoch 4/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8839 - loss: 0.2589 - val_accuracy: 0.9305 - val_loss: 0.1605\n",
            "Epoch 5/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8920 - loss: 0.2469 - val_accuracy: 0.9571 - val_loss: 0.1249\n",
            "Epoch 6/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.2179 - val_accuracy: 0.9468 - val_loss: 0.1285\n",
            "Epoch 7/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2121 - val_accuracy: 0.9530 - val_loss: 0.1106\n",
            "Epoch 8/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.1831 - val_accuracy: 0.9468 - val_loss: 0.1206\n",
            "Epoch 9/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.1848 - val_accuracy: 0.9591 - val_loss: 0.1094\n",
            "Epoch 10/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.1759 - val_accuracy: 0.9571 - val_loss: 0.0954\n",
            "Epoch 11/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.1366 - val_accuracy: 0.9530 - val_loss: 0.1073\n",
            "Epoch 12/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.1332 - val_accuracy: 0.9652 - val_loss: 0.0873\n",
            "Epoch 13/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9522 - loss: 0.1181 - val_accuracy: 0.9796 - val_loss: 0.0552\n",
            "Epoch 14/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1103 - val_accuracy: 0.9755 - val_loss: 0.0556\n",
            "Epoch 15/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.1061 - val_accuracy: 0.9857 - val_loss: 0.0510\n",
            "Epoch 16/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.0857 - val_accuracy: 0.9836 - val_loss: 0.0522\n",
            "Epoch 17/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9606 - loss: 0.0931 - val_accuracy: 0.9755 - val_loss: 0.0635\n",
            "Epoch 18/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.0833 - val_accuracy: 0.9673 - val_loss: 0.0718\n",
            "Epoch 19/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 0.0823 - val_accuracy: 0.9734 - val_loss: 0.0687\n",
            "Epoch 20/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9751 - loss: 0.0713 - val_accuracy: 0.9652 - val_loss: 0.0658\n",
            "Epoch 21/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0623 - val_accuracy: 0.9734 - val_loss: 0.0670\n",
            "Epoch 22/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0606 - val_accuracy: 0.9734 - val_loss: 0.0583\n",
            "Epoch 23/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9749 - loss: 0.0666 - val_accuracy: 0.9734 - val_loss: 0.0744\n",
            "Epoch 24/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0559 - val_accuracy: 0.9693 - val_loss: 0.0792\n",
            "Epoch 25/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.0635 - val_accuracy: 0.9632 - val_loss: 0.0795\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9651 - loss: 0.0824\n",
            "Validation Accuracy: 0.9632\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_100, y_train_100, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "acc_100 = accuracy\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "model.save('emoticons_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,720</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │         \u001b[38;5;34m1,720\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │         \u001b[38;5;34m1,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,224\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,173</span> (86.62 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,173\u001b[0m (86.62 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,369</span> (28.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,369\u001b[0m (28.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,740</span> (57.58 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m14,740\u001b[0m (57.58 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print the model summary for reference\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcvCDYi-4e_W"
      },
      "source": [
        "### Training with 80% data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5312 - loss: 0.6886 - val_accuracy: 0.6094 - val_loss: 0.6730\n",
            "Epoch 2/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8064 - loss: 0.4427 - val_accuracy: 0.8712 - val_loss: 0.4093\n",
            "Epoch 3/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8809 - loss: 0.2826 - val_accuracy: 0.9141 - val_loss: 0.2563\n",
            "Epoch 4/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9081 - loss: 0.2318 - val_accuracy: 0.9264 - val_loss: 0.1768\n",
            "Epoch 5/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2329 - val_accuracy: 0.9305 - val_loss: 0.1498\n",
            "Epoch 6/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9290 - loss: 0.1766 - val_accuracy: 0.9448 - val_loss: 0.1308\n",
            "Epoch 7/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.1683 - val_accuracy: 0.9509 - val_loss: 0.1036\n",
            "Epoch 8/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9305 - loss: 0.1702 - val_accuracy: 0.9468 - val_loss: 0.1114\n",
            "Epoch 9/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9358 - loss: 0.1637 - val_accuracy: 0.9509 - val_loss: 0.1095\n",
            "Epoch 10/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9355 - loss: 0.1607 - val_accuracy: 0.9571 - val_loss: 0.1008\n",
            "Epoch 11/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9339 - loss: 0.1584 - val_accuracy: 0.9632 - val_loss: 0.0994\n",
            "Epoch 12/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.1635 - val_accuracy: 0.9489 - val_loss: 0.0987\n",
            "Epoch 13/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.1452 - val_accuracy: 0.9550 - val_loss: 0.0954\n",
            "Epoch 14/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1387 - val_accuracy: 0.9734 - val_loss: 0.0846\n",
            "Epoch 15/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.1433 - val_accuracy: 0.9571 - val_loss: 0.0995\n",
            "Epoch 16/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9543 - loss: 0.1205 - val_accuracy: 0.9734 - val_loss: 0.0764\n",
            "Epoch 17/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1333 - val_accuracy: 0.9591 - val_loss: 0.0783\n",
            "Epoch 18/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9547 - loss: 0.1182 - val_accuracy: 0.9652 - val_loss: 0.0626\n",
            "Epoch 19/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9547 - loss: 0.1013 - val_accuracy: 0.9611 - val_loss: 0.0830\n",
            "Epoch 20/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9620 - loss: 0.0953 - val_accuracy: 0.9714 - val_loss: 0.0699\n",
            "Epoch 21/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.0758 - val_accuracy: 0.9611 - val_loss: 0.0834\n",
            "Epoch 22/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9713 - loss: 0.0752 - val_accuracy: 0.9652 - val_loss: 0.0743\n",
            "Epoch 23/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9751 - loss: 0.0747 - val_accuracy: 0.9714 - val_loss: 0.0721\n",
            "Epoch 24/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9787 - loss: 0.0661 - val_accuracy: 0.9693 - val_loss: 0.0727\n",
            "Epoch 25/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9772 - loss: 0.0682 - val_accuracy: 0.9673 - val_loss: 0.0701\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.9601 - loss: 0.0825\n",
            "Validation Accuracy: 0.9673\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_80, y_train_80, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "acc_80 = accuracy\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqguxm-p4gov"
      },
      "source": [
        "### Training with 60% data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4976 - loss: 0.6947 - val_accuracy: 0.5153 - val_loss: 0.6918\n",
            "Epoch 2/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6351 - loss: 0.6444 - val_accuracy: 0.8180 - val_loss: 0.5630\n",
            "Epoch 3/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8624 - loss: 0.3417 - val_accuracy: 0.9039 - val_loss: 0.3907\n",
            "Epoch 4/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8823 - loss: 0.2793 - val_accuracy: 0.8916 - val_loss: 0.2882\n",
            "Epoch 5/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9025 - loss: 0.2467 - val_accuracy: 0.9223 - val_loss: 0.1947\n",
            "Epoch 6/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2456 - val_accuracy: 0.9284 - val_loss: 0.1633\n",
            "Epoch 7/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.2185 - val_accuracy: 0.9202 - val_loss: 0.1670\n",
            "Epoch 8/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2241 - val_accuracy: 0.9284 - val_loss: 0.1621\n",
            "Epoch 9/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2116 - val_accuracy: 0.9387 - val_loss: 0.1484\n",
            "Epoch 10/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.1976 - val_accuracy: 0.9387 - val_loss: 0.1481\n",
            "Epoch 11/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.1991 - val_accuracy: 0.9366 - val_loss: 0.1339\n",
            "Epoch 12/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2085 - val_accuracy: 0.9325 - val_loss: 0.1419\n",
            "Epoch 13/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.1895 - val_accuracy: 0.9550 - val_loss: 0.1202\n",
            "Epoch 14/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.1910 - val_accuracy: 0.9448 - val_loss: 0.1296\n",
            "Epoch 15/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.1782 - val_accuracy: 0.9550 - val_loss: 0.1187\n",
            "Epoch 16/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9415 - loss: 0.1582 - val_accuracy: 0.9448 - val_loss: 0.1315\n",
            "Epoch 17/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.1718 - val_accuracy: 0.9468 - val_loss: 0.1307\n",
            "Epoch 18/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9343 - loss: 0.1749 - val_accuracy: 0.9427 - val_loss: 0.1187\n",
            "Epoch 19/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9435 - loss: 0.1501 - val_accuracy: 0.9591 - val_loss: 0.0991\n",
            "Epoch 20/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9397 - loss: 0.1500 - val_accuracy: 0.9571 - val_loss: 0.0979\n",
            "Epoch 21/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9323 - loss: 0.1613 - val_accuracy: 0.9611 - val_loss: 0.0922\n",
            "Epoch 22/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1327 - val_accuracy: 0.9530 - val_loss: 0.0984\n",
            "Epoch 23/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.1359 - val_accuracy: 0.9571 - val_loss: 0.0965\n",
            "Epoch 24/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1277 - val_accuracy: 0.9550 - val_loss: 0.0926\n",
            "Epoch 25/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9522 - loss: 0.1203 - val_accuracy: 0.9632 - val_loss: 0.0851\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.9667 - loss: 0.0720\n",
            "Validation Accuracy: 0.9632\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_60, y_train_60, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "acc_60 = accuracy\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf0pR68U4iPA"
      },
      "source": [
        "### Training with 40% data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5001 - loss: 0.6936 - val_accuracy: 0.5562 - val_loss: 0.6929\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5482 - loss: 0.6853 - val_accuracy: 0.6033 - val_loss: 0.6863\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.5886 - val_accuracy: 0.8241 - val_loss: 0.5424\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.3400 - val_accuracy: 0.8691 - val_loss: 0.4436\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.2736 - val_accuracy: 0.8650 - val_loss: 0.3574\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.2505 - val_accuracy: 0.8691 - val_loss: 0.2852\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2631 - val_accuracy: 0.8978 - val_loss: 0.2398\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2064 - val_accuracy: 0.9100 - val_loss: 0.1899\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.2010 - val_accuracy: 0.9141 - val_loss: 0.1909\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2059 - val_accuracy: 0.9121 - val_loss: 0.1917\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.1980 - val_accuracy: 0.9223 - val_loss: 0.1681\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9335 - loss: 0.1653 - val_accuracy: 0.9182 - val_loss: 0.1684\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9309 - loss: 0.1596 - val_accuracy: 0.9182 - val_loss: 0.1654\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9309 - loss: 0.1698 - val_accuracy: 0.9182 - val_loss: 0.1880\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.1724 - val_accuracy: 0.9284 - val_loss: 0.1650\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.1885 - val_accuracy: 0.9284 - val_loss: 0.1588\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9434 - loss: 0.1363 - val_accuracy: 0.9325 - val_loss: 0.1650\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.1618 - val_accuracy: 0.9202 - val_loss: 0.1921\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9307 - loss: 0.1642 - val_accuracy: 0.9223 - val_loss: 0.1599\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.1749 - val_accuracy: 0.9346 - val_loss: 0.1588\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9403 - loss: 0.1483 - val_accuracy: 0.9243 - val_loss: 0.1618\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9351 - loss: 0.1555 - val_accuracy: 0.9141 - val_loss: 0.1779\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.1377 - val_accuracy: 0.9346 - val_loss: 0.1586\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9367 - loss: 0.1576 - val_accuracy: 0.9366 - val_loss: 0.1470\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.1527 - val_accuracy: 0.9284 - val_loss: 0.1703\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.9423 - loss: 0.1399\n",
            "Validation Accuracy: 0.9284\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_40, y_train_40, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "acc_40 = accuracy\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhxS-SEE4jmq"
      },
      "source": [
        "### Training with 20% data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5236 - loss: 0.6938 - val_accuracy: 0.5153 - val_loss: 0.6929\n",
            "Epoch 2/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5481 - loss: 0.6846 - val_accuracy: 0.5153 - val_loss: 0.6925\n",
            "Epoch 3/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5932 - loss: 0.6760 - val_accuracy: 0.5112 - val_loss: 0.6907\n",
            "Epoch 4/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7051 - loss: 0.6113 - val_accuracy: 0.6299 - val_loss: 0.6774\n",
            "Epoch 5/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7558 - loss: 0.5173 - val_accuracy: 0.6810 - val_loss: 0.6293\n",
            "Epoch 6/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.3652 - val_accuracy: 0.8016 - val_loss: 0.5451\n",
            "Epoch 7/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8590 - loss: 0.3276 - val_accuracy: 0.8344 - val_loss: 0.4887\n",
            "Epoch 8/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.2870 - val_accuracy: 0.8160 - val_loss: 0.4589\n",
            "Epoch 9/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8743 - loss: 0.2819 - val_accuracy: 0.8200 - val_loss: 0.4210\n",
            "Epoch 10/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.2719 - val_accuracy: 0.8528 - val_loss: 0.3713\n",
            "Epoch 11/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8954 - loss: 0.2436 - val_accuracy: 0.8609 - val_loss: 0.3455\n",
            "Epoch 12/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2365 - val_accuracy: 0.8344 - val_loss: 0.3838\n",
            "Epoch 13/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.2078 - val_accuracy: 0.8569 - val_loss: 0.3252\n",
            "Epoch 14/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.2447 - val_accuracy: 0.8405 - val_loss: 0.3764\n",
            "Epoch 15/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.2798 - val_accuracy: 0.8630 - val_loss: 0.3455\n",
            "Epoch 16/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2058 - val_accuracy: 0.8528 - val_loss: 0.3748\n",
            "Epoch 17/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.2204 - val_accuracy: 0.8569 - val_loss: 0.3395\n",
            "Epoch 18/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2006 - val_accuracy: 0.8466 - val_loss: 0.4037\n",
            "Epoch 19/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2203 - val_accuracy: 0.8425 - val_loss: 0.4316\n",
            "Epoch 20/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.1868 - val_accuracy: 0.8650 - val_loss: 0.3379\n",
            "Epoch 21/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2032 - val_accuracy: 0.8671 - val_loss: 0.3358\n",
            "Epoch 22/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.1889 - val_accuracy: 0.8630 - val_loss: 0.3884\n",
            "Epoch 23/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.1983 - val_accuracy: 0.8712 - val_loss: 0.3276\n",
            "Epoch 24/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9321 - loss: 0.1779 - val_accuracy: 0.8671 - val_loss: 0.3209\n",
            "Epoch 25/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9228 - loss: 0.1917 - val_accuracy: 0.8793 - val_loss: 0.3338\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.8894 - loss: 0.3007\n",
            "Validation Accuracy: 0.8793\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_20, y_train_20, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "acc_20 = accuracy\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "-dSUVFednPSD",
        "outputId": "04cc19e4-a9a7-426f-db58-3537c798b7c2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# prompt: create a plot which plots the accuracy vs the percentage of training data used\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the accuracy values for each training data percentage stored in a list\n",
        "training_data_percentages = [20, 40, 60, 80, 100]\n",
        "accuracies = [acc_20, acc_40, acc_60, acc_80, acc_100]  # Replace with your actual accuracy values\n",
        "\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(training_data_percentages, accuracies, marker='o')\n",
        "plt.xlabel('Percentage of Training Data Used')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Accuracy vs. Training Data Percentage')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Data Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the CSV files\n",
        "test_df = pd.read_csv('/Users/namangupta/Desktop/771/mini-project-1/datasets/test/test_emoticon.csv')\n",
        "\n",
        "# Assuming the CSV files have 'emojis' and 'label' columns\n",
        "test_texts = test_df['input_emoticon'].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, all the test data strings are of length 3, after preprocessing. So, they can be fed into our already trained model to get the binary prediction labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'001000011111001000010100001100010101010101101111001000000010010100000000011011100010001000111010111001011011110110010010011100101111111001001000001000001110010100001101100011000001101000101000110011000111101001000001100100100000001010000110000111000001000001001110101100101011110011110011110001011101001100000001000000011000111000011110111000100101100000110000100011001100101100100100010011111001100101010000101100111000001000000001010001100010100100111101100001000101010000000001110001001100110011001011010010000000011001001010101110000100110101101010010100011100000101000010100000011101011000100010000011010010001110011110100000101100010000110001010110100010011111100001010010101100000010000010000100000101000000100011110000001001010000111100110010001101011011010001111110000100001000000000001011100011010110001001010010101001000000001110010001100000100101100001011000100000000100101010101011100100111100010000101100001111010110000110001010000011001011001011000010000001011011011000101110010100011010011001011011001010101100011000110010111001011010100100010010111001100101110010001011001010100001101101100011000110000100101110111101111010010110000000100011010010111001000000001101100011000011111010110101101100100100100011010000011101110010000111101000111010101001110101111001110011000001110000111000110100000100001010110100101100110101010000100011001011000000110111000011001101001001001000000000010000101000011011100000101110000000001010011001010011111111100000100100100011110000011001110010111000110000000111010101000111100000011000000001110000001010101110100001001001110101011101001010000110000000101110000000000010001010010001010100001100000110011111011001101011100000100000000011010010111010000110101100010110000010101011011100101000000110000011101110010000100100101100011001011010101101001010100101000001101001000110010001010001101111001111111100010000101101000111001110011001001100110110000101010010001101011101011110110100100100010000111101000111101010000010001010010101011110000011001101011001100010000110011001000000001111011110000100110011000010010111001011000100010000010100111000000001001100000000000010001000101010110010001001101101010000110111011110010100110001001110101101000011000101001110000010000110011010011111'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = model.predict(test_padded)\n",
        "predicted_labels = (predictions > 0.5).astype(int)\n",
        "\n",
        "predictions_string = ''\n",
        "for i in predicted_labels:\n",
        "    predictions_string += str(i[0])\n",
        "\n",
        "predictions_string\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
