{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hardik1408/CS771/blob/hardik/emoticon_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loading the files\n"
      ],
      "metadata": {
        "id": "DkxlTXck4JxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Load the CSV files\n",
        "train_df = pd.read_csv('train_emoticon.csv')\n",
        "validation_df = pd.read_csv('valid_emoticon.csv')\n",
        "\n",
        "# Assuming the CSV files have 'emojis' and 'label' columns\n",
        "train_texts = train_df['input_emoticon'].values\n",
        "train_labels = train_df['label'].values\n",
        "\n",
        "validation_texts = validation_df['input_emoticon'].values\n",
        "validation_labels = validation_df['label'].values"
      ],
      "metadata": {
        "id": "x3jZxolZMRsN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preprocessing on input"
      ],
      "metadata": {
        "id": "Us9r2ho04M5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Tokenize and pad the emoji sequences\n",
        "tokenizer = Tokenizer(char_level=True)  # Tokenizing each emoji as a character\n",
        "tokenizer.fit_on_texts(train_texts)  # Fit only on training data\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "validation_sequences = tokenizer.texts_to_sequences(validation_texts)\n",
        "\n",
        "# Pad the sequences to the same length\n",
        "max_len = max([len(seq) for seq in train_sequences])  # Maximum sequence length in train data\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "validation_padded = pad_sequences(validation_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Convert labels into numeric format if they are not (if necessary)\n",
        "train_labels = train_labels.astype(int)\n",
        "validation_labels = validation_labels.astype(int)"
      ],
      "metadata": {
        "id": "KWUvSmeJjS6Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dividing data for the task"
      ],
      "metadata": {
        "id": "IbJTSlT44Qhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_train_100 = train_padded\n",
        "y_train_100 = train_labels\n",
        "# prompt: take only 80% of the training dataset\n",
        "\n",
        "train_size_80 = int(len(x_train_100) * 0.8)\n",
        "x_train_80 = x_train_100[:train_size_80]\n",
        "y_train_80 = y_train_100[:train_size_80]\n",
        "# prompt: take only 60% of training data\n",
        "\n",
        "# Shuffle the indices of the training data\n",
        "indices = np.arange(len(x_train_100))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calculate the number of samples for 60% of the data\n",
        "train_size_60_random = int(len(x_train_100) * 0.6)\n",
        "\n",
        "# Select the shuffled indices for the 60% split\n",
        "x_train_60 = x_train_100[indices[:train_size_60_random]]\n",
        "y_train_60 = y_train_100[indices[:train_size_60_random]]\n",
        "\n",
        "indices = np.arange(len(x_train_100))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calculate the number of samples for 60% of the data\n",
        "train_size_40_random = int(len(x_train_100) * 0.4)\n",
        "\n",
        "# Select the shuffled indices for the 60% split\n",
        "x_train_40 = x_train_100[indices[:train_size_40_random]]\n",
        "y_train_40 = y_train_100[indices[:train_size_40_random]]\n",
        "\n",
        "indices = np.arange(len(x_train_100))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calculate the number of samples for 60% of the data\n",
        "train_size_20_random = int(len(x_train_100) * 0.2)\n",
        "\n",
        "# Select the shuffled indices for the 60% split\n",
        "x_train_20 = x_train_100[indices[:train_size_20_random]]\n",
        "y_train_20 = y_train_100[indices[:train_size_20_random]]\n",
        "\n"
      ],
      "metadata": {
        "id": "nhvob_QQkWzq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model\n"
      ],
      "metadata": {
        "id": "gleGdU3HkvXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary for reference\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "R36oQLIbkxWD",
        "outputId": "2cd49fca-73b8-4f20-e36b-dd3170442896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 100%"
      ],
      "metadata": {
        "id": "opm-L1rY4cVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train_100, y_train_100, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "Gq1r6hsyjq8m",
        "outputId": "822860ab-78ab-4e3a-fddd-5f2e34bd7529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 57ms/step - accuracy: 0.6056 - loss: 0.6168 - val_accuracy: 0.8753 - val_loss: 0.5164\n",
            "Epoch 2/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.8740 - loss: 0.2906 - val_accuracy: 0.9039 - val_loss: 0.3017\n",
            "Epoch 3/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.8861 - loss: 0.2572 - val_accuracy: 0.9059 - val_loss: 0.2217\n",
            "Epoch 4/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.8926 - loss: 0.2384 - val_accuracy: 0.8998 - val_loss: 0.2409\n",
            "Epoch 5/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9067 - loss: 0.2083 - val_accuracy: 0.9141 - val_loss: 0.1972\n",
            "Epoch 6/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.9144 - loss: 0.1899 - val_accuracy: 0.9121 - val_loss: 0.1517\n",
            "Epoch 7/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 0.9398 - loss: 0.1501 - val_accuracy: 0.9387 - val_loss: 0.1616\n",
            "Epoch 8/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 36ms/step - accuracy: 0.9429 - loss: 0.1425 - val_accuracy: 0.9325 - val_loss: 0.1207\n",
            "Epoch 9/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.9510 - loss: 0.1210 - val_accuracy: 0.9284 - val_loss: 0.1320\n",
            "Epoch 10/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9608 - loss: 0.1049 - val_accuracy: 0.9611 - val_loss: 0.0825\n",
            "Epoch 11/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9602 - loss: 0.1054 - val_accuracy: 0.9632 - val_loss: 0.0730\n",
            "Epoch 12/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9729 - loss: 0.0778 - val_accuracy: 0.9550 - val_loss: 0.0842\n",
            "Epoch 13/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9733 - loss: 0.0732 - val_accuracy: 0.9489 - val_loss: 0.1666\n",
            "Epoch 14/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9724 - loss: 0.0806 - val_accuracy: 0.9571 - val_loss: 0.1212\n",
            "Epoch 15/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9808 - loss: 0.0586 - val_accuracy: 0.9591 - val_loss: 0.1033\n",
            "Epoch 16/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9786 - loss: 0.0559 - val_accuracy: 0.9652 - val_loss: 0.0996\n",
            "Epoch 17/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9828 - loss: 0.0436 - val_accuracy: 0.9693 - val_loss: 0.0715\n",
            "Epoch 18/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.9850 - loss: 0.0414 - val_accuracy: 0.9611 - val_loss: 0.0882\n",
            "Epoch 19/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9861 - loss: 0.0364 - val_accuracy: 0.9571 - val_loss: 0.1517\n",
            "Epoch 20/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9843 - loss: 0.0459 - val_accuracy: 0.9673 - val_loss: 0.0836\n",
            "Epoch 21/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9842 - loss: 0.0472 - val_accuracy: 0.9734 - val_loss: 0.0544\n",
            "Epoch 22/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.9873 - loss: 0.0323 - val_accuracy: 0.9693 - val_loss: 0.1032\n",
            "Epoch 23/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9870 - loss: 0.0399 - val_accuracy: 0.9652 - val_loss: 0.1046\n",
            "Epoch 24/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.9881 - loss: 0.0311 - val_accuracy: 0.9714 - val_loss: 0.0976\n",
            "Epoch 25/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.9890 - loss: 0.0366 - val_accuracy: 0.9652 - val_loss: 0.0738\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0689\n",
            "Validation Accuracy: 0.9652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 80%"
      ],
      "metadata": {
        "id": "VcvCDYi-4e_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary for reference\n",
        "model.summary()\n",
        "model.fit(x_train_80, y_train_80, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "Z1V5p7Xjj2Co",
        "outputId": "deafe999-4591-44f8-a372-b9e681a419d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 46ms/step - accuracy: 0.5955 - loss: 0.6269 - val_accuracy: 0.8732 - val_loss: 0.5525\n",
            "Epoch 2/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.8605 - loss: 0.3147 - val_accuracy: 0.8753 - val_loss: 0.4077\n",
            "Epoch 3/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - accuracy: 0.8958 - loss: 0.2545 - val_accuracy: 0.8834 - val_loss: 0.2541\n",
            "Epoch 4/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 0.8906 - loss: 0.2474 - val_accuracy: 0.9141 - val_loss: 0.1934\n",
            "Epoch 5/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.9022 - loss: 0.2266 - val_accuracy: 0.9202 - val_loss: 0.2140\n",
            "Epoch 6/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.9063 - loss: 0.2030 - val_accuracy: 0.9264 - val_loss: 0.1810\n",
            "Epoch 7/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.9207 - loss: 0.1829 - val_accuracy: 0.9202 - val_loss: 0.1731\n",
            "Epoch 8/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.9333 - loss: 0.1573 - val_accuracy: 0.9243 - val_loss: 0.1677\n",
            "Epoch 9/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.9458 - loss: 0.1398 - val_accuracy: 0.9284 - val_loss: 0.1640\n",
            "Epoch 10/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - accuracy: 0.9471 - loss: 0.1343 - val_accuracy: 0.9366 - val_loss: 0.1345\n",
            "Epoch 11/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.9551 - loss: 0.1202 - val_accuracy: 0.9489 - val_loss: 0.1431\n",
            "Epoch 12/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.9650 - loss: 0.0977 - val_accuracy: 0.9632 - val_loss: 0.1031\n",
            "Epoch 13/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9713 - loss: 0.0723 - val_accuracy: 0.9509 - val_loss: 0.1169\n",
            "Epoch 14/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 0.9782 - loss: 0.0609 - val_accuracy: 0.9427 - val_loss: 0.1530\n",
            "Epoch 15/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.9785 - loss: 0.0620 - val_accuracy: 0.9509 - val_loss: 0.1041\n",
            "Epoch 16/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9839 - loss: 0.0537 - val_accuracy: 0.9387 - val_loss: 0.1888\n",
            "Epoch 17/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9784 - loss: 0.0567 - val_accuracy: 0.9489 - val_loss: 0.1165\n",
            "Epoch 18/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9897 - loss: 0.0306 - val_accuracy: 0.9284 - val_loss: 0.1721\n",
            "Epoch 19/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 0.9780 - loss: 0.0532 - val_accuracy: 0.9611 - val_loss: 0.1249\n",
            "Epoch 20/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9898 - loss: 0.0301 - val_accuracy: 0.9714 - val_loss: 0.0914\n",
            "Epoch 21/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9885 - loss: 0.0324 - val_accuracy: 0.9673 - val_loss: 0.1135\n",
            "Epoch 22/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9863 - loss: 0.0422 - val_accuracy: 0.9652 - val_loss: 0.0853\n",
            "Epoch 23/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9870 - loss: 0.0420 - val_accuracy: 0.9652 - val_loss: 0.1349\n",
            "Epoch 24/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - accuracy: 0.9942 - loss: 0.0208 - val_accuracy: 0.9816 - val_loss: 0.0677\n",
            "Epoch 25/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9894 - loss: 0.0350 - val_accuracy: 0.9652 - val_loss: 0.0971\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9652 - loss: 0.0774\n",
            "Validation Accuracy: 0.9652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 60%"
      ],
      "metadata": {
        "id": "Nqguxm-p4gov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary for reference\n",
        "model.summary()\n",
        "model.fit(x_train_60, y_train_60, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy_60 = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy_60:.4f}')"
      ],
      "metadata": {
        "id": "8bgEkeFxkFyO",
        "outputId": "82819869-5f20-4fbe-cc4e-27f65c7d2f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_16 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_17 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_8                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_8                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.5657 - loss: 0.6483 - val_accuracy: 0.7403 - val_loss: 0.5940\n",
            "Epoch 2/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.8546 - loss: 0.3233 - val_accuracy: 0.8855 - val_loss: 0.4835\n",
            "Epoch 3/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.8850 - loss: 0.2673 - val_accuracy: 0.9121 - val_loss: 0.3570\n",
            "Epoch 4/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.8899 - loss: 0.2563 - val_accuracy: 0.9182 - val_loss: 0.2335\n",
            "Epoch 5/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.8950 - loss: 0.2510 - val_accuracy: 0.9182 - val_loss: 0.2158\n",
            "Epoch 6/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.9087 - loss: 0.2193 - val_accuracy: 0.8753 - val_loss: 0.2807\n",
            "Epoch 7/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9025 - loss: 0.2176 - val_accuracy: 0.9121 - val_loss: 0.2072\n",
            "Epoch 8/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.9139 - loss: 0.1979 - val_accuracy: 0.9059 - val_loss: 0.2143\n",
            "Epoch 9/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9190 - loss: 0.1920 - val_accuracy: 0.8998 - val_loss: 0.2252\n",
            "Epoch 10/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9015 - loss: 0.2113 - val_accuracy: 0.9162 - val_loss: 0.1714\n",
            "Epoch 11/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9314 - loss: 0.1566 - val_accuracy: 0.9284 - val_loss: 0.1697\n",
            "Epoch 12/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.9447 - loss: 0.1374 - val_accuracy: 0.8937 - val_loss: 0.2388\n",
            "Epoch 13/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9469 - loss: 0.1374 - val_accuracy: 0.9305 - val_loss: 0.1503\n",
            "Epoch 14/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.9635 - loss: 0.0899 - val_accuracy: 0.9407 - val_loss: 0.1655\n",
            "Epoch 15/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9584 - loss: 0.1070 - val_accuracy: 0.9468 - val_loss: 0.1442\n",
            "Epoch 16/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9672 - loss: 0.0904 - val_accuracy: 0.9243 - val_loss: 0.1797\n",
            "Epoch 17/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9768 - loss: 0.0634 - val_accuracy: 0.9366 - val_loss: 0.1473\n",
            "Epoch 18/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9750 - loss: 0.0684 - val_accuracy: 0.9427 - val_loss: 0.1554\n",
            "Epoch 19/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9803 - loss: 0.0561 - val_accuracy: 0.9223 - val_loss: 0.2379\n",
            "Epoch 20/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.9781 - loss: 0.0635 - val_accuracy: 0.9346 - val_loss: 0.1641\n",
            "Epoch 21/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.9762 - loss: 0.0644 - val_accuracy: 0.9509 - val_loss: 0.1692\n",
            "Epoch 22/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9838 - loss: 0.0491 - val_accuracy: 0.9448 - val_loss: 0.1782\n",
            "Epoch 23/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.9875 - loss: 0.0344 - val_accuracy: 0.9489 - val_loss: 0.1268\n",
            "Epoch 24/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9823 - loss: 0.0506 - val_accuracy: 0.9407 - val_loss: 0.2029\n",
            "Epoch 25/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9927 - loss: 0.0288 - val_accuracy: 0.9489 - val_loss: 0.1877\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9535 - loss: 0.1697\n",
            "Validation Accuracy: 0.9489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 40%"
      ],
      "metadata": {
        "id": "tf0pR68U4iPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary for reference\n",
        "model.summary()\n",
        "model.fit(x_train_40, y_train_40, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy_40 = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy_40:.4f}')\n"
      ],
      "metadata": {
        "id": "FZhjAsLgkKZf",
        "outputId": "aec30e75-82cc-4a32-e4e3-c7c8ad089716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_18 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_19 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_9                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_9                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 0.5552 - loss: 0.6811 - val_accuracy: 0.7587 - val_loss: 0.6300\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.8297 - loss: 0.3829 - val_accuracy: 0.8834 - val_loss: 0.5439\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8584 - loss: 0.3083 - val_accuracy: 0.8957 - val_loss: 0.4536\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.8870 - loss: 0.2536 - val_accuracy: 0.8487 - val_loss: 0.3885\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.9073 - loss: 0.2148 - val_accuracy: 0.9018 - val_loss: 0.3020\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.9069 - loss: 0.2133 - val_accuracy: 0.8875 - val_loss: 0.3018\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9106 - loss: 0.2024 - val_accuracy: 0.8916 - val_loss: 0.3020\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.9217 - loss: 0.1907 - val_accuracy: 0.9059 - val_loss: 0.2824\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9217 - loss: 0.1855 - val_accuracy: 0.9039 - val_loss: 0.2826\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9376 - loss: 0.1474 - val_accuracy: 0.9018 - val_loss: 0.3140\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - accuracy: 0.9141 - loss: 0.2011 - val_accuracy: 0.8875 - val_loss: 0.2922\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9183 - loss: 0.1874 - val_accuracy: 0.9039 - val_loss: 0.3165\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.9365 - loss: 0.1474 - val_accuracy: 0.8650 - val_loss: 0.4008\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - accuracy: 0.9380 - loss: 0.1513 - val_accuracy: 0.8998 - val_loss: 0.3125\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9473 - loss: 0.1362 - val_accuracy: 0.8937 - val_loss: 0.3314\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9580 - loss: 0.1127 - val_accuracy: 0.8937 - val_loss: 0.3133\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9515 - loss: 0.1333 - val_accuracy: 0.9080 - val_loss: 0.2996\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.9546 - loss: 0.1073 - val_accuracy: 0.8773 - val_loss: 0.4299\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9627 - loss: 0.0975 - val_accuracy: 0.8875 - val_loss: 0.3491\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9722 - loss: 0.0797 - val_accuracy: 0.8978 - val_loss: 0.3302\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9817 - loss: 0.0600 - val_accuracy: 0.8916 - val_loss: 0.3770\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9685 - loss: 0.0811 - val_accuracy: 0.9141 - val_loss: 0.3925\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9633 - loss: 0.0891 - val_accuracy: 0.9182 - val_loss: 0.3232\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9797 - loss: 0.0549 - val_accuracy: 0.9162 - val_loss: 0.4055\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.9821 - loss: 0.0461 - val_accuracy: 0.9039 - val_loss: 0.4010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9181 - loss: 0.3848\n",
            "Validation Accuracy: 0.9039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 20%"
      ],
      "metadata": {
        "id": "LhxS-SEE4jmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary for reference\n",
        "model.summary()\n",
        "model.fit(x_train_20, y_train_20, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy_20 = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy_20:.4f}')\n"
      ],
      "metadata": {
        "id": "fiK1u68dkOhc",
        "outputId": "c0f1d2d9-acc1-4c58-8099-04a11bf906b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_20 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_21 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_10               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_10               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.5014 - loss: 0.7008 - val_accuracy: 0.6115 - val_loss: 0.6921\n",
            "Epoch 2/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6998 - loss: 0.6010 - val_accuracy: 0.8282 - val_loss: 0.6209\n",
            "Epoch 3/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.8764 - loss: 0.3004 - val_accuracy: 0.7280 - val_loss: 0.5972\n",
            "Epoch 4/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9020 - loss: 0.2320 - val_accuracy: 0.8671 - val_loss: 0.5288\n",
            "Epoch 5/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9197 - loss: 0.2096 - val_accuracy: 0.8241 - val_loss: 0.4768\n",
            "Epoch 6/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9264 - loss: 0.1886 - val_accuracy: 0.8609 - val_loss: 0.4455\n",
            "Epoch 7/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.9387 - loss: 0.1630 - val_accuracy: 0.8384 - val_loss: 0.4008\n",
            "Epoch 8/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9567 - loss: 0.1178 - val_accuracy: 0.8282 - val_loss: 0.3784\n",
            "Epoch 9/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9418 - loss: 0.1475 - val_accuracy: 0.8057 - val_loss: 0.3913\n",
            "Epoch 10/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9375 - loss: 0.1624 - val_accuracy: 0.8425 - val_loss: 0.3468\n",
            "Epoch 11/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9571 - loss: 0.1138 - val_accuracy: 0.8139 - val_loss: 0.4220\n",
            "Epoch 12/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9445 - loss: 0.1528 - val_accuracy: 0.8344 - val_loss: 0.4075\n",
            "Epoch 13/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.9543 - loss: 0.1297 - val_accuracy: 0.8160 - val_loss: 0.5119\n",
            "Epoch 14/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9658 - loss: 0.1018 - val_accuracy: 0.8160 - val_loss: 0.6069\n",
            "Epoch 15/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9626 - loss: 0.0887 - val_accuracy: 0.8303 - val_loss: 0.5447\n",
            "Epoch 16/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9443 - loss: 0.1382 - val_accuracy: 0.8405 - val_loss: 0.5941\n",
            "Epoch 17/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.9474 - loss: 0.1267 - val_accuracy: 0.8344 - val_loss: 0.6154\n",
            "Epoch 18/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9625 - loss: 0.0884 - val_accuracy: 0.8405 - val_loss: 0.5797\n",
            "Epoch 19/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9669 - loss: 0.0994 - val_accuracy: 0.8344 - val_loss: 0.6835\n",
            "Epoch 20/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9624 - loss: 0.0923 - val_accuracy: 0.8139 - val_loss: 0.7563\n",
            "Epoch 21/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9583 - loss: 0.1024 - val_accuracy: 0.8487 - val_loss: 0.6249\n",
            "Epoch 22/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9650 - loss: 0.1102 - val_accuracy: 0.8344 - val_loss: 0.7232\n",
            "Epoch 23/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.9723 - loss: 0.0748 - val_accuracy: 0.8323 - val_loss: 0.8635\n",
            "Epoch 24/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9779 - loss: 0.0713 - val_accuracy: 0.8098 - val_loss: 1.0870\n",
            "Epoch 25/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9810 - loss: 0.0519 - val_accuracy: 0.7955 - val_loss: 1.1630\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8251 - loss: 1.1102\n",
            "Validation Accuracy: 0.7955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a plot which plots the accuracy vs the percentage of training data used\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the accuracy values for each training data percentage stored in a list\n",
        "training_data_percentages = [20, 40, 60, 80, 100]\n",
        "accuracies = [0.8262, 0.9182, 0.9530, 0.9652, 0.9652]  # Replace with your actual accuracy values\n",
        "\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(training_data_percentages, accuracies, marker='o')\n",
        "plt.xlabel('Percentage of Training Data Used')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Accuracy vs. Training Data Percentage')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-dSUVFednPSD",
        "outputId": "04cc19e4-a9a7-426f-db58-3537c798b7c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))  # Embedding layer\n",
        "model.add(LSTM(16))  # LSTM layer with 16 units\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c6SLKGoMju9",
        "outputId": "dd7994bf-97ce-4ebc-ded1-dc47a8973b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using the training data and validate on the validation set\n",
        "model.fit(train_padded, train_labels, epochs=30, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "print(f'Validation Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpjqkVnOMkKl",
        "outputId": "c75031e3-e74d-4fde-b319-c9977a1757d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9450 - loss: 0.1328 - val_accuracy: 0.9387 - val_loss: 0.1429\n",
            "Epoch 2/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9520 - loss: 0.1197 - val_accuracy: 0.9284 - val_loss: 0.1512\n",
            "Epoch 3/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9556 - loss: 0.1115 - val_accuracy: 0.9407 - val_loss: 0.1292\n",
            "Epoch 4/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9556 - loss: 0.1123 - val_accuracy: 0.9305 - val_loss: 0.1426\n",
            "Epoch 5/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9644 - loss: 0.0991 - val_accuracy: 0.9387 - val_loss: 0.1372\n",
            "Epoch 6/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9608 - loss: 0.0990 - val_accuracy: 0.9366 - val_loss: 0.1310\n",
            "Epoch 7/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9623 - loss: 0.0958 - val_accuracy: 0.9489 - val_loss: 0.1233\n",
            "Epoch 8/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.1029 - val_accuracy: 0.9407 - val_loss: 0.1163\n",
            "Epoch 9/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9665 - loss: 0.0888 - val_accuracy: 0.9509 - val_loss: 0.1183\n",
            "Epoch 10/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9645 - loss: 0.0892 - val_accuracy: 0.9489 - val_loss: 0.1129\n",
            "Epoch 11/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9703 - loss: 0.0794 - val_accuracy: 0.9550 - val_loss: 0.1097\n",
            "Epoch 12/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9720 - loss: 0.0742 - val_accuracy: 0.9468 - val_loss: 0.1205\n",
            "Epoch 13/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9716 - loss: 0.0722 - val_accuracy: 0.9468 - val_loss: 0.1317\n",
            "Epoch 14/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.0794 - val_accuracy: 0.9489 - val_loss: 0.1154\n",
            "Epoch 15/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9722 - loss: 0.0697 - val_accuracy: 0.9468 - val_loss: 0.1041\n",
            "Epoch 16/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9765 - loss: 0.0640 - val_accuracy: 0.9530 - val_loss: 0.1156\n",
            "Epoch 17/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9671 - loss: 0.0748 - val_accuracy: 0.9632 - val_loss: 0.1003\n",
            "Epoch 18/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9775 - loss: 0.0601 - val_accuracy: 0.9571 - val_loss: 0.1133\n",
            "Epoch 19/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9796 - loss: 0.0559 - val_accuracy: 0.9632 - val_loss: 0.1017\n",
            "Epoch 20/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.0575 - val_accuracy: 0.9530 - val_loss: 0.1159\n",
            "Epoch 21/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9794 - loss: 0.0543 - val_accuracy: 0.9611 - val_loss: 0.1082\n",
            "Epoch 22/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9819 - loss: 0.0511 - val_accuracy: 0.9591 - val_loss: 0.1160\n",
            "Epoch 23/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9767 - loss: 0.0588 - val_accuracy: 0.9509 - val_loss: 0.1197\n",
            "Epoch 24/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9820 - loss: 0.0474 - val_accuracy: 0.9591 - val_loss: 0.1155\n",
            "Epoch 25/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0440 - val_accuracy: 0.9611 - val_loss: 0.1068\n",
            "Epoch 26/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9808 - loss: 0.0492 - val_accuracy: 0.9591 - val_loss: 0.1127\n",
            "Epoch 27/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9822 - loss: 0.0430 - val_accuracy: 0.9632 - val_loss: 0.1095\n",
            "Epoch 28/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0460 - val_accuracy: 0.9448 - val_loss: 0.1502\n",
            "Epoch 29/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9821 - loss: 0.0444 - val_accuracy: 0.9489 - val_loss: 0.1554\n",
            "Epoch 30/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9873 - loss: 0.0386 - val_accuracy: 0.9489 - val_loss: 0.1650\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.1959\n",
            "Validation Accuracy: 0.9488752484321594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary for reference\n",
        "model.summary()\n",
        "\n",
        "# Train the model using the train set and validate on the validation set\n",
        "model.fit(train_padded, train_labels, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n94odYqLNmjj",
        "outputId": "2a17f712-4ae2-4d93-b9e3-4804a47657b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_17 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_12 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_13 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.6212 - loss: 0.6068 - val_accuracy: 0.8814 - val_loss: 0.5348\n",
            "Epoch 2/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.8650 - loss: 0.3023 - val_accuracy: 0.9039 - val_loss: 0.3002\n",
            "Epoch 3/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.8833 - loss: 0.2616 - val_accuracy: 0.8998 - val_loss: 0.2316\n",
            "Epoch 4/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.8991 - loss: 0.2358 - val_accuracy: 0.8487 - val_loss: 0.2975\n",
            "Epoch 5/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9001 - loss: 0.2201 - val_accuracy: 0.8671 - val_loss: 0.2746\n",
            "Epoch 6/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.9046 - loss: 0.2053 - val_accuracy: 0.9018 - val_loss: 0.1801\n",
            "Epoch 7/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9190 - loss: 0.1818 - val_accuracy: 0.9264 - val_loss: 0.1496\n",
            "Epoch 8/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9411 - loss: 0.1464 - val_accuracy: 0.9366 - val_loss: 0.1398\n",
            "Epoch 9/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9521 - loss: 0.1212 - val_accuracy: 0.9530 - val_loss: 0.0959\n",
            "Epoch 10/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.9597 - loss: 0.1026 - val_accuracy: 0.9652 - val_loss: 0.0833\n",
            "Epoch 11/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9607 - loss: 0.0877 - val_accuracy: 0.9611 - val_loss: 0.0795\n",
            "Epoch 12/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9733 - loss: 0.0672 - val_accuracy: 0.9673 - val_loss: 0.1292\n",
            "Epoch 13/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9692 - loss: 0.0792 - val_accuracy: 0.9489 - val_loss: 0.1700\n",
            "Epoch 14/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9743 - loss: 0.0709 - val_accuracy: 0.9673 - val_loss: 0.1104\n",
            "Epoch 15/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.9796 - loss: 0.0617 - val_accuracy: 0.9611 - val_loss: 0.1340\n",
            "Epoch 16/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9829 - loss: 0.0502 - val_accuracy: 0.9611 - val_loss: 0.1215\n",
            "Epoch 17/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9849 - loss: 0.0457 - val_accuracy: 0.9673 - val_loss: 0.1220\n",
            "Epoch 18/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.9844 - loss: 0.0406 - val_accuracy: 0.9611 - val_loss: 0.1023\n",
            "Epoch 19/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9881 - loss: 0.0363 - val_accuracy: 0.9530 - val_loss: 0.1511\n",
            "Epoch 20/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9858 - loss: 0.0366 - val_accuracy: 0.9673 - val_loss: 0.1172\n",
            "Epoch 21/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.9876 - loss: 0.0400 - val_accuracy: 0.9632 - val_loss: 0.1270\n",
            "Epoch 22/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9902 - loss: 0.0280 - val_accuracy: 0.9693 - val_loss: 0.1338\n",
            "Epoch 23/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.9896 - loss: 0.0322 - val_accuracy: 0.9571 - val_loss: 0.1732\n",
            "Epoch 24/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9892 - loss: 0.0266 - val_accuracy: 0.9571 - val_loss: 0.1714\n",
            "Epoch 25/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9915 - loss: 0.0319 - val_accuracy: 0.9755 - val_loss: 0.1267\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ef737f674f0>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfxGjdppPGSF",
        "outputId": "b11276c0-e90d-489d-9b55-4573d8fe49d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9761 - loss: 0.1209\n",
            "Validation Accuracy: 0.9755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i1_zPbQASFyX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}