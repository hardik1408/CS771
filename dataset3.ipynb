{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./datasets/train/train_text_seq.csv')\n",
    "df_valid = pd.read_csv('./datasets/valid/valid_text_seq.csv')\n",
    "\n",
    "# Extract input sequences and labels\n",
    "X_train = df_train['input_str'].values\n",
    "y_train = df_train['label'].values\n",
    "X_valid = df_valid['input_str'].values\n",
    "y_valid = df_valid['label'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the digits using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(list('0123456789'))\n",
    "\n",
    "# Convert input_str into sequences of encoded digits, removing the first three zeroes\n",
    "def encode_sequence(sequence):\n",
    "    return label_encoder.transform(list(sequence.lstrip('0')))  # Remove leading zeroes\n",
    "\n",
    "X_train_encoded = [encode_sequence(seq) for seq in X_train]\n",
    "X_valid_encoded = [encode_sequence(seq) for seq in X_valid]\n",
    "\n",
    "# Pad the sequences to ensure they all have the same length (47 in this case)\n",
    "X_train_padded = pad_sequences(X_train_encoded, maxlen=47, padding='post')\n",
    "X_valid_padded = pad_sequences(X_valid_encoded, maxlen=47, padding='post')\n",
    "\n",
    "# Convert the labels to categorical (0 or 1)\n",
    "y_train_categorical = to_categorical(y_train, num_classes=2)\n",
    "y_valid_categorical = to_categorical(y_valid, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation with different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5030674846625767\n"
     ]
    }
   ],
   "source": [
    "#apply logistic regression to the data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_padded, y_train)\n",
    "y_pred = logreg.predict(X_valid_padded)\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5787321063394683\n"
     ]
    }
   ],
   "source": [
    "#apply random forest classification on the data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_padded, y_train)\n",
    "y_pred = rf.predict(X_valid_padded)\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6053169734151329\n"
     ]
    }
   ],
   "source": [
    "#apply xgboost classification on the data after instaling xgboost\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_padded, y_train)\n",
    "y_pred = xgb.predict(X_valid_padded)\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Model - LSTM + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5036 - loss: 0.6934 - val_accuracy: 0.5153 - val_loss: 0.6904\n",
      "Epoch 2/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5623 - loss: 0.6811 - val_accuracy: 0.6728 - val_loss: 0.6239\n",
      "Epoch 3/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6435 - loss: 0.6327 - val_accuracy: 0.6871 - val_loss: 0.5825\n",
      "Epoch 4/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6793 - loss: 0.5974 - val_accuracy: 0.7137 - val_loss: 0.5529\n",
      "Epoch 5/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7035 - loss: 0.5648 - val_accuracy: 0.7485 - val_loss: 0.5163\n",
      "Epoch 6/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7231 - loss: 0.5411 - val_accuracy: 0.7587 - val_loss: 0.5110\n",
      "Epoch 7/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7251 - loss: 0.5440 - val_accuracy: 0.7730 - val_loss: 0.4855\n",
      "Epoch 8/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7498 - loss: 0.5120 - val_accuracy: 0.7914 - val_loss: 0.4783\n",
      "Epoch 9/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7496 - loss: 0.5000 - val_accuracy: 0.7771 - val_loss: 0.4702\n",
      "Epoch 10/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7653 - loss: 0.4897 - val_accuracy: 0.7710 - val_loss: 0.4579\n",
      "Epoch 11/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7714 - loss: 0.4755 - val_accuracy: 0.7894 - val_loss: 0.4708\n",
      "Epoch 12/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7690 - loss: 0.4735 - val_accuracy: 0.8098 - val_loss: 0.4392\n",
      "Epoch 13/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7859 - loss: 0.4508 - val_accuracy: 0.8016 - val_loss: 0.4346\n",
      "Epoch 14/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7798 - loss: 0.4553 - val_accuracy: 0.8057 - val_loss: 0.4256\n",
      "Epoch 15/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.4235 - val_accuracy: 0.8098 - val_loss: 0.4265\n",
      "Epoch 16/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 0.4363 - val_accuracy: 0.7975 - val_loss: 0.4372\n",
      "Epoch 17/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7935 - loss: 0.4298 - val_accuracy: 0.7975 - val_loss: 0.4290\n",
      "Epoch 18/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8053 - loss: 0.4147 - val_accuracy: 0.8119 - val_loss: 0.4129\n",
      "Epoch 19/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8097 - loss: 0.4082 - val_accuracy: 0.8057 - val_loss: 0.4031\n",
      "Epoch 20/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8045 - loss: 0.4200 - val_accuracy: 0.8180 - val_loss: 0.4052\n",
      "Epoch 21/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8143 - loss: 0.4046 - val_accuracy: 0.8078 - val_loss: 0.3992\n",
      "Epoch 22/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.3984 - val_accuracy: 0.8037 - val_loss: 0.4011\n",
      "Epoch 23/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8195 - loss: 0.3917 - val_accuracy: 0.8057 - val_loss: 0.3955\n",
      "Epoch 24/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.3958 - val_accuracy: 0.8221 - val_loss: 0.3843\n",
      "Epoch 25/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8199 - loss: 0.3968 - val_accuracy: 0.8119 - val_loss: 0.3863\n",
      "Epoch 26/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8204 - loss: 0.3875 - val_accuracy: 0.8037 - val_loss: 0.4011\n",
      "Epoch 27/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8175 - loss: 0.3872 - val_accuracy: 0.8160 - val_loss: 0.3800\n",
      "Epoch 28/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8302 - loss: 0.3877 - val_accuracy: 0.8241 - val_loss: 0.3583\n",
      "Epoch 29/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8312 - loss: 0.3755 - val_accuracy: 0.8241 - val_loss: 0.3604\n",
      "Epoch 30/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.3660 - val_accuracy: 0.8057 - val_loss: 0.3754\n",
      "Epoch 31/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8393 - loss: 0.3660 - val_accuracy: 0.8160 - val_loss: 0.3825\n",
      "Epoch 32/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.3597 - val_accuracy: 0.8180 - val_loss: 0.3859\n",
      "Epoch 33/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: 0.3623 - val_accuracy: 0.8241 - val_loss: 0.3647\n",
      "Epoch 34/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8447 - loss: 0.3488 - val_accuracy: 0.8425 - val_loss: 0.3664\n",
      "Epoch 35/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 0.3545 - val_accuracy: 0.8241 - val_loss: 0.3611\n",
      "Epoch 36/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8393 - loss: 0.3575 - val_accuracy: 0.8303 - val_loss: 0.3539\n",
      "Epoch 37/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3571 - val_accuracy: 0.8221 - val_loss: 0.3495\n",
      "Epoch 38/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8425 - loss: 0.3508 - val_accuracy: 0.8323 - val_loss: 0.3660\n",
      "Epoch 39/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8503 - loss: 0.3345 - val_accuracy: 0.8405 - val_loss: 0.3392\n",
      "Epoch 40/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8455 - loss: 0.3415 - val_accuracy: 0.8303 - val_loss: 0.3401\n",
      "Epoch 41/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8487 - loss: 0.3382 - val_accuracy: 0.8487 - val_loss: 0.3257\n",
      "Epoch 42/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: 0.3446 - val_accuracy: 0.8446 - val_loss: 0.3330\n",
      "Epoch 43/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8475 - loss: 0.3373 - val_accuracy: 0.8691 - val_loss: 0.3089\n",
      "Epoch 44/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8475 - loss: 0.3443 - val_accuracy: 0.8384 - val_loss: 0.3314\n",
      "Epoch 45/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8523 - loss: 0.3376 - val_accuracy: 0.8446 - val_loss: 0.3319\n",
      "Epoch 46/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8442 - loss: 0.3422 - val_accuracy: 0.8487 - val_loss: 0.3208\n",
      "Epoch 47/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.3270 - val_accuracy: 0.8528 - val_loss: 0.3111\n",
      "Epoch 48/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8537 - loss: 0.3309 - val_accuracy: 0.8548 - val_loss: 0.3298\n",
      "Epoch 49/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8514 - loss: 0.3254 - val_accuracy: 0.8466 - val_loss: 0.3245\n",
      "Epoch 50/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.3262 - val_accuracy: 0.8609 - val_loss: 0.3134\n",
      "Epoch 51/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3283 - val_accuracy: 0.8712 - val_loss: 0.3014\n",
      "Epoch 52/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8602 - loss: 0.3113 - val_accuracy: 0.8671 - val_loss: 0.3140\n",
      "Epoch 53/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8676 - loss: 0.3077 - val_accuracy: 0.8793 - val_loss: 0.2911\n",
      "Epoch 54/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8593 - loss: 0.3156 - val_accuracy: 0.8671 - val_loss: 0.2916\n",
      "Epoch 55/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3224 - val_accuracy: 0.8691 - val_loss: 0.3063\n",
      "Epoch 56/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8589 - loss: 0.3158 - val_accuracy: 0.8466 - val_loss: 0.3138\n",
      "Epoch 57/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8623 - loss: 0.3117 - val_accuracy: 0.8589 - val_loss: 0.2971\n",
      "Epoch 58/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 0.3059 - val_accuracy: 0.8630 - val_loss: 0.3203\n",
      "Epoch 59/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8577 - loss: 0.3165 - val_accuracy: 0.8712 - val_loss: 0.2961\n",
      "Epoch 60/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8691 - loss: 0.2990 - val_accuracy: 0.8671 - val_loss: 0.3018\n",
      "Epoch 61/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8647 - loss: 0.3046 - val_accuracy: 0.8834 - val_loss: 0.2745\n",
      "Epoch 62/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8691 - loss: 0.2964 - val_accuracy: 0.8732 - val_loss: 0.2736\n",
      "Epoch 63/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.3063 - val_accuracy: 0.8671 - val_loss: 0.2920\n",
      "Epoch 64/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.2979 - val_accuracy: 0.8650 - val_loss: 0.2900\n",
      "Epoch 65/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8710 - loss: 0.2926 - val_accuracy: 0.8569 - val_loss: 0.2950\n",
      "Epoch 66/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.3096 - val_accuracy: 0.8712 - val_loss: 0.2821\n",
      "Epoch 67/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.2922 - val_accuracy: 0.8691 - val_loss: 0.2795\n",
      "Epoch 68/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8660 - loss: 0.2902 - val_accuracy: 0.8793 - val_loss: 0.2740\n",
      "Epoch 69/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8647 - loss: 0.2960 - val_accuracy: 0.8834 - val_loss: 0.2759\n",
      "Epoch 70/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8741 - loss: 0.2922 - val_accuracy: 0.8773 - val_loss: 0.2781\n",
      "Epoch 71/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8739 - loss: 0.2844 - val_accuracy: 0.8834 - val_loss: 0.2702\n",
      "Epoch 72/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.2714 - val_accuracy: 0.8753 - val_loss: 0.2774\n",
      "Epoch 73/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8779 - loss: 0.2801 - val_accuracy: 0.8773 - val_loss: 0.2937\n",
      "Epoch 74/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.2837 - val_accuracy: 0.8691 - val_loss: 0.2808\n",
      "Epoch 75/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8852 - loss: 0.2618 - val_accuracy: 0.8712 - val_loss: 0.2790\n",
      "Epoch 76/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8747 - loss: 0.2747 - val_accuracy: 0.8834 - val_loss: 0.2620\n",
      "Epoch 77/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 0.2718 - val_accuracy: 0.8834 - val_loss: 0.2889\n",
      "Epoch 78/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8804 - loss: 0.2702 - val_accuracy: 0.8671 - val_loss: 0.2791\n",
      "Epoch 79/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.2818 - val_accuracy: 0.8773 - val_loss: 0.2732\n",
      "Epoch 80/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.2712 - val_accuracy: 0.8793 - val_loss: 0.2665\n",
      "Epoch 81/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8792 - loss: 0.2690 - val_accuracy: 0.8957 - val_loss: 0.2591\n",
      "Epoch 82/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.2722 - val_accuracy: 0.8691 - val_loss: 0.2686\n",
      "Epoch 83/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8786 - loss: 0.2810 - val_accuracy: 0.8712 - val_loss: 0.2892\n",
      "Epoch 84/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8811 - loss: 0.2691 - val_accuracy: 0.8834 - val_loss: 0.2619\n",
      "Epoch 85/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8776 - loss: 0.2779 - val_accuracy: 0.8875 - val_loss: 0.2568\n",
      "Epoch 86/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.2653 - val_accuracy: 0.8773 - val_loss: 0.2827\n",
      "Epoch 87/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8779 - loss: 0.2748 - val_accuracy: 0.8834 - val_loss: 0.2871\n",
      "Epoch 88/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.2752 - val_accuracy: 0.8875 - val_loss: 0.2785\n",
      "Epoch 89/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8818 - loss: 0.2696 - val_accuracy: 0.8773 - val_loss: 0.2806\n",
      "Epoch 90/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.2679 - val_accuracy: 0.8732 - val_loss: 0.2897\n",
      "Epoch 91/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8861 - loss: 0.2670 - val_accuracy: 0.8896 - val_loss: 0.2733\n",
      "Epoch 92/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.2652 - val_accuracy: 0.8753 - val_loss: 0.2833\n",
      "Epoch 93/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.2565 - val_accuracy: 0.8793 - val_loss: 0.2772\n",
      "Epoch 94/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8900 - loss: 0.2523 - val_accuracy: 0.8834 - val_loss: 0.2556\n",
      "Epoch 95/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.2532 - val_accuracy: 0.8814 - val_loss: 0.2641\n",
      "Epoch 96/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8720 - loss: 0.2685 - val_accuracy: 0.8814 - val_loss: 0.2614\n",
      "Epoch 97/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.2521 - val_accuracy: 0.8834 - val_loss: 0.2785\n",
      "Epoch 98/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2508 - val_accuracy: 0.8978 - val_loss: 0.2546\n",
      "Epoch 99/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2551 - val_accuracy: 0.8937 - val_loss: 0.2640\n",
      "Epoch 100/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.2501 - val_accuracy: 0.8691 - val_loss: 0.2561\n",
      "Epoch 101/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.2533 - val_accuracy: 0.8875 - val_loss: 0.2552\n",
      "Epoch 102/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8932 - loss: 0.2499 - val_accuracy: 0.8957 - val_loss: 0.2568\n",
      "Epoch 103/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2517 - val_accuracy: 0.8896 - val_loss: 0.2561\n",
      "Epoch 104/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.2479 - val_accuracy: 0.8916 - val_loss: 0.2593\n",
      "Epoch 105/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 0.2444 - val_accuracy: 0.8937 - val_loss: 0.2611\n",
      "Epoch 106/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.2589 - val_accuracy: 0.8916 - val_loss: 0.2564\n",
      "Epoch 107/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.2410 - val_accuracy: 0.8916 - val_loss: 0.2604\n",
      "Epoch 108/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.2511 - val_accuracy: 0.8773 - val_loss: 0.2465\n",
      "Epoch 109/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.2407 - val_accuracy: 0.8793 - val_loss: 0.2636\n",
      "Epoch 110/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.2518 - val_accuracy: 0.8916 - val_loss: 0.2599\n",
      "Epoch 111/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.2361 - val_accuracy: 0.8978 - val_loss: 0.2677\n",
      "Epoch 112/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 0.2435 - val_accuracy: 0.8875 - val_loss: 0.2580\n",
      "Epoch 113/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.2424 - val_accuracy: 0.8875 - val_loss: 0.2436\n",
      "Epoch 114/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8921 - loss: 0.2464 - val_accuracy: 0.9080 - val_loss: 0.2413\n",
      "Epoch 115/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.2350 - val_accuracy: 0.8875 - val_loss: 0.2484\n",
      "Epoch 116/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.2418 - val_accuracy: 0.8916 - val_loss: 0.2349\n",
      "Epoch 117/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8960 - loss: 0.2366 - val_accuracy: 0.8875 - val_loss: 0.2604\n",
      "Epoch 118/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.2323 - val_accuracy: 0.8916 - val_loss: 0.2445\n",
      "Epoch 119/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8912 - loss: 0.2425 - val_accuracy: 0.8773 - val_loss: 0.2629\n",
      "Epoch 120/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8981 - loss: 0.2392 - val_accuracy: 0.8814 - val_loss: 0.2587\n",
      "Epoch 121/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9006 - loss: 0.2299 - val_accuracy: 0.9018 - val_loss: 0.2445\n",
      "Epoch 122/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8933 - loss: 0.2489 - val_accuracy: 0.8998 - val_loss: 0.2437\n",
      "Epoch 123/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.2363 - val_accuracy: 0.8814 - val_loss: 0.2436\n",
      "Epoch 124/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.2354 - val_accuracy: 0.8978 - val_loss: 0.2435\n",
      "Epoch 125/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.2433 - val_accuracy: 0.8896 - val_loss: 0.2440\n",
      "Epoch 126/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.2361 - val_accuracy: 0.8875 - val_loss: 0.2575\n",
      "Epoch 127/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2373 - val_accuracy: 0.8793 - val_loss: 0.2667\n",
      "Epoch 128/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.2278 - val_accuracy: 0.8793 - val_loss: 0.2527\n",
      "Epoch 129/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8995 - loss: 0.2382 - val_accuracy: 0.8957 - val_loss: 0.2557\n",
      "Epoch 130/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9032 - loss: 0.2271 - val_accuracy: 0.8957 - val_loss: 0.2386\n",
      "Epoch 131/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8990 - loss: 0.2328 - val_accuracy: 0.9039 - val_loss: 0.2509\n",
      "Epoch 132/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.2178 - val_accuracy: 0.9039 - val_loss: 0.2407\n",
      "Epoch 133/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8987 - loss: 0.2382 - val_accuracy: 0.8916 - val_loss: 0.2422\n",
      "Epoch 134/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.2274 - val_accuracy: 0.8753 - val_loss: 0.2625\n",
      "Epoch 135/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.2163 - val_accuracy: 0.8937 - val_loss: 0.2475\n",
      "Epoch 136/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9012 - loss: 0.2364 - val_accuracy: 0.8998 - val_loss: 0.2799\n",
      "Epoch 137/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9012 - loss: 0.2253 - val_accuracy: 0.8671 - val_loss: 0.2597\n",
      "Epoch 138/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.2294 - val_accuracy: 0.8834 - val_loss: 0.2501\n",
      "Epoch 139/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9033 - loss: 0.2249 - val_accuracy: 0.8937 - val_loss: 0.2522\n",
      "Epoch 140/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9057 - loss: 0.2279 - val_accuracy: 0.8793 - val_loss: 0.2618\n",
      "Epoch 141/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9005 - loss: 0.2298 - val_accuracy: 0.8753 - val_loss: 0.2527\n",
      "Epoch 142/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.2279 - val_accuracy: 0.8834 - val_loss: 0.2419\n",
      "Epoch 143/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.2199 - val_accuracy: 0.8834 - val_loss: 0.2511\n",
      "Epoch 144/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9068 - loss: 0.2234 - val_accuracy: 0.8773 - val_loss: 0.2461\n",
      "Epoch 145/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.2290 - val_accuracy: 0.8875 - val_loss: 0.2694\n",
      "Epoch 146/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.2300 - val_accuracy: 0.8978 - val_loss: 0.2448\n",
      "Epoch 147/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.2197 - val_accuracy: 0.8773 - val_loss: 0.2452\n",
      "Epoch 148/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9064 - loss: 0.2172 - val_accuracy: 0.8998 - val_loss: 0.2450\n",
      "Epoch 149/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.2114 - val_accuracy: 0.8793 - val_loss: 0.2535\n",
      "Epoch 150/150\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.2242 - val_accuracy: 0.9080 - val_loss: 0.2499\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9007 - loss: 0.2396\n",
      "Validation Loss: 0.2498711496591568, Validation Accuracy: 0.907975435256958\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(X_train_padded)\n",
    "indices = np.arange(total_samples)\n",
    "np.random.shuffle(indices)\n",
    "train_size_80_random = int(total_samples* 0.8)\n",
    "X_train_80 = X_train_padded[:train_size_80_random]\n",
    "y_train_80 = y_train_categorical[:train_size_80_random]\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10, output_dim=12, input_length=47))  # Embedding layer with output_dim=12\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))  # Convolutional layer with 32 filters\n",
    "model.add(MaxPooling1D(pool_size=2))  # Max pooling layer\n",
    "model.add(Dropout(0.3))  # Dropout layer\n",
    "model.add(LSTM(24, return_sequences=False))  # LSTM layer with 24 units\n",
    "model.add(Dense(32, activation='relu'))  # Dense layer with 32 units\n",
    "model.add(Dense(2, activation='softmax'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_padded, y_train_categorical, \n",
    "          validation_data=(X_valid_padded, y_valid_categorical), \n",
    "          epochs=150, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_valid_padded, y_valid_categorical)\n",
    "print(f'Validation Loss: {loss}, Validation Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,184</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m12\u001b[0m)         │           \u001b[38;5;34m120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m1,184\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m5,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,928</span> (89.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,928\u001b[0m (89.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,642</span> (29.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,642\u001b[0m (29.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,286</span> (59.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m15,286\u001b[0m (59.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/dataset3.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using 80%, 60%, 40%, 20% of dataset to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model using 80% of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4981 - loss: 0.6939 - val_accuracy: 0.5174 - val_loss: 0.6916\n",
      "Epoch 2/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5497 - loss: 0.6843 - val_accuracy: 0.6524 - val_loss: 0.6301\n",
      "Epoch 3/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6273 - loss: 0.6390 - val_accuracy: 0.6871 - val_loss: 0.6120\n",
      "Epoch 4/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6363 - loss: 0.6337 - val_accuracy: 0.6892 - val_loss: 0.5940\n",
      "Epoch 5/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6681 - loss: 0.6117 - val_accuracy: 0.7137 - val_loss: 0.5786\n",
      "Epoch 6/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6837 - loss: 0.5918 - val_accuracy: 0.7198 - val_loss: 0.5620\n",
      "Epoch 7/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.5728 - val_accuracy: 0.7301 - val_loss: 0.5567\n",
      "Epoch 8/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7138 - loss: 0.5583 - val_accuracy: 0.7321 - val_loss: 0.5468\n",
      "Epoch 9/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7122 - loss: 0.5532 - val_accuracy: 0.7464 - val_loss: 0.5342\n",
      "Epoch 10/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.5532 - val_accuracy: 0.7382 - val_loss: 0.5323\n",
      "Epoch 11/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.5288 - val_accuracy: 0.7546 - val_loss: 0.5113\n",
      "Epoch 12/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7473 - loss: 0.5203 - val_accuracy: 0.7566 - val_loss: 0.5054\n",
      "Epoch 13/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7509 - loss: 0.5061 - val_accuracy: 0.7587 - val_loss: 0.4957\n",
      "Epoch 14/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7622 - loss: 0.4862 - val_accuracy: 0.7566 - val_loss: 0.4816\n",
      "Epoch 15/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7484 - loss: 0.4897 - val_accuracy: 0.7894 - val_loss: 0.4634\n",
      "Epoch 16/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7745 - loss: 0.4611 - val_accuracy: 0.7669 - val_loss: 0.4781\n",
      "Epoch 17/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7661 - loss: 0.4760 - val_accuracy: 0.8037 - val_loss: 0.4541\n",
      "Epoch 18/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7792 - loss: 0.4554 - val_accuracy: 0.7996 - val_loss: 0.4514\n",
      "Epoch 19/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.4525 - val_accuracy: 0.7935 - val_loss: 0.4493\n",
      "Epoch 20/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7889 - loss: 0.4622 - val_accuracy: 0.7771 - val_loss: 0.4492\n",
      "Epoch 21/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8041 - loss: 0.4269 - val_accuracy: 0.7996 - val_loss: 0.4255\n",
      "Epoch 22/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7948 - loss: 0.4428 - val_accuracy: 0.7955 - val_loss: 0.4286\n",
      "Epoch 23/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7962 - loss: 0.4373 - val_accuracy: 0.8098 - val_loss: 0.4121\n",
      "Epoch 24/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7969 - loss: 0.4348 - val_accuracy: 0.8098 - val_loss: 0.4091\n",
      "Epoch 25/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8045 - loss: 0.4208 - val_accuracy: 0.8098 - val_loss: 0.4125\n",
      "Epoch 26/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.4121 - val_accuracy: 0.8078 - val_loss: 0.4030\n",
      "Epoch 27/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.4161 - val_accuracy: 0.8078 - val_loss: 0.4103\n",
      "Epoch 28/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.4048 - val_accuracy: 0.8139 - val_loss: 0.3983\n",
      "Epoch 29/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8286 - loss: 0.3851 - val_accuracy: 0.8139 - val_loss: 0.3906\n",
      "Epoch 30/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.3890 - val_accuracy: 0.8282 - val_loss: 0.3857\n",
      "Epoch 31/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.3903 - val_accuracy: 0.8323 - val_loss: 0.3864\n",
      "Epoch 32/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8215 - loss: 0.3849 - val_accuracy: 0.8364 - val_loss: 0.3694\n",
      "Epoch 33/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.3700 - val_accuracy: 0.8160 - val_loss: 0.3765\n",
      "Epoch 34/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.3817 - val_accuracy: 0.8425 - val_loss: 0.3658\n",
      "Epoch 35/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3727 - val_accuracy: 0.8384 - val_loss: 0.3652\n",
      "Epoch 36/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3627 - val_accuracy: 0.8282 - val_loss: 0.3668\n",
      "Epoch 37/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.3816 - val_accuracy: 0.8364 - val_loss: 0.3676\n",
      "Epoch 38/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8231 - loss: 0.3897 - val_accuracy: 0.8344 - val_loss: 0.3529\n",
      "Epoch 39/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8317 - loss: 0.3716 - val_accuracy: 0.8364 - val_loss: 0.3604\n",
      "Epoch 40/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3618 - val_accuracy: 0.8303 - val_loss: 0.3530\n",
      "Epoch 41/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8387 - loss: 0.3520 - val_accuracy: 0.8446 - val_loss: 0.3629\n",
      "Epoch 42/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3507 - val_accuracy: 0.8323 - val_loss: 0.3645\n",
      "Epoch 43/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8478 - loss: 0.3348 - val_accuracy: 0.8425 - val_loss: 0.3432\n",
      "Epoch 44/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.3531 - val_accuracy: 0.8303 - val_loss: 0.3542\n",
      "Epoch 45/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8449 - loss: 0.3464 - val_accuracy: 0.8282 - val_loss: 0.3448\n",
      "Epoch 46/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.3520 - val_accuracy: 0.8364 - val_loss: 0.3559\n",
      "Epoch 47/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3442 - val_accuracy: 0.8303 - val_loss: 0.3476\n",
      "Epoch 48/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8533 - loss: 0.3330 - val_accuracy: 0.8344 - val_loss: 0.3394\n",
      "Epoch 49/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8458 - loss: 0.3424 - val_accuracy: 0.8344 - val_loss: 0.3425\n",
      "Epoch 50/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.3318 - val_accuracy: 0.8405 - val_loss: 0.3408\n",
      "Epoch 51/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8472 - loss: 0.3289 - val_accuracy: 0.8282 - val_loss: 0.3459\n",
      "Epoch 52/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.3269 - val_accuracy: 0.8528 - val_loss: 0.3473\n",
      "Epoch 53/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.3361 - val_accuracy: 0.8487 - val_loss: 0.3292\n",
      "Epoch 54/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8521 - loss: 0.3321 - val_accuracy: 0.8364 - val_loss: 0.3358\n",
      "Epoch 55/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8418 - loss: 0.3435 - val_accuracy: 0.8425 - val_loss: 0.3343\n",
      "Epoch 56/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8553 - loss: 0.3405 - val_accuracy: 0.8569 - val_loss: 0.3318\n",
      "Epoch 57/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8473 - loss: 0.3340 - val_accuracy: 0.8446 - val_loss: 0.3323\n",
      "Epoch 58/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3469 - val_accuracy: 0.8487 - val_loss: 0.3330\n",
      "Epoch 59/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.3280 - val_accuracy: 0.8425 - val_loss: 0.3445\n",
      "Epoch 60/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8641 - loss: 0.3067 - val_accuracy: 0.8344 - val_loss: 0.3226\n",
      "Epoch 61/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.3347 - val_accuracy: 0.8344 - val_loss: 0.3293\n",
      "Epoch 62/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8496 - loss: 0.3166 - val_accuracy: 0.8282 - val_loss: 0.3380\n",
      "Epoch 63/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3269 - val_accuracy: 0.8425 - val_loss: 0.3371\n",
      "Epoch 64/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.3167 - val_accuracy: 0.8425 - val_loss: 0.3279\n",
      "Epoch 65/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8551 - loss: 0.3188 - val_accuracy: 0.8262 - val_loss: 0.3395\n",
      "Epoch 66/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8680 - loss: 0.3152 - val_accuracy: 0.8569 - val_loss: 0.3109\n",
      "Epoch 67/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8575 - loss: 0.3215 - val_accuracy: 0.8466 - val_loss: 0.3350\n",
      "Epoch 68/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8611 - loss: 0.3200 - val_accuracy: 0.8548 - val_loss: 0.3185\n",
      "Epoch 69/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8590 - loss: 0.3071 - val_accuracy: 0.8425 - val_loss: 0.3216\n",
      "Epoch 70/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8544 - loss: 0.3134 - val_accuracy: 0.8303 - val_loss: 0.3431\n",
      "Epoch 71/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.3151 - val_accuracy: 0.8425 - val_loss: 0.3366\n",
      "Epoch 72/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8615 - loss: 0.3161 - val_accuracy: 0.8262 - val_loss: 0.3278\n",
      "Epoch 73/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8632 - loss: 0.3088 - val_accuracy: 0.8589 - val_loss: 0.3153\n",
      "Epoch 74/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8575 - loss: 0.3113 - val_accuracy: 0.8405 - val_loss: 0.3123\n",
      "Epoch 75/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8578 - loss: 0.3122 - val_accuracy: 0.8364 - val_loss: 0.3188\n",
      "Epoch 76/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 0.3071 - val_accuracy: 0.8405 - val_loss: 0.3217\n",
      "Epoch 77/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.2934 - val_accuracy: 0.8241 - val_loss: 0.3377\n",
      "Epoch 78/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8674 - loss: 0.3124 - val_accuracy: 0.8507 - val_loss: 0.3229\n",
      "Epoch 79/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8623 - loss: 0.3015 - val_accuracy: 0.8364 - val_loss: 0.3279\n",
      "Epoch 80/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.3144 - val_accuracy: 0.8507 - val_loss: 0.3050\n",
      "Epoch 81/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8624 - loss: 0.3018 - val_accuracy: 0.8466 - val_loss: 0.3148\n",
      "Epoch 82/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.2947 - val_accuracy: 0.8548 - val_loss: 0.3128\n",
      "Epoch 83/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.2900 - val_accuracy: 0.8384 - val_loss: 0.3177\n",
      "Epoch 84/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.3059 - val_accuracy: 0.8548 - val_loss: 0.3001\n",
      "Epoch 85/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8726 - loss: 0.2887 - val_accuracy: 0.8466 - val_loss: 0.3194\n",
      "Epoch 86/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8522 - loss: 0.3102 - val_accuracy: 0.8425 - val_loss: 0.3098\n",
      "Epoch 87/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.2907 - val_accuracy: 0.8466 - val_loss: 0.3207\n",
      "Epoch 88/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8660 - loss: 0.3025 - val_accuracy: 0.8507 - val_loss: 0.3040\n",
      "Epoch 89/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8614 - loss: 0.3057 - val_accuracy: 0.8507 - val_loss: 0.2981\n",
      "Epoch 90/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8663 - loss: 0.3067 - val_accuracy: 0.8609 - val_loss: 0.3000\n",
      "Epoch 91/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8715 - loss: 0.2863 - val_accuracy: 0.8528 - val_loss: 0.2974\n",
      "Epoch 92/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8778 - loss: 0.2797 - val_accuracy: 0.8569 - val_loss: 0.3054\n",
      "Epoch 93/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.2929 - val_accuracy: 0.8507 - val_loss: 0.3094\n",
      "Epoch 94/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.2713 - val_accuracy: 0.8466 - val_loss: 0.2974\n",
      "Epoch 95/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.3104 - val_accuracy: 0.8487 - val_loss: 0.2991\n",
      "Epoch 96/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8754 - loss: 0.2820 - val_accuracy: 0.8548 - val_loss: 0.2996\n",
      "Epoch 97/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8703 - loss: 0.2824 - val_accuracy: 0.8507 - val_loss: 0.3151\n",
      "Epoch 98/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8710 - loss: 0.2900 - val_accuracy: 0.8650 - val_loss: 0.3001\n",
      "Epoch 99/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8656 - loss: 0.2970 - val_accuracy: 0.8630 - val_loss: 0.3068\n",
      "Epoch 100/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.2885 - val_accuracy: 0.8732 - val_loss: 0.2938\n",
      "Epoch 101/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.2791 - val_accuracy: 0.8569 - val_loss: 0.2911\n",
      "Epoch 102/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.2705 - val_accuracy: 0.8589 - val_loss: 0.3084\n",
      "Epoch 103/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8894 - loss: 0.2639 - val_accuracy: 0.8609 - val_loss: 0.2959\n",
      "Epoch 104/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.2809 - val_accuracy: 0.8569 - val_loss: 0.2994\n",
      "Epoch 105/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.2841 - val_accuracy: 0.8630 - val_loss: 0.3057\n",
      "Epoch 106/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2710 - val_accuracy: 0.8589 - val_loss: 0.2945\n",
      "Epoch 107/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.2804 - val_accuracy: 0.8528 - val_loss: 0.2958\n",
      "Epoch 108/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.2703 - val_accuracy: 0.8753 - val_loss: 0.2899\n",
      "Epoch 109/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.2671 - val_accuracy: 0.8732 - val_loss: 0.2952\n",
      "Epoch 110/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.2879 - val_accuracy: 0.8589 - val_loss: 0.2920\n",
      "Epoch 111/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8851 - loss: 0.2565 - val_accuracy: 0.8691 - val_loss: 0.2914\n",
      "Epoch 112/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8745 - loss: 0.2841 - val_accuracy: 0.8691 - val_loss: 0.3080\n",
      "Epoch 113/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8748 - loss: 0.2772 - val_accuracy: 0.8630 - val_loss: 0.2930\n",
      "Epoch 114/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8817 - loss: 0.2659 - val_accuracy: 0.8732 - val_loss: 0.2917\n",
      "Epoch 115/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.2608 - val_accuracy: 0.8753 - val_loss: 0.2933\n",
      "Epoch 116/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8952 - loss: 0.2499 - val_accuracy: 0.8671 - val_loss: 0.2949\n",
      "Epoch 117/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8823 - loss: 0.2695 - val_accuracy: 0.8609 - val_loss: 0.3189\n",
      "Epoch 118/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8760 - loss: 0.2806 - val_accuracy: 0.8712 - val_loss: 0.3007\n",
      "Epoch 119/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.2734 - val_accuracy: 0.8691 - val_loss: 0.2935\n",
      "Epoch 120/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8857 - loss: 0.2674 - val_accuracy: 0.8732 - val_loss: 0.2961\n",
      "Epoch 121/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.2574 - val_accuracy: 0.8589 - val_loss: 0.3001\n",
      "Epoch 122/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8862 - loss: 0.2717 - val_accuracy: 0.8609 - val_loss: 0.2973\n",
      "Epoch 123/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.2581 - val_accuracy: 0.8671 - val_loss: 0.2852\n",
      "Epoch 124/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.2624 - val_accuracy: 0.8609 - val_loss: 0.2952\n",
      "Epoch 125/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8890 - loss: 0.2645 - val_accuracy: 0.8753 - val_loss: 0.2819\n",
      "Epoch 126/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.2692 - val_accuracy: 0.8609 - val_loss: 0.2906\n",
      "Epoch 127/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.2517 - val_accuracy: 0.8712 - val_loss: 0.2985\n",
      "Epoch 128/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.2530 - val_accuracy: 0.8753 - val_loss: 0.2806\n",
      "Epoch 129/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.2711 - val_accuracy: 0.8650 - val_loss: 0.3031\n",
      "Epoch 130/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.2559 - val_accuracy: 0.8814 - val_loss: 0.2821\n",
      "Epoch 131/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.2534 - val_accuracy: 0.8793 - val_loss: 0.2887\n",
      "Epoch 132/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2683 - val_accuracy: 0.8793 - val_loss: 0.2822\n",
      "Epoch 133/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.2361 - val_accuracy: 0.8630 - val_loss: 0.3016\n",
      "Epoch 134/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.2504 - val_accuracy: 0.8630 - val_loss: 0.3012\n",
      "Epoch 135/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2525 - val_accuracy: 0.8732 - val_loss: 0.2979\n",
      "Epoch 136/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8904 - loss: 0.2472 - val_accuracy: 0.8609 - val_loss: 0.3000\n",
      "Epoch 137/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.2541 - val_accuracy: 0.8814 - val_loss: 0.2861\n",
      "Epoch 138/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8928 - loss: 0.2569 - val_accuracy: 0.8753 - val_loss: 0.2857\n",
      "Epoch 139/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.2426 - val_accuracy: 0.8773 - val_loss: 0.2939\n",
      "Epoch 140/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8911 - loss: 0.2465 - val_accuracy: 0.8855 - val_loss: 0.2910\n",
      "Epoch 141/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.2409 - val_accuracy: 0.8732 - val_loss: 0.2915\n",
      "Epoch 142/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.2441 - val_accuracy: 0.8793 - val_loss: 0.2954\n",
      "Epoch 143/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2440 - val_accuracy: 0.8753 - val_loss: 0.2813\n",
      "Epoch 144/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.2325 - val_accuracy: 0.8609 - val_loss: 0.2817\n",
      "Epoch 145/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2363 - val_accuracy: 0.8834 - val_loss: 0.2829\n",
      "Epoch 146/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8920 - loss: 0.2444 - val_accuracy: 0.8937 - val_loss: 0.2763\n",
      "Epoch 147/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.2616 - val_accuracy: 0.8855 - val_loss: 0.2925\n",
      "Epoch 148/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.2410 - val_accuracy: 0.8773 - val_loss: 0.2912\n",
      "Epoch 149/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.2410 - val_accuracy: 0.8753 - val_loss: 0.2859\n",
      "Epoch 150/150\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.2551 - val_accuracy: 0.8773 - val_loss: 0.2833\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.8835 - loss: 0.2598\n",
      "Validation Loss: 0.28330856561660767, Validation Accuracy: 0.8773006200790405\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(X_train_padded)\n",
    "indices = np.arange(total_samples)\n",
    "np.random.shuffle(indices)\n",
    "train_size_80_random = int(total_samples* 0.8)\n",
    "X_train_80 = X_train_padded[:train_size_80_random]\n",
    "y_train_80 = y_train_categorical[:train_size_80_random]\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10, output_dim=12, input_length=47))  # Embedding layer with output_dim=12\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))  # Convolutional layer with 32 filters\n",
    "model.add(MaxPooling1D(pool_size=2))  # Max pooling layer\n",
    "model.add(Dropout(0.3))  # Dropout layer\n",
    "model.add(LSTM(24, return_sequences=False))  # LSTM layer with 24 units\n",
    "model.add(Dense(32, activation='relu'))  # Dense layer with 32 units\n",
    "model.add(Dense(2, activation='softmax'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_80, y_train_80, \n",
    "          validation_data=(X_valid_padded, y_valid_categorical), \n",
    "          epochs=150, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy80 = model.evaluate(X_valid_padded, y_valid_categorical)\n",
    "print(f'Validation Loss: {loss}, Validation Accuracy: {accuracy80}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model using 60% of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4998 - loss: 0.6936 - val_accuracy: 0.5174 - val_loss: 0.6917\n",
      "Epoch 2/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5380 - loss: 0.6911 - val_accuracy: 0.6769 - val_loss: 0.6367\n",
      "Epoch 3/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6130 - loss: 0.6516 - val_accuracy: 0.6769 - val_loss: 0.6135\n",
      "Epoch 4/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6498 - loss: 0.6339 - val_accuracy: 0.7014 - val_loss: 0.6010\n",
      "Epoch 5/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6578 - loss: 0.6147 - val_accuracy: 0.6953 - val_loss: 0.5945\n",
      "Epoch 6/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6747 - loss: 0.6067 - val_accuracy: 0.7178 - val_loss: 0.5625\n",
      "Epoch 7/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6925 - loss: 0.5904 - val_accuracy: 0.7342 - val_loss: 0.5545\n",
      "Epoch 8/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6988 - loss: 0.5698 - val_accuracy: 0.7587 - val_loss: 0.5294\n",
      "Epoch 9/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7107 - loss: 0.5570 - val_accuracy: 0.7260 - val_loss: 0.5253\n",
      "Epoch 10/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7134 - loss: 0.5525 - val_accuracy: 0.7628 - val_loss: 0.5127\n",
      "Epoch 11/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7224 - loss: 0.5411 - val_accuracy: 0.7566 - val_loss: 0.5028\n",
      "Epoch 12/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7276 - loss: 0.5274 - val_accuracy: 0.7710 - val_loss: 0.4903\n",
      "Epoch 13/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7560 - loss: 0.5083 - val_accuracy: 0.7546 - val_loss: 0.4881\n",
      "Epoch 14/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7632 - loss: 0.4944 - val_accuracy: 0.7730 - val_loss: 0.4701\n",
      "Epoch 15/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7704 - loss: 0.4857 - val_accuracy: 0.7689 - val_loss: 0.4740\n",
      "Epoch 16/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7612 - loss: 0.4774 - val_accuracy: 0.7710 - val_loss: 0.4671\n",
      "Epoch 17/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.4791 - val_accuracy: 0.7587 - val_loss: 0.5006\n",
      "Epoch 18/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7609 - loss: 0.4755 - val_accuracy: 0.7873 - val_loss: 0.4514\n",
      "Epoch 19/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7716 - loss: 0.4605 - val_accuracy: 0.7894 - val_loss: 0.4448\n",
      "Epoch 20/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7919 - loss: 0.4411 - val_accuracy: 0.7894 - val_loss: 0.4485\n",
      "Epoch 21/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7477 - loss: 0.4830 - val_accuracy: 0.7894 - val_loss: 0.4498\n",
      "Epoch 22/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7818 - loss: 0.4587 - val_accuracy: 0.7832 - val_loss: 0.4536\n",
      "Epoch 23/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.4287 - val_accuracy: 0.8037 - val_loss: 0.4296\n",
      "Epoch 24/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7967 - loss: 0.4223 - val_accuracy: 0.7975 - val_loss: 0.4340\n",
      "Epoch 25/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8025 - loss: 0.4261 - val_accuracy: 0.8139 - val_loss: 0.4287\n",
      "Epoch 26/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.4229 - val_accuracy: 0.7894 - val_loss: 0.4428\n",
      "Epoch 27/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7970 - loss: 0.4261 - val_accuracy: 0.8200 - val_loss: 0.4274\n",
      "Epoch 28/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7967 - loss: 0.4261 - val_accuracy: 0.8016 - val_loss: 0.4293\n",
      "Epoch 29/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.4076 - val_accuracy: 0.8057 - val_loss: 0.4260\n",
      "Epoch 30/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8085 - loss: 0.4185 - val_accuracy: 0.7955 - val_loss: 0.4204\n",
      "Epoch 31/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 0.4121 - val_accuracy: 0.8098 - val_loss: 0.4169\n",
      "Epoch 32/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8002 - loss: 0.4202 - val_accuracy: 0.7975 - val_loss: 0.4181\n",
      "Epoch 33/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.3989 - val_accuracy: 0.8180 - val_loss: 0.4166\n",
      "Epoch 34/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8055 - loss: 0.4054 - val_accuracy: 0.8057 - val_loss: 0.4345\n",
      "Epoch 35/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.3992 - val_accuracy: 0.8037 - val_loss: 0.4067\n",
      "Epoch 36/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8088 - loss: 0.4103 - val_accuracy: 0.8078 - val_loss: 0.4128\n",
      "Epoch 37/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8117 - loss: 0.3965 - val_accuracy: 0.8139 - val_loss: 0.4043\n",
      "Epoch 38/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8211 - loss: 0.3959 - val_accuracy: 0.8139 - val_loss: 0.4125\n",
      "Epoch 39/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.3831 - val_accuracy: 0.8303 - val_loss: 0.3965\n",
      "Epoch 40/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8184 - loss: 0.3843 - val_accuracy: 0.8180 - val_loss: 0.4065\n",
      "Epoch 41/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8121 - loss: 0.4008 - val_accuracy: 0.8139 - val_loss: 0.4077\n",
      "Epoch 42/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8227 - loss: 0.3777 - val_accuracy: 0.8241 - val_loss: 0.3949\n",
      "Epoch 43/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.3821 - val_accuracy: 0.8180 - val_loss: 0.4062\n",
      "Epoch 44/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.3764 - val_accuracy: 0.8262 - val_loss: 0.3964\n",
      "Epoch 45/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8134 - loss: 0.4044 - val_accuracy: 0.8160 - val_loss: 0.3896\n",
      "Epoch 46/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8391 - loss: 0.3613 - val_accuracy: 0.8200 - val_loss: 0.3991\n",
      "Epoch 47/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8240 - loss: 0.3809 - val_accuracy: 0.8384 - val_loss: 0.3831\n",
      "Epoch 48/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 0.3540 - val_accuracy: 0.8282 - val_loss: 0.3866\n",
      "Epoch 49/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.3584 - val_accuracy: 0.8241 - val_loss: 0.3891\n",
      "Epoch 50/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.3607 - val_accuracy: 0.8303 - val_loss: 0.3789\n",
      "Epoch 51/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8357 - loss: 0.3523 - val_accuracy: 0.8303 - val_loss: 0.3790\n",
      "Epoch 52/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.3611 - val_accuracy: 0.8282 - val_loss: 0.3678\n",
      "Epoch 53/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8470 - loss: 0.3515 - val_accuracy: 0.8364 - val_loss: 0.3630\n",
      "Epoch 54/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3454 - val_accuracy: 0.8241 - val_loss: 0.3689\n",
      "Epoch 55/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.3434 - val_accuracy: 0.8282 - val_loss: 0.3719\n",
      "Epoch 56/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.3628 - val_accuracy: 0.8282 - val_loss: 0.3713\n",
      "Epoch 57/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3464 - val_accuracy: 0.8303 - val_loss: 0.3767\n",
      "Epoch 58/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8502 - loss: 0.3338 - val_accuracy: 0.8344 - val_loss: 0.3587\n",
      "Epoch 59/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8425 - loss: 0.3513 - val_accuracy: 0.8282 - val_loss: 0.3615\n",
      "Epoch 60/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8418 - loss: 0.3545 - val_accuracy: 0.8323 - val_loss: 0.3696\n",
      "Epoch 61/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.3457 - val_accuracy: 0.8098 - val_loss: 0.3848\n",
      "Epoch 62/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8521 - loss: 0.3407 - val_accuracy: 0.8344 - val_loss: 0.3610\n",
      "Epoch 63/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8464 - loss: 0.3463 - val_accuracy: 0.8344 - val_loss: 0.3463\n",
      "Epoch 64/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3301 - val_accuracy: 0.8282 - val_loss: 0.3570\n",
      "Epoch 65/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8487 - loss: 0.3295 - val_accuracy: 0.8405 - val_loss: 0.3480\n",
      "Epoch 66/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8435 - loss: 0.3357 - val_accuracy: 0.8405 - val_loss: 0.3498\n",
      "Epoch 67/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8480 - loss: 0.3360 - val_accuracy: 0.8384 - val_loss: 0.3438\n",
      "Epoch 68/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3178 - val_accuracy: 0.8487 - val_loss: 0.3307\n",
      "Epoch 69/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8467 - loss: 0.3395 - val_accuracy: 0.8569 - val_loss: 0.3411\n",
      "Epoch 70/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.3448 - val_accuracy: 0.8364 - val_loss: 0.3516\n",
      "Epoch 71/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8552 - loss: 0.3289 - val_accuracy: 0.8241 - val_loss: 0.3600\n",
      "Epoch 72/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8624 - loss: 0.3175 - val_accuracy: 0.8405 - val_loss: 0.3549\n",
      "Epoch 73/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8594 - loss: 0.3193 - val_accuracy: 0.8384 - val_loss: 0.3370\n",
      "Epoch 74/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8697 - loss: 0.3202 - val_accuracy: 0.8487 - val_loss: 0.3295\n",
      "Epoch 75/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.3188 - val_accuracy: 0.8282 - val_loss: 0.3383\n",
      "Epoch 76/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.2984 - val_accuracy: 0.8446 - val_loss: 0.3413\n",
      "Epoch 77/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.3090 - val_accuracy: 0.8548 - val_loss: 0.3228\n",
      "Epoch 78/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8572 - loss: 0.3180 - val_accuracy: 0.8446 - val_loss: 0.3302\n",
      "Epoch 79/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.3148 - val_accuracy: 0.8446 - val_loss: 0.3295\n",
      "Epoch 80/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8636 - loss: 0.2988 - val_accuracy: 0.8221 - val_loss: 0.3605\n",
      "Epoch 81/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8579 - loss: 0.3260 - val_accuracy: 0.8548 - val_loss: 0.3275\n",
      "Epoch 82/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8575 - loss: 0.3093 - val_accuracy: 0.8548 - val_loss: 0.3460\n",
      "Epoch 83/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8588 - loss: 0.3195 - val_accuracy: 0.8446 - val_loss: 0.3287\n",
      "Epoch 84/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8759 - loss: 0.3022 - val_accuracy: 0.8569 - val_loss: 0.3208\n",
      "Epoch 85/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3067 - val_accuracy: 0.8446 - val_loss: 0.3303\n",
      "Epoch 86/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8660 - loss: 0.3030 - val_accuracy: 0.8507 - val_loss: 0.3140\n",
      "Epoch 87/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8683 - loss: 0.3046 - val_accuracy: 0.8446 - val_loss: 0.3223\n",
      "Epoch 88/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8630 - loss: 0.3004 - val_accuracy: 0.8405 - val_loss: 0.3298\n",
      "Epoch 89/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8660 - loss: 0.2958 - val_accuracy: 0.8548 - val_loss: 0.3344\n",
      "Epoch 90/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8697 - loss: 0.2963 - val_accuracy: 0.8446 - val_loss: 0.3234\n",
      "Epoch 91/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8757 - loss: 0.2893 - val_accuracy: 0.8425 - val_loss: 0.3301\n",
      "Epoch 92/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8694 - loss: 0.3031 - val_accuracy: 0.8528 - val_loss: 0.3208\n",
      "Epoch 93/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8678 - loss: 0.2986 - val_accuracy: 0.8323 - val_loss: 0.3311\n",
      "Epoch 94/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8767 - loss: 0.2774 - val_accuracy: 0.8344 - val_loss: 0.3703\n",
      "Epoch 95/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8674 - loss: 0.3006 - val_accuracy: 0.8425 - val_loss: 0.3312\n",
      "Epoch 96/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8741 - loss: 0.2930 - val_accuracy: 0.8405 - val_loss: 0.3164\n",
      "Epoch 97/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.2925 - val_accuracy: 0.8282 - val_loss: 0.3377\n",
      "Epoch 98/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8622 - loss: 0.3055 - val_accuracy: 0.8364 - val_loss: 0.3215\n",
      "Epoch 99/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.2616 - val_accuracy: 0.8487 - val_loss: 0.3144\n",
      "Epoch 100/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8683 - loss: 0.2966 - val_accuracy: 0.8425 - val_loss: 0.3274\n",
      "Epoch 101/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.2923 - val_accuracy: 0.8466 - val_loss: 0.3215\n",
      "Epoch 102/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8791 - loss: 0.2835 - val_accuracy: 0.8487 - val_loss: 0.3213\n",
      "Epoch 103/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8912 - loss: 0.2650 - val_accuracy: 0.8323 - val_loss: 0.3228\n",
      "Epoch 104/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.2861 - val_accuracy: 0.8548 - val_loss: 0.3127\n",
      "Epoch 105/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8742 - loss: 0.2846 - val_accuracy: 0.8446 - val_loss: 0.3243\n",
      "Epoch 106/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8825 - loss: 0.2776 - val_accuracy: 0.8425 - val_loss: 0.2997\n",
      "Epoch 107/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8705 - loss: 0.2756 - val_accuracy: 0.8630 - val_loss: 0.2970\n",
      "Epoch 108/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8825 - loss: 0.2695 - val_accuracy: 0.8569 - val_loss: 0.2979\n",
      "Epoch 109/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.2681 - val_accuracy: 0.8466 - val_loss: 0.3313\n",
      "Epoch 110/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.2817 - val_accuracy: 0.8712 - val_loss: 0.3144\n",
      "Epoch 111/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8795 - loss: 0.2775 - val_accuracy: 0.8548 - val_loss: 0.2979\n",
      "Epoch 112/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8741 - loss: 0.2836 - val_accuracy: 0.8528 - val_loss: 0.3135\n",
      "Epoch 113/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8760 - loss: 0.2787 - val_accuracy: 0.8548 - val_loss: 0.3114\n",
      "Epoch 114/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8795 - loss: 0.2782 - val_accuracy: 0.8609 - val_loss: 0.2958\n",
      "Epoch 115/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8798 - loss: 0.2752 - val_accuracy: 0.8609 - val_loss: 0.3226\n",
      "Epoch 116/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8820 - loss: 0.2786 - val_accuracy: 0.8589 - val_loss: 0.2993\n",
      "Epoch 117/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8812 - loss: 0.2638 - val_accuracy: 0.8507 - val_loss: 0.3047\n",
      "Epoch 118/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8911 - loss: 0.2667 - val_accuracy: 0.8589 - val_loss: 0.3076\n",
      "Epoch 119/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.2605 - val_accuracy: 0.8773 - val_loss: 0.2950\n",
      "Epoch 120/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.2693 - val_accuracy: 0.8793 - val_loss: 0.3028\n",
      "Epoch 121/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.2762 - val_accuracy: 0.8712 - val_loss: 0.3024\n",
      "Epoch 122/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8863 - loss: 0.2664 - val_accuracy: 0.8650 - val_loss: 0.3083\n",
      "Epoch 123/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8875 - loss: 0.2579 - val_accuracy: 0.8712 - val_loss: 0.2969\n",
      "Epoch 124/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8810 - loss: 0.2670 - val_accuracy: 0.8732 - val_loss: 0.3014\n",
      "Epoch 125/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8838 - loss: 0.2628 - val_accuracy: 0.8650 - val_loss: 0.2913\n",
      "Epoch 126/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8882 - loss: 0.2563 - val_accuracy: 0.8773 - val_loss: 0.2742\n",
      "Epoch 127/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.2602 - val_accuracy: 0.8650 - val_loss: 0.2921\n",
      "Epoch 128/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8922 - loss: 0.2551 - val_accuracy: 0.8773 - val_loss: 0.2995\n",
      "Epoch 129/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.2733 - val_accuracy: 0.8609 - val_loss: 0.3058\n",
      "Epoch 130/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8834 - loss: 0.2723 - val_accuracy: 0.8773 - val_loss: 0.2707\n",
      "Epoch 131/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8785 - loss: 0.2636 - val_accuracy: 0.8650 - val_loss: 0.3000\n",
      "Epoch 132/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8875 - loss: 0.2430 - val_accuracy: 0.8875 - val_loss: 0.2674\n",
      "Epoch 133/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8825 - loss: 0.2646 - val_accuracy: 0.8569 - val_loss: 0.2830\n",
      "Epoch 134/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8932 - loss: 0.2519 - val_accuracy: 0.8875 - val_loss: 0.2809\n",
      "Epoch 135/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.2714 - val_accuracy: 0.8691 - val_loss: 0.2892\n",
      "Epoch 136/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8848 - loss: 0.2552 - val_accuracy: 0.8650 - val_loss: 0.2950\n",
      "Epoch 137/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.2450 - val_accuracy: 0.8671 - val_loss: 0.2923\n",
      "Epoch 138/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.2527 - val_accuracy: 0.8569 - val_loss: 0.2914\n",
      "Epoch 139/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.2328 - val_accuracy: 0.8589 - val_loss: 0.2875\n",
      "Epoch 140/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8913 - loss: 0.2591 - val_accuracy: 0.8712 - val_loss: 0.2770\n",
      "Epoch 141/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.2553 - val_accuracy: 0.8630 - val_loss: 0.2828\n",
      "Epoch 142/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8972 - loss: 0.2531 - val_accuracy: 0.8753 - val_loss: 0.2830\n",
      "Epoch 143/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.2455 - val_accuracy: 0.8691 - val_loss: 0.2746\n",
      "Epoch 144/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8965 - loss: 0.2425 - val_accuracy: 0.8609 - val_loss: 0.2825\n",
      "Epoch 145/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.2470 - val_accuracy: 0.8773 - val_loss: 0.2655\n",
      "Epoch 146/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9050 - loss: 0.2360 - val_accuracy: 0.8753 - val_loss: 0.2767\n",
      "Epoch 147/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8942 - loss: 0.2498 - val_accuracy: 0.8834 - val_loss: 0.2762\n",
      "Epoch 148/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.2422 - val_accuracy: 0.8753 - val_loss: 0.2668\n",
      "Epoch 149/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8814 - loss: 0.2559 - val_accuracy: 0.8875 - val_loss: 0.2699\n",
      "Epoch 150/150\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: 0.2388 - val_accuracy: 0.8814 - val_loss: 0.2774\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.8890 - loss: 0.2642\n",
      "Validation Loss: 0.27736061811447144, Validation Accuracy: 0.8813905715942383\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(total_samples)\n",
    "np.random.shuffle(indices)\n",
    "train_size_60_random = int(total_samples* 0.6)\n",
    "X_train_60 = X_train_padded[:train_size_60_random]\n",
    "y_train_60 = y_train_categorical[:train_size_60_random]\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10, output_dim=12, input_length=47))  # Embedding layer with output_dim=12\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))  # Convolutional layer with 32 filters\n",
    "model.add(MaxPooling1D(pool_size=2))  # Max pooling layer\n",
    "model.add(Dropout(0.3))  # Dropout layer\n",
    "model.add(LSTM(24, return_sequences=False))  # LSTM layer with 24 units\n",
    "model.add(Dense(32, activation='relu'))  # Dense layer with 32 units\n",
    "model.add(Dense(2, activation='softmax'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_60, y_train_60, \n",
    "          validation_data=(X_valid_padded, y_valid_categorical), \n",
    "          epochs=150, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy60 = model.evaluate(X_valid_padded, y_valid_categorical)\n",
    "print(f'Validation Loss: {loss}, Validation Accuracy: {accuracy60}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model using 40% of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4979 - loss: 0.6934 - val_accuracy: 0.5153 - val_loss: 0.6918\n",
      "Epoch 2/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5157 - loss: 0.6910 - val_accuracy: 0.4867 - val_loss: 0.6955\n",
      "Epoch 3/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5845 - loss: 0.6703 - val_accuracy: 0.6339 - val_loss: 0.6355\n",
      "Epoch 4/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6251 - loss: 0.6384 - val_accuracy: 0.6728 - val_loss: 0.6120\n",
      "Epoch 5/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6495 - loss: 0.6246 - val_accuracy: 0.6667 - val_loss: 0.6037\n",
      "Epoch 6/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6716 - loss: 0.6022 - val_accuracy: 0.6789 - val_loss: 0.6002\n",
      "Epoch 7/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6711 - loss: 0.5971 - val_accuracy: 0.6871 - val_loss: 0.5836\n",
      "Epoch 8/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6834 - loss: 0.5840 - val_accuracy: 0.7137 - val_loss: 0.5648\n",
      "Epoch 9/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7037 - loss: 0.5747 - val_accuracy: 0.7239 - val_loss: 0.5595\n",
      "Epoch 10/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7065 - loss: 0.5663 - val_accuracy: 0.7280 - val_loss: 0.5462\n",
      "Epoch 11/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7268 - loss: 0.5356 - val_accuracy: 0.7280 - val_loss: 0.5430\n",
      "Epoch 12/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7144 - loss: 0.5484 - val_accuracy: 0.7260 - val_loss: 0.5391\n",
      "Epoch 13/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7162 - loss: 0.5402 - val_accuracy: 0.7117 - val_loss: 0.5397\n",
      "Epoch 14/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7518 - loss: 0.5233 - val_accuracy: 0.7280 - val_loss: 0.5439\n",
      "Epoch 15/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7518 - loss: 0.5106 - val_accuracy: 0.7301 - val_loss: 0.5337\n",
      "Epoch 16/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7353 - loss: 0.5214 - val_accuracy: 0.7505 - val_loss: 0.5184\n",
      "Epoch 17/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7649 - loss: 0.4767 - val_accuracy: 0.7485 - val_loss: 0.5066\n",
      "Epoch 18/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7528 - loss: 0.5007 - val_accuracy: 0.7587 - val_loss: 0.4920\n",
      "Epoch 19/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7584 - loss: 0.4873 - val_accuracy: 0.7444 - val_loss: 0.4957\n",
      "Epoch 20/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7509 - loss: 0.4882 - val_accuracy: 0.7444 - val_loss: 0.5037\n",
      "Epoch 21/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7646 - loss: 0.4871 - val_accuracy: 0.7362 - val_loss: 0.5154\n",
      "Epoch 22/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.4678 - val_accuracy: 0.7566 - val_loss: 0.4845\n",
      "Epoch 23/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7789 - loss: 0.4828 - val_accuracy: 0.7730 - val_loss: 0.4706\n",
      "Epoch 24/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7561 - loss: 0.4846 - val_accuracy: 0.7771 - val_loss: 0.4852\n",
      "Epoch 25/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4463 - val_accuracy: 0.7648 - val_loss: 0.4750\n",
      "Epoch 26/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7764 - loss: 0.4625 - val_accuracy: 0.7689 - val_loss: 0.4665\n",
      "Epoch 27/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.4598 - val_accuracy: 0.7791 - val_loss: 0.4660\n",
      "Epoch 28/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.4321 - val_accuracy: 0.7791 - val_loss: 0.4578\n",
      "Epoch 29/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.4413 - val_accuracy: 0.7710 - val_loss: 0.4654\n",
      "Epoch 30/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 0.4461 - val_accuracy: 0.7894 - val_loss: 0.4611\n",
      "Epoch 31/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7793 - loss: 0.4621 - val_accuracy: 0.7648 - val_loss: 0.4593\n",
      "Epoch 32/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7976 - loss: 0.4367 - val_accuracy: 0.7873 - val_loss: 0.4536\n",
      "Epoch 33/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7870 - loss: 0.4434 - val_accuracy: 0.7832 - val_loss: 0.4574\n",
      "Epoch 34/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.4300 - val_accuracy: 0.7812 - val_loss: 0.4418\n",
      "Epoch 35/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8023 - loss: 0.4260 - val_accuracy: 0.7955 - val_loss: 0.4443\n",
      "Epoch 36/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.4295 - val_accuracy: 0.7975 - val_loss: 0.4400\n",
      "Epoch 37/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8139 - loss: 0.4023 - val_accuracy: 0.7935 - val_loss: 0.4412\n",
      "Epoch 38/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8227 - loss: 0.3918 - val_accuracy: 0.7751 - val_loss: 0.4616\n",
      "Epoch 39/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.4000 - val_accuracy: 0.7873 - val_loss: 0.4361\n",
      "Epoch 40/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4153 - val_accuracy: 0.7730 - val_loss: 0.4477\n",
      "Epoch 41/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.3979 - val_accuracy: 0.7832 - val_loss: 0.4286\n",
      "Epoch 42/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.3845 - val_accuracy: 0.7710 - val_loss: 0.4554\n",
      "Epoch 43/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8222 - loss: 0.3853 - val_accuracy: 0.7935 - val_loss: 0.4322\n",
      "Epoch 44/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8192 - loss: 0.4077 - val_accuracy: 0.7832 - val_loss: 0.4373\n",
      "Epoch 45/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8136 - loss: 0.3987 - val_accuracy: 0.7587 - val_loss: 0.4767\n",
      "Epoch 46/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.4033 - val_accuracy: 0.7812 - val_loss: 0.4368\n",
      "Epoch 47/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8143 - loss: 0.3964 - val_accuracy: 0.7975 - val_loss: 0.4219\n",
      "Epoch 48/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8220 - loss: 0.3889 - val_accuracy: 0.7955 - val_loss: 0.4267\n",
      "Epoch 49/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8314 - loss: 0.3954 - val_accuracy: 0.8057 - val_loss: 0.4196\n",
      "Epoch 50/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.3858 - val_accuracy: 0.8098 - val_loss: 0.4140\n",
      "Epoch 51/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.3807 - val_accuracy: 0.7975 - val_loss: 0.4164\n",
      "Epoch 52/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8347 - loss: 0.3694 - val_accuracy: 0.7996 - val_loss: 0.4252\n",
      "Epoch 53/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8308 - loss: 0.3897 - val_accuracy: 0.7853 - val_loss: 0.4227\n",
      "Epoch 54/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.3655 - val_accuracy: 0.8037 - val_loss: 0.4102\n",
      "Epoch 55/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.3741 - val_accuracy: 0.7812 - val_loss: 0.4153\n",
      "Epoch 56/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.3682 - val_accuracy: 0.7955 - val_loss: 0.4218\n",
      "Epoch 57/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.3778 - val_accuracy: 0.7894 - val_loss: 0.4135\n",
      "Epoch 58/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8212 - loss: 0.3869 - val_accuracy: 0.7975 - val_loss: 0.4134\n",
      "Epoch 59/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8520 - loss: 0.3433 - val_accuracy: 0.8016 - val_loss: 0.4090\n",
      "Epoch 60/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.3650 - val_accuracy: 0.8119 - val_loss: 0.4049\n",
      "Epoch 61/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8530 - loss: 0.3493 - val_accuracy: 0.7812 - val_loss: 0.4163\n",
      "Epoch 62/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8480 - loss: 0.3608 - val_accuracy: 0.8078 - val_loss: 0.3940\n",
      "Epoch 63/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8461 - loss: 0.3560 - val_accuracy: 0.7914 - val_loss: 0.4150\n",
      "Epoch 64/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8449 - loss: 0.3572 - val_accuracy: 0.7955 - val_loss: 0.4056\n",
      "Epoch 65/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8428 - loss: 0.3529 - val_accuracy: 0.7894 - val_loss: 0.4054\n",
      "Epoch 66/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8543 - loss: 0.3305 - val_accuracy: 0.7914 - val_loss: 0.3952\n",
      "Epoch 67/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.3442 - val_accuracy: 0.7894 - val_loss: 0.4222\n",
      "Epoch 68/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8382 - loss: 0.3514 - val_accuracy: 0.8057 - val_loss: 0.3982\n",
      "Epoch 69/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.3564 - val_accuracy: 0.7955 - val_loss: 0.4024\n",
      "Epoch 70/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.3325 - val_accuracy: 0.7955 - val_loss: 0.4009\n",
      "Epoch 71/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8434 - loss: 0.3442 - val_accuracy: 0.8016 - val_loss: 0.3945\n",
      "Epoch 72/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8499 - loss: 0.3342 - val_accuracy: 0.8119 - val_loss: 0.3799\n",
      "Epoch 73/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8530 - loss: 0.3490 - val_accuracy: 0.8037 - val_loss: 0.3952\n",
      "Epoch 74/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.3398 - val_accuracy: 0.7996 - val_loss: 0.4008\n",
      "Epoch 75/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.3297 - val_accuracy: 0.8200 - val_loss: 0.3910\n",
      "Epoch 76/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8476 - loss: 0.3323 - val_accuracy: 0.8200 - val_loss: 0.3849\n",
      "Epoch 77/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8550 - loss: 0.3237 - val_accuracy: 0.8282 - val_loss: 0.3692\n",
      "Epoch 78/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8481 - loss: 0.3381 - val_accuracy: 0.8323 - val_loss: 0.3735\n",
      "Epoch 79/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8538 - loss: 0.3329 - val_accuracy: 0.8078 - val_loss: 0.3868\n",
      "Epoch 80/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8509 - loss: 0.3347 - val_accuracy: 0.8119 - val_loss: 0.3816\n",
      "Epoch 81/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8634 - loss: 0.3284 - val_accuracy: 0.8098 - val_loss: 0.3846\n",
      "Epoch 82/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.3294 - val_accuracy: 0.8241 - val_loss: 0.3644\n",
      "Epoch 83/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8540 - loss: 0.3259 - val_accuracy: 0.8160 - val_loss: 0.3881\n",
      "Epoch 84/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8511 - loss: 0.3347 - val_accuracy: 0.8139 - val_loss: 0.3770\n",
      "Epoch 85/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8674 - loss: 0.3213 - val_accuracy: 0.8180 - val_loss: 0.3753\n",
      "Epoch 86/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8470 - loss: 0.3341 - val_accuracy: 0.8323 - val_loss: 0.3748\n",
      "Epoch 87/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.3304 - val_accuracy: 0.8221 - val_loss: 0.3759\n",
      "Epoch 88/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.3224 - val_accuracy: 0.8139 - val_loss: 0.3796\n",
      "Epoch 89/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.3234 - val_accuracy: 0.8200 - val_loss: 0.3715\n",
      "Epoch 90/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8676 - loss: 0.3116 - val_accuracy: 0.8098 - val_loss: 0.3904\n",
      "Epoch 91/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8722 - loss: 0.3056 - val_accuracy: 0.8180 - val_loss: 0.3740\n",
      "Epoch 92/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8487 - loss: 0.3244 - val_accuracy: 0.8241 - val_loss: 0.3675\n",
      "Epoch 93/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8655 - loss: 0.3113 - val_accuracy: 0.8200 - val_loss: 0.3646\n",
      "Epoch 94/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8617 - loss: 0.3122 - val_accuracy: 0.8139 - val_loss: 0.3797\n",
      "Epoch 95/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.2902 - val_accuracy: 0.8200 - val_loss: 0.3679\n",
      "Epoch 96/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8556 - loss: 0.3238 - val_accuracy: 0.8262 - val_loss: 0.3712\n",
      "Epoch 97/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8801 - loss: 0.2972 - val_accuracy: 0.8241 - val_loss: 0.3628\n",
      "Epoch 98/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8748 - loss: 0.2902 - val_accuracy: 0.8160 - val_loss: 0.3654\n",
      "Epoch 99/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8651 - loss: 0.3142 - val_accuracy: 0.8221 - val_loss: 0.3608\n",
      "Epoch 100/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8662 - loss: 0.3020 - val_accuracy: 0.8344 - val_loss: 0.3543\n",
      "Epoch 101/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8639 - loss: 0.3132 - val_accuracy: 0.8180 - val_loss: 0.3839\n",
      "Epoch 102/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.3129 - val_accuracy: 0.8446 - val_loss: 0.3552\n",
      "Epoch 103/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8712 - loss: 0.3022 - val_accuracy: 0.8344 - val_loss: 0.3653\n",
      "Epoch 104/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8740 - loss: 0.3081 - val_accuracy: 0.8446 - val_loss: 0.3550\n",
      "Epoch 105/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8641 - loss: 0.3144 - val_accuracy: 0.8282 - val_loss: 0.3666\n",
      "Epoch 106/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.2872 - val_accuracy: 0.8221 - val_loss: 0.3708\n",
      "Epoch 107/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8694 - loss: 0.3083 - val_accuracy: 0.8303 - val_loss: 0.3678\n",
      "Epoch 108/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8672 - loss: 0.2944 - val_accuracy: 0.8446 - val_loss: 0.3519\n",
      "Epoch 109/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8886 - loss: 0.2628 - val_accuracy: 0.8344 - val_loss: 0.3674\n",
      "Epoch 110/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8779 - loss: 0.2899 - val_accuracy: 0.8221 - val_loss: 0.3760\n",
      "Epoch 111/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.2992 - val_accuracy: 0.8303 - val_loss: 0.3503\n",
      "Epoch 112/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8735 - loss: 0.2945 - val_accuracy: 0.8344 - val_loss: 0.3581\n",
      "Epoch 113/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.2906 - val_accuracy: 0.8405 - val_loss: 0.3534\n",
      "Epoch 114/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8834 - loss: 0.2804 - val_accuracy: 0.8364 - val_loss: 0.3585\n",
      "Epoch 115/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8790 - loss: 0.2883 - val_accuracy: 0.8262 - val_loss: 0.3720\n",
      "Epoch 116/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8725 - loss: 0.2920 - val_accuracy: 0.8303 - val_loss: 0.3643\n",
      "Epoch 117/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.2857 - val_accuracy: 0.8466 - val_loss: 0.3460\n",
      "Epoch 118/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8766 - loss: 0.2738 - val_accuracy: 0.8364 - val_loss: 0.3550\n",
      "Epoch 119/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.2687 - val_accuracy: 0.8200 - val_loss: 0.3618\n",
      "Epoch 120/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8707 - loss: 0.2887 - val_accuracy: 0.8262 - val_loss: 0.3411\n",
      "Epoch 121/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.2748 - val_accuracy: 0.8446 - val_loss: 0.3515\n",
      "Epoch 122/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8745 - loss: 0.2868 - val_accuracy: 0.8384 - val_loss: 0.3405\n",
      "Epoch 123/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8776 - loss: 0.2878 - val_accuracy: 0.8180 - val_loss: 0.3853\n",
      "Epoch 124/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8792 - loss: 0.2667 - val_accuracy: 0.8507 - val_loss: 0.3539\n",
      "Epoch 125/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8811 - loss: 0.2749 - val_accuracy: 0.8425 - val_loss: 0.3464\n",
      "Epoch 126/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8813 - loss: 0.2716 - val_accuracy: 0.8507 - val_loss: 0.3425\n",
      "Epoch 127/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.2803 - val_accuracy: 0.8425 - val_loss: 0.3618\n",
      "Epoch 128/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.2618 - val_accuracy: 0.8384 - val_loss: 0.3396\n",
      "Epoch 129/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.2609 - val_accuracy: 0.8466 - val_loss: 0.3544\n",
      "Epoch 130/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8904 - loss: 0.2564 - val_accuracy: 0.8364 - val_loss: 0.3703\n",
      "Epoch 131/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.2980 - val_accuracy: 0.8446 - val_loss: 0.3467\n",
      "Epoch 132/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.2696 - val_accuracy: 0.8262 - val_loss: 0.3560\n",
      "Epoch 133/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8811 - loss: 0.2762 - val_accuracy: 0.8364 - val_loss: 0.3668\n",
      "Epoch 134/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.2651 - val_accuracy: 0.8446 - val_loss: 0.3498\n",
      "Epoch 135/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8870 - loss: 0.2666 - val_accuracy: 0.8589 - val_loss: 0.3403\n",
      "Epoch 136/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.2553 - val_accuracy: 0.8507 - val_loss: 0.3477\n",
      "Epoch 137/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8965 - loss: 0.2518 - val_accuracy: 0.8344 - val_loss: 0.3424\n",
      "Epoch 138/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8927 - loss: 0.2588 - val_accuracy: 0.8630 - val_loss: 0.3349\n",
      "Epoch 139/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8919 - loss: 0.2537 - val_accuracy: 0.8589 - val_loss: 0.3333\n",
      "Epoch 140/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8760 - loss: 0.2685 - val_accuracy: 0.8384 - val_loss: 0.3648\n",
      "Epoch 141/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.2684 - val_accuracy: 0.8528 - val_loss: 0.3316\n",
      "Epoch 142/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9032 - loss: 0.2381 - val_accuracy: 0.8446 - val_loss: 0.3447\n",
      "Epoch 143/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8804 - loss: 0.2755 - val_accuracy: 0.8405 - val_loss: 0.3678\n",
      "Epoch 144/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8870 - loss: 0.2510 - val_accuracy: 0.8425 - val_loss: 0.3575\n",
      "Epoch 145/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8834 - loss: 0.2548 - val_accuracy: 0.8364 - val_loss: 0.3601\n",
      "Epoch 146/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8928 - loss: 0.2513 - val_accuracy: 0.8507 - val_loss: 0.3407\n",
      "Epoch 147/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8870 - loss: 0.2630 - val_accuracy: 0.8364 - val_loss: 0.3396\n",
      "Epoch 148/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8870 - loss: 0.2687 - val_accuracy: 0.8384 - val_loss: 0.3539\n",
      "Epoch 149/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.2548 - val_accuracy: 0.8466 - val_loss: 0.3480\n",
      "Epoch 150/150\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: 0.2543 - val_accuracy: 0.8425 - val_loss: 0.3459\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.8659 - loss: 0.3159\n",
      "Validation Loss: 0.3459203541278839, Validation Accuracy: 0.8425357937812805\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(X_train_padded)\n",
    "indices = np.arange(total_samples)\n",
    "np.random.shuffle(indices)\n",
    "train_size_40_random = int(total_samples* 0.4)\n",
    "X_train_40 = X_train_padded[:train_size_40_random]\n",
    "y_train_40 = y_train_categorical[:train_size_40_random]\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10, output_dim=12, input_length=47))  # Embedding layer with output_dim=12\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))  # Convolutional layer with 32 filters\n",
    "model.add(MaxPooling1D(pool_size=2))  # Max pooling layer\n",
    "model.add(Dropout(0.3))  # Dropout layer\n",
    "model.add(LSTM(24, return_sequences=False))  # LSTM layer with 24 units\n",
    "model.add(Dense(32, activation='relu'))  # Dense layer with 32 units\n",
    "model.add(Dense(2, activation='softmax'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_40, y_train_40, \n",
    "          validation_data=(X_valid_padded, y_valid_categorical), \n",
    "          epochs=150, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy40 = model.evaluate(X_valid_padded, y_valid_categorical)\n",
    "print(f'Validation Loss: {loss}, Validation Accuracy: {accuracy40}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model using 20% of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4747 - loss: 0.6936 - val_accuracy: 0.5112 - val_loss: 0.6931\n",
      "Epoch 2/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5080 - loss: 0.6932 - val_accuracy: 0.5153 - val_loss: 0.6928\n",
      "Epoch 3/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4740 - loss: 0.6933 - val_accuracy: 0.5153 - val_loss: 0.6927\n",
      "Epoch 4/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4965 - loss: 0.6932 - val_accuracy: 0.5235 - val_loss: 0.6927\n",
      "Epoch 5/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5004 - loss: 0.6930 - val_accuracy: 0.5256 - val_loss: 0.6920\n",
      "Epoch 6/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5088 - loss: 0.6933 - val_accuracy: 0.5317 - val_loss: 0.6904\n",
      "Epoch 7/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5346 - loss: 0.6899 - val_accuracy: 0.5971 - val_loss: 0.6668\n",
      "Epoch 8/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6127 - loss: 0.6604 - val_accuracy: 0.6503 - val_loss: 0.6372\n",
      "Epoch 9/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6328 - loss: 0.6488 - val_accuracy: 0.6442 - val_loss: 0.6374\n",
      "Epoch 10/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6428 - loss: 0.6345 - val_accuracy: 0.6380 - val_loss: 0.6330\n",
      "Epoch 11/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: 0.6272 - val_accuracy: 0.6339 - val_loss: 0.6370\n",
      "Epoch 12/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6571 - loss: 0.6167 - val_accuracy: 0.6626 - val_loss: 0.6171\n",
      "Epoch 13/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6640 - loss: 0.6089 - val_accuracy: 0.6442 - val_loss: 0.6304\n",
      "Epoch 14/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6554 - loss: 0.6105 - val_accuracy: 0.6789 - val_loss: 0.6037\n",
      "Epoch 15/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6514 - loss: 0.6034 - val_accuracy: 0.6585 - val_loss: 0.6232\n",
      "Epoch 16/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6589 - loss: 0.6078 - val_accuracy: 0.6564 - val_loss: 0.6185\n",
      "Epoch 17/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6725 - loss: 0.5879 - val_accuracy: 0.6871 - val_loss: 0.5996\n",
      "Epoch 18/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7052 - loss: 0.5525 - val_accuracy: 0.6851 - val_loss: 0.5823\n",
      "Epoch 19/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6811 - loss: 0.5790 - val_accuracy: 0.6830 - val_loss: 0.5905\n",
      "Epoch 20/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7092 - loss: 0.5607 - val_accuracy: 0.7076 - val_loss: 0.5717\n",
      "Epoch 21/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7116 - loss: 0.5582 - val_accuracy: 0.6933 - val_loss: 0.5744\n",
      "Epoch 22/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7067 - loss: 0.5549 - val_accuracy: 0.7117 - val_loss: 0.5787\n",
      "Epoch 23/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7213 - loss: 0.5414 - val_accuracy: 0.7076 - val_loss: 0.5717\n",
      "Epoch 24/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7300 - loss: 0.5251 - val_accuracy: 0.7137 - val_loss: 0.5644\n",
      "Epoch 25/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7205 - loss: 0.5406 - val_accuracy: 0.7137 - val_loss: 0.5440\n",
      "Epoch 26/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.5103 - val_accuracy: 0.7055 - val_loss: 0.5511\n",
      "Epoch 27/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.5246 - val_accuracy: 0.7239 - val_loss: 0.5398\n",
      "Epoch 28/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7516 - loss: 0.5162 - val_accuracy: 0.7280 - val_loss: 0.5359\n",
      "Epoch 29/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.5321 - val_accuracy: 0.7219 - val_loss: 0.5571\n",
      "Epoch 30/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7280 - loss: 0.5284 - val_accuracy: 0.7219 - val_loss: 0.5299\n",
      "Epoch 31/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7516 - loss: 0.4846 - val_accuracy: 0.7178 - val_loss: 0.5565\n",
      "Epoch 32/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7481 - loss: 0.5115 - val_accuracy: 0.7178 - val_loss: 0.5265\n",
      "Epoch 33/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7642 - loss: 0.4801 - val_accuracy: 0.7403 - val_loss: 0.5156\n",
      "Epoch 34/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7652 - loss: 0.4778 - val_accuracy: 0.7505 - val_loss: 0.5128\n",
      "Epoch 35/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.4809 - val_accuracy: 0.7526 - val_loss: 0.5206\n",
      "Epoch 36/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7517 - loss: 0.4852 - val_accuracy: 0.7505 - val_loss: 0.5118\n",
      "Epoch 37/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7636 - loss: 0.4709 - val_accuracy: 0.7546 - val_loss: 0.5129\n",
      "Epoch 38/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.4791 - val_accuracy: 0.7464 - val_loss: 0.5187\n",
      "Epoch 39/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7685 - loss: 0.4955 - val_accuracy: 0.7505 - val_loss: 0.5020\n",
      "Epoch 40/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7805 - loss: 0.4753 - val_accuracy: 0.7526 - val_loss: 0.5013\n",
      "Epoch 41/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7833 - loss: 0.4617 - val_accuracy: 0.7423 - val_loss: 0.5046\n",
      "Epoch 42/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7743 - loss: 0.4568 - val_accuracy: 0.7628 - val_loss: 0.5082\n",
      "Epoch 43/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7652 - loss: 0.4787 - val_accuracy: 0.7628 - val_loss: 0.4959\n",
      "Epoch 44/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7759 - loss: 0.4619 - val_accuracy: 0.7628 - val_loss: 0.4986\n",
      "Epoch 45/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7707 - loss: 0.4468 - val_accuracy: 0.7566 - val_loss: 0.4872\n",
      "Epoch 46/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7759 - loss: 0.4712 - val_accuracy: 0.7485 - val_loss: 0.4900\n",
      "Epoch 47/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7908 - loss: 0.4327 - val_accuracy: 0.7607 - val_loss: 0.4803\n",
      "Epoch 48/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.4405 - val_accuracy: 0.7730 - val_loss: 0.4794\n",
      "Epoch 49/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7964 - loss: 0.4518 - val_accuracy: 0.7628 - val_loss: 0.4932\n",
      "Epoch 50/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.4377 - val_accuracy: 0.7751 - val_loss: 0.4703\n",
      "Epoch 51/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.4259 - val_accuracy: 0.7832 - val_loss: 0.4847\n",
      "Epoch 52/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7665 - loss: 0.4661 - val_accuracy: 0.7730 - val_loss: 0.4754\n",
      "Epoch 53/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.4239 - val_accuracy: 0.7873 - val_loss: 0.4767\n",
      "Epoch 54/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7894 - loss: 0.4416 - val_accuracy: 0.7648 - val_loss: 0.4853\n",
      "Epoch 55/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7899 - loss: 0.4317 - val_accuracy: 0.7669 - val_loss: 0.4910\n",
      "Epoch 56/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8030 - loss: 0.4311 - val_accuracy: 0.7648 - val_loss: 0.4607\n",
      "Epoch 57/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8222 - loss: 0.3897 - val_accuracy: 0.7791 - val_loss: 0.4546\n",
      "Epoch 58/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4266 - val_accuracy: 0.7873 - val_loss: 0.4551\n",
      "Epoch 59/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8060 - loss: 0.4318 - val_accuracy: 0.7791 - val_loss: 0.4633\n",
      "Epoch 60/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7963 - loss: 0.4151 - val_accuracy: 0.7873 - val_loss: 0.4658\n",
      "Epoch 61/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8002 - loss: 0.4167 - val_accuracy: 0.7832 - val_loss: 0.4574\n",
      "Epoch 62/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.4129 - val_accuracy: 0.7628 - val_loss: 0.5057\n",
      "Epoch 63/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.4206 - val_accuracy: 0.7628 - val_loss: 0.4743\n",
      "Epoch 64/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8175 - loss: 0.3892 - val_accuracy: 0.7669 - val_loss: 0.4619\n",
      "Epoch 65/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8294 - loss: 0.3978 - val_accuracy: 0.7710 - val_loss: 0.4727\n",
      "Epoch 66/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8313 - loss: 0.3964 - val_accuracy: 0.7669 - val_loss: 0.4624\n",
      "Epoch 67/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.3963 - val_accuracy: 0.7873 - val_loss: 0.4894\n",
      "Epoch 68/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8149 - loss: 0.4032 - val_accuracy: 0.7751 - val_loss: 0.4540\n",
      "Epoch 69/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8177 - loss: 0.3941 - val_accuracy: 0.7791 - val_loss: 0.4743\n",
      "Epoch 70/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.3795 - val_accuracy: 0.7955 - val_loss: 0.4529\n",
      "Epoch 71/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8221 - loss: 0.3831 - val_accuracy: 0.7791 - val_loss: 0.4569\n",
      "Epoch 72/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.3907 - val_accuracy: 0.7812 - val_loss: 0.4768\n",
      "Epoch 73/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8288 - loss: 0.3858 - val_accuracy: 0.7853 - val_loss: 0.4594\n",
      "Epoch 74/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8501 - loss: 0.3675 - val_accuracy: 0.7791 - val_loss: 0.4700\n",
      "Epoch 75/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7966 - loss: 0.4142 - val_accuracy: 0.7669 - val_loss: 0.4639\n",
      "Epoch 76/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8515 - loss: 0.3840 - val_accuracy: 0.7853 - val_loss: 0.5002\n",
      "Epoch 77/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.3817 - val_accuracy: 0.7730 - val_loss: 0.4747\n",
      "Epoch 78/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3604 - val_accuracy: 0.7894 - val_loss: 0.4588\n",
      "Epoch 79/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.3638 - val_accuracy: 0.7710 - val_loss: 0.4859\n",
      "Epoch 80/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.3972 - val_accuracy: 0.7853 - val_loss: 0.4587\n",
      "Epoch 81/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8380 - loss: 0.3618 - val_accuracy: 0.7832 - val_loss: 0.5067\n",
      "Epoch 82/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8374 - loss: 0.3873 - val_accuracy: 0.7791 - val_loss: 0.4588\n",
      "Epoch 83/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.3529 - val_accuracy: 0.7791 - val_loss: 0.4677\n",
      "Epoch 84/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8435 - loss: 0.3524 - val_accuracy: 0.7853 - val_loss: 0.4658\n",
      "Epoch 85/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8243 - loss: 0.3825 - val_accuracy: 0.7894 - val_loss: 0.4503\n",
      "Epoch 86/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8560 - loss: 0.3740 - val_accuracy: 0.7832 - val_loss: 0.4474\n",
      "Epoch 87/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8184 - loss: 0.3767 - val_accuracy: 0.7812 - val_loss: 0.4767\n",
      "Epoch 88/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.3916 - val_accuracy: 0.7955 - val_loss: 0.4427\n",
      "Epoch 89/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.3676 - val_accuracy: 0.7832 - val_loss: 0.4496\n",
      "Epoch 90/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.3619 - val_accuracy: 0.7935 - val_loss: 0.4743\n",
      "Epoch 91/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8588 - loss: 0.3385 - val_accuracy: 0.7955 - val_loss: 0.4611\n",
      "Epoch 92/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8457 - loss: 0.3539 - val_accuracy: 0.7955 - val_loss: 0.4469\n",
      "Epoch 93/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8509 - loss: 0.3507 - val_accuracy: 0.7955 - val_loss: 0.4441\n",
      "Epoch 94/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8378 - loss: 0.3694 - val_accuracy: 0.7771 - val_loss: 0.4563\n",
      "Epoch 95/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8337 - loss: 0.3690 - val_accuracy: 0.7812 - val_loss: 0.4499\n",
      "Epoch 96/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3597 - val_accuracy: 0.7771 - val_loss: 0.4491\n",
      "Epoch 97/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3697 - val_accuracy: 0.7853 - val_loss: 0.4557\n",
      "Epoch 98/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8352 - loss: 0.3368 - val_accuracy: 0.8016 - val_loss: 0.4551\n",
      "Epoch 99/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8194 - loss: 0.3717 - val_accuracy: 0.7873 - val_loss: 0.4692\n",
      "Epoch 100/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8676 - loss: 0.3113 - val_accuracy: 0.7914 - val_loss: 0.4529\n",
      "Epoch 101/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8495 - loss: 0.3582 - val_accuracy: 0.7832 - val_loss: 0.4989\n",
      "Epoch 102/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8495 - loss: 0.3446 - val_accuracy: 0.7812 - val_loss: 0.4741\n",
      "Epoch 103/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8584 - loss: 0.3380 - val_accuracy: 0.7873 - val_loss: 0.4742\n",
      "Epoch 104/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.3048 - val_accuracy: 0.7935 - val_loss: 0.4787\n",
      "Epoch 105/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8535 - loss: 0.3302 - val_accuracy: 0.7853 - val_loss: 0.4605\n",
      "Epoch 106/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8637 - loss: 0.3241 - val_accuracy: 0.7894 - val_loss: 0.4898\n",
      "Epoch 107/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.3400 - val_accuracy: 0.7955 - val_loss: 0.4501\n",
      "Epoch 108/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3396 - val_accuracy: 0.7935 - val_loss: 0.4632\n",
      "Epoch 109/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.3217 - val_accuracy: 0.7935 - val_loss: 0.4488\n",
      "Epoch 110/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8532 - loss: 0.3203 - val_accuracy: 0.7955 - val_loss: 0.4511\n",
      "Epoch 111/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8582 - loss: 0.3331 - val_accuracy: 0.7832 - val_loss: 0.4746\n",
      "Epoch 112/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8461 - loss: 0.3419 - val_accuracy: 0.7935 - val_loss: 0.4701\n",
      "Epoch 113/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3452 - val_accuracy: 0.8016 - val_loss: 0.4621\n",
      "Epoch 114/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8516 - loss: 0.3137 - val_accuracy: 0.8057 - val_loss: 0.4635\n",
      "Epoch 115/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8359 - loss: 0.3508 - val_accuracy: 0.7975 - val_loss: 0.4678\n",
      "Epoch 116/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3442 - val_accuracy: 0.7996 - val_loss: 0.4565\n",
      "Epoch 117/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8606 - loss: 0.3123 - val_accuracy: 0.8016 - val_loss: 0.4821\n",
      "Epoch 118/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8600 - loss: 0.3159 - val_accuracy: 0.8119 - val_loss: 0.4507\n",
      "Epoch 119/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8558 - loss: 0.3205 - val_accuracy: 0.8098 - val_loss: 0.4718\n",
      "Epoch 120/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8529 - loss: 0.3271 - val_accuracy: 0.8037 - val_loss: 0.4497\n",
      "Epoch 121/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8731 - loss: 0.3057 - val_accuracy: 0.7975 - val_loss: 0.4664\n",
      "Epoch 122/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8637 - loss: 0.3339 - val_accuracy: 0.7996 - val_loss: 0.4554\n",
      "Epoch 123/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8521 - loss: 0.3109 - val_accuracy: 0.7935 - val_loss: 0.4647\n",
      "Epoch 124/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8492 - loss: 0.3341 - val_accuracy: 0.8057 - val_loss: 0.4492\n",
      "Epoch 125/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8733 - loss: 0.2935 - val_accuracy: 0.8139 - val_loss: 0.4598\n",
      "Epoch 126/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8723 - loss: 0.2910 - val_accuracy: 0.8160 - val_loss: 0.4616\n",
      "Epoch 127/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8747 - loss: 0.2987 - val_accuracy: 0.8078 - val_loss: 0.4643\n",
      "Epoch 128/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.3180 - val_accuracy: 0.8016 - val_loss: 0.4469\n",
      "Epoch 129/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.3014 - val_accuracy: 0.8057 - val_loss: 0.4586\n",
      "Epoch 130/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8538 - loss: 0.3235 - val_accuracy: 0.8057 - val_loss: 0.4646\n",
      "Epoch 131/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8544 - loss: 0.3297 - val_accuracy: 0.8016 - val_loss: 0.4631\n",
      "Epoch 132/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.2806 - val_accuracy: 0.8037 - val_loss: 0.4706\n",
      "Epoch 133/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8606 - loss: 0.3039 - val_accuracy: 0.8078 - val_loss: 0.4654\n",
      "Epoch 134/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8666 - loss: 0.2996 - val_accuracy: 0.8098 - val_loss: 0.4496\n",
      "Epoch 135/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.3004 - val_accuracy: 0.8200 - val_loss: 0.4525\n",
      "Epoch 136/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8861 - loss: 0.2824 - val_accuracy: 0.8057 - val_loss: 0.4488\n",
      "Epoch 137/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8594 - loss: 0.3203 - val_accuracy: 0.8098 - val_loss: 0.4593\n",
      "Epoch 138/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.2752 - val_accuracy: 0.8119 - val_loss: 0.4495\n",
      "Epoch 139/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8699 - loss: 0.2990 - val_accuracy: 0.8180 - val_loss: 0.4798\n",
      "Epoch 140/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8624 - loss: 0.3020 - val_accuracy: 0.8180 - val_loss: 0.4375\n",
      "Epoch 141/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8499 - loss: 0.3252 - val_accuracy: 0.8180 - val_loss: 0.4508\n",
      "Epoch 142/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8723 - loss: 0.2804 - val_accuracy: 0.8119 - val_loss: 0.4590\n",
      "Epoch 143/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8636 - loss: 0.2958 - val_accuracy: 0.8241 - val_loss: 0.4598\n",
      "Epoch 144/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.2839 - val_accuracy: 0.8221 - val_loss: 0.4286\n",
      "Epoch 145/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8809 - loss: 0.2955 - val_accuracy: 0.8221 - val_loss: 0.4326\n",
      "Epoch 146/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8704 - loss: 0.2888 - val_accuracy: 0.8282 - val_loss: 0.4515\n",
      "Epoch 147/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.2747 - val_accuracy: 0.8139 - val_loss: 0.4388\n",
      "Epoch 148/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.2932 - val_accuracy: 0.8180 - val_loss: 0.4578\n",
      "Epoch 149/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8499 - loss: 0.3307 - val_accuracy: 0.8160 - val_loss: 0.4582\n",
      "Epoch 150/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8782 - loss: 0.2736 - val_accuracy: 0.8221 - val_loss: 0.4624\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.8369 - loss: 0.4545\n",
      "Validation Loss: 0.46243396401405334, Validation Accuracy: 0.8220859169960022\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(X_train_padded)\n",
    "indices = np.arange(total_samples)\n",
    "np.random.shuffle(indices)\n",
    "train_size_20_random = int(total_samples* 0.2)\n",
    "X_train_20 = X_train_padded[:train_size_20_random]\n",
    "y_train_20 = y_train_categorical[:train_size_20_random]\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10, output_dim=12, input_length=47))  # Embedding layer with output_dim=12\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))  # Convolutional layer with 32 filters\n",
    "model.add(MaxPooling1D(pool_size=2))  # Max pooling layer\n",
    "model.add(Dropout(0.3))  # Dropout layer\n",
    "model.add(LSTM(24, return_sequences=False))  # LSTM layer with 24 units\n",
    "model.add(Dense(32, activation='relu'))  # Dense layer with 32 units\n",
    "model.add(Dense(2, activation='softmax'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_20, y_train_20, \n",
    "          validation_data=(X_valid_padded, y_valid_categorical), \n",
    "          epochs=150, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy20 = model.evaluate(X_valid_padded, y_valid_categorical)\n",
    "print(f'Validation Loss: {loss}, Validation Accuracy: {accuracy20}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mtpl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Percentages of data used\n",
    "percentages = [100, 80, 60, 40, 20]\n",
    "\n",
    "# Accuracies corresponding to the percentages \n",
    "\n",
    "accuracies = [accuracy,accuracy80,accuracy60,accuracy40,accuracy20]\n",
    "\n",
    "# Plotting the accuracies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(percentages, accuracies, marker='o')\n",
    "plt.title('Model Accuracy vs. Percentage of Data Used')\n",
    "plt.xlabel('Percentage of Data Used')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
