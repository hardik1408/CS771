{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hardik1408/CS771/blob/hardik/emoticon_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkxlTXck4JxY"
      },
      "source": [
        "## loading the files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x3jZxolZMRsN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Load the CSV files\n",
        "train_df = pd.read_csv('/Users/namangupta/Desktop/771/mini-project-1/datasets/train/train_emoticon.csv')\n",
        "validation_df = pd.read_csv('/Users/namangupta/Desktop/771/mini-project-1/datasets/valid/valid_emoticon.csv')\n",
        "\n",
        "# Assuming the CSV files have 'emojis' and 'label' columns\n",
        "train_texts = train_df['input_emoticon'].values\n",
        "train_labels = train_df['label'].values\n",
        "\n",
        "validation_texts = validation_df['input_emoticon'].values\n",
        "validation_labels = validation_df['label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Observing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_train = []\n",
        "for i in train_texts:\n",
        "    total_train += i\n",
        "\n",
        "emoji_freq = dict()\n",
        "for i in total_train:\n",
        "    if i in emoji_freq:\n",
        "        emoji_freq[i] += 1\n",
        "    else:\n",
        "        emoji_freq[i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ğŸ˜›', 'ğŸ›', 'ğŸ˜‘', 'ğŸ˜£', 'ğŸ™¯', 'ğŸš¼', 'ğŸ™¼']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emoji_0_1 = dict()\n",
        "\n",
        "for i in emoji_freq:\n",
        "    emoji_0_1[i] = (0,0)\n",
        "\n",
        "for i in emoji_freq:\n",
        "    for j in range(len(train_texts)):\n",
        "        if i in train_texts[j]:\n",
        "            if train_labels[j] == 1:\n",
        "                emoji_0_1[i] = (emoji_0_1[i][0], emoji_0_1[i][1]+1)\n",
        "            else:\n",
        "                emoji_0_1[i] = (emoji_0_1[i][0]+1, emoji_0_1[i][1])\n",
        "\n",
        "emoji_0_1\n",
        "\n",
        "mannnyyy = []\n",
        "for i in emoji_0_1:\n",
        "    if emoji_0_1[i] == (3576, 3504):\n",
        "        mannnyyy.append(i)\n",
        "\n",
        "mannnyyy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We find that in every row these 7 emoticons appear!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3576, 3505, 0)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ss0 = 0\n",
        "ss1 = 1\n",
        "snd = 0\n",
        "\n",
        "for i in range(len(train_texts)):\n",
        "    j = train_texts[i]\n",
        "    for em in mannnyyy:\n",
        "        if em in j:\n",
        "            pass\n",
        "        else:\n",
        "            snd += 1\n",
        "            break\n",
        "    else:\n",
        "        if train_labels[i] == 0:\n",
        "            ss0 += 1\n",
        "        else:\n",
        "            ss1 += 1\n",
        "    \n",
        "ss0, ss1, snd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({10}, {10})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l1 = []\n",
        "l0 = []\n",
        "\n",
        "for i in range(len(train_texts)):\n",
        "    s = []\n",
        "    for idx in range(len(train_texts[i])):\n",
        "        j = train_texts[i][idx]\n",
        "        if j in mannnyyy:\n",
        "            s.append((j, idx))\n",
        "\n",
        "    if train_labels[i] == 1:\n",
        "        l1.append(len(s))\n",
        "    else:\n",
        "        l0.append(len(s))\n",
        "\n",
        "set(l1), set(l0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also, these 7 emoticons make up exactly 10/13 of every given string (Be it train or validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_texts_mod = []\n",
        "\n",
        "for i in train_texts:\n",
        "    s = ''\n",
        "    for j in i:\n",
        "        if j not in mannnyyy:\n",
        "            s += j\n",
        "    train_texts_mod.append(s)\n",
        "\n",
        "train_texts_mod = np.array(train_texts_mod, dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_texts_mod = []\n",
        "\n",
        "for i in validation_texts:\n",
        "    s = ''\n",
        "    for j in i:\n",
        "        if j not in mannnyyy:\n",
        "            s += j\n",
        "    validation_texts_mod.append(s)\n",
        "\n",
        "validation_texts_mod = np.array(validation_texts_mod, dtype=object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use 'train_text_mod' and 'validation_text_mod' -> which are just a 3 length string for every element (rather than 13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us9r2ho04M5N"
      },
      "source": [
        "## preprocessing on input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KWUvSmeJjS6Q"
      },
      "outputs": [],
      "source": [
        "#  Tokenize and pad the emoji sequences\n",
        "tokenizer = Tokenizer(char_level=True)  # Tokenizing each emoji as a character\n",
        "tokenizer.fit_on_texts(train_texts)  # Fit only on training data\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts_mod)\n",
        "validation_sequences = tokenizer.texts_to_sequences(validation_texts_mod)\n",
        "\n",
        "# Pad the sequences to the same length\n",
        "max_len = max([len(seq) for seq in train_sequences])  # Maximum sequence length in train data\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "validation_padded = pad_sequences(validation_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Convert labels into numeric format if they are not (if necessary)\n",
        "train_labels = train_labels.astype(int)\n",
        "validation_labels = validation_labels.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbJTSlT44Qhh"
      },
      "source": [
        "## dividing data for the task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nhvob_QQkWzq"
      },
      "outputs": [],
      "source": [
        "x_train_100 = train_padded\n",
        "y_train_100 = train_labels\n",
        "# prompt: take only 80% of the training dataset\n",
        "\n",
        "train_size_80 = int(len(x_train_100) * 0.8)\n",
        "x_train_80 = x_train_100[:train_size_80]\n",
        "y_train_80 = y_train_100[:train_size_80]\n",
        "# prompt: take only 60% of training data\n",
        "\n",
        "# Shuffle the indices of the training data\n",
        "indices = np.arange(len(x_train_100))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calculate the number of samples for 60% of the data\n",
        "train_size_60_random = int(len(x_train_100) * 0.6)\n",
        "\n",
        "# Select the shuffled indices for the 60% split\n",
        "x_train_60 = x_train_100[indices[:train_size_60_random]]\n",
        "y_train_60 = y_train_100[indices[:train_size_60_random]]\n",
        "\n",
        "indices = np.arange(len(x_train_100))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calculate the number of samples for 60% of the data\n",
        "train_size_40_random = int(len(x_train_100) * 0.4)\n",
        "\n",
        "# Select the shuffled indices for the 60% split\n",
        "x_train_40 = x_train_100[indices[:train_size_40_random]]\n",
        "y_train_40 = y_train_100[indices[:train_size_40_random]]\n",
        "\n",
        "indices = np.arange(len(x_train_100))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calculate the number of samples for 60% of the data\n",
        "train_size_20_random = int(len(x_train_100) * 0.2)\n",
        "\n",
        "# Select the shuffled indices for the 60% split\n",
        "x_train_20 = x_train_100[indices[:train_size_20_random]]\n",
        "y_train_20 = y_train_100[indices[:train_size_20_random]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gleGdU3HkvXp"
      },
      "source": [
        "### model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "R36oQLIbkxWD",
        "outputId": "2cd49fca-73b8-4f20-e36b-dd3170442896"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opm-L1rY4cVG"
      },
      "source": [
        "### 100%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq1r6hsyjq8m",
        "outputId": "822860ab-78ab-4e3a-fddd-5f2e34bd7529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5500 - loss: 0.6783 - val_accuracy: 0.8589 - val_loss: 0.5611\n",
            "Epoch 2/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.3561 - val_accuracy: 0.9018 - val_loss: 0.2921\n",
            "Epoch 3/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.2822 - val_accuracy: 0.9305 - val_loss: 0.1893\n",
            "Epoch 4/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9023 - loss: 0.2323 - val_accuracy: 0.9427 - val_loss: 0.1392\n",
            "Epoch 5/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2214 - val_accuracy: 0.9489 - val_loss: 0.1499\n",
            "Epoch 6/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2022 - val_accuracy: 0.9468 - val_loss: 0.1314\n",
            "Epoch 7/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2047 - val_accuracy: 0.9325 - val_loss: 0.1659\n",
            "Epoch 8/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.1879 - val_accuracy: 0.9427 - val_loss: 0.1234\n",
            "Epoch 9/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9351 - loss: 0.1653 - val_accuracy: 0.9673 - val_loss: 0.0925\n",
            "Epoch 10/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.1890 - val_accuracy: 0.9509 - val_loss: 0.1254\n",
            "Epoch 11/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9382 - loss: 0.1585 - val_accuracy: 0.9591 - val_loss: 0.0966\n",
            "Epoch 12/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9318 - loss: 0.1620 - val_accuracy: 0.9550 - val_loss: 0.1019\n",
            "Epoch 13/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.1648 - val_accuracy: 0.9509 - val_loss: 0.1161\n",
            "Epoch 14/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9367 - loss: 0.1464 - val_accuracy: 0.9693 - val_loss: 0.0890\n",
            "Epoch 15/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9400 - loss: 0.1429 - val_accuracy: 0.9632 - val_loss: 0.0834\n",
            "Epoch 16/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.1383 - val_accuracy: 0.9632 - val_loss: 0.0941\n",
            "Epoch 17/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.1394 - val_accuracy: 0.9693 - val_loss: 0.0899\n",
            "Epoch 18/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1233 - val_accuracy: 0.9591 - val_loss: 0.0907\n",
            "Epoch 19/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1237 - val_accuracy: 0.9611 - val_loss: 0.0820\n",
            "Epoch 20/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.1466 - val_accuracy: 0.9673 - val_loss: 0.0812\n",
            "Epoch 21/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.1252 - val_accuracy: 0.9632 - val_loss: 0.0866\n",
            "Epoch 22/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9525 - loss: 0.1138 - val_accuracy: 0.9652 - val_loss: 0.0718\n",
            "Epoch 23/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.1207 - val_accuracy: 0.9816 - val_loss: 0.0693\n",
            "Epoch 24/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1059 - val_accuracy: 0.9591 - val_loss: 0.0852\n",
            "Epoch 25/25\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.0918 - val_accuracy: 0.9714 - val_loss: 0.0725\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.9677 - loss: 0.0724\n",
            "Validation Accuracy: 0.9714\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_100, y_train_100, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,720</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m)           â”‚         \u001b[38;5;34m1,720\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          â”‚         \u001b[38;5;34m1,088\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              â”‚           \u001b[38;5;34m264\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚             \u001b[38;5;34m9\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,173</span> (86.62 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,173\u001b[0m (86.62 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,369</span> (28.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,369\u001b[0m (28.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,740</span> (57.58 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m14,740\u001b[0m (57.58 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print the model summary for reference\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcvCDYi-4e_W"
      },
      "source": [
        "### 80%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5226 - loss: 0.6925 - val_accuracy: 0.4847 - val_loss: 0.6893\n",
            "Epoch 2/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7788 - loss: 0.5079 - val_accuracy: 0.8793 - val_loss: 0.4545\n",
            "Epoch 3/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8715 - loss: 0.3329 - val_accuracy: 0.9018 - val_loss: 0.2931\n",
            "Epoch 4/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8906 - loss: 0.2877 - val_accuracy: 0.8814 - val_loss: 0.2563\n",
            "Epoch 5/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8970 - loss: 0.2701 - val_accuracy: 0.9346 - val_loss: 0.1883\n",
            "Epoch 6/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.2652 - val_accuracy: 0.9264 - val_loss: 0.1754\n",
            "Epoch 7/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9023 - loss: 0.2490 - val_accuracy: 0.9080 - val_loss: 0.1860\n",
            "Epoch 8/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9045 - loss: 0.2450 - val_accuracy: 0.9223 - val_loss: 0.1565\n",
            "Epoch 9/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9143 - loss: 0.2268 - val_accuracy: 0.9427 - val_loss: 0.1466\n",
            "Epoch 10/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.2223 - val_accuracy: 0.9325 - val_loss: 0.1558\n",
            "Epoch 11/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2114 - val_accuracy: 0.9468 - val_loss: 0.1369\n",
            "Epoch 12/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9213 - loss: 0.2191 - val_accuracy: 0.9468 - val_loss: 0.1325\n",
            "Epoch 13/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9219 - loss: 0.2073 - val_accuracy: 0.9509 - val_loss: 0.1175\n",
            "Epoch 14/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.1944 - val_accuracy: 0.9284 - val_loss: 0.1423\n",
            "Epoch 15/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2165 - val_accuracy: 0.9530 - val_loss: 0.1159\n",
            "Epoch 16/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.1723 - val_accuracy: 0.9611 - val_loss: 0.1058\n",
            "Epoch 17/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9311 - loss: 0.1841 - val_accuracy: 0.9509 - val_loss: 0.1092\n",
            "Epoch 18/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9350 - loss: 0.1722 - val_accuracy: 0.9611 - val_loss: 0.1088\n",
            "Epoch 19/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.1589 - val_accuracy: 0.9550 - val_loss: 0.1060\n",
            "Epoch 20/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9408 - loss: 0.1614 - val_accuracy: 0.9509 - val_loss: 0.1022\n",
            "Epoch 21/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1522 - val_accuracy: 0.9611 - val_loss: 0.0844\n",
            "Epoch 22/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9579 - loss: 0.1228 - val_accuracy: 0.9468 - val_loss: 0.1066\n",
            "Epoch 23/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1571 - val_accuracy: 0.9571 - val_loss: 0.0875\n",
            "Epoch 24/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.1131 - val_accuracy: 0.9571 - val_loss: 0.0888\n",
            "Epoch 25/25\n",
            "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9609 - loss: 0.1198 - val_accuracy: 0.9611 - val_loss: 0.0997\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9554 - loss: 0.1058\n",
            "Validation Accuracy: 0.9611\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_80, y_train_80, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqguxm-p4gov"
      },
      "source": [
        "### 60%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5093 - loss: 0.6936 - val_accuracy: 0.5153 - val_loss: 0.6930\n",
            "Epoch 2/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5960 - loss: 0.6696 - val_accuracy: 0.8262 - val_loss: 0.6004\n",
            "Epoch 3/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8450 - loss: 0.3761 - val_accuracy: 0.8548 - val_loss: 0.4086\n",
            "Epoch 4/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8751 - loss: 0.2954 - val_accuracy: 0.9182 - val_loss: 0.2651\n",
            "Epoch 5/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.2543 - val_accuracy: 0.9162 - val_loss: 0.2100\n",
            "Epoch 6/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.2530 - val_accuracy: 0.9182 - val_loss: 0.1873\n",
            "Epoch 7/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9014 - loss: 0.2323 - val_accuracy: 0.9407 - val_loss: 0.1432\n",
            "Epoch 8/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2005 - val_accuracy: 0.9243 - val_loss: 0.1491\n",
            "Epoch 9/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.1916 - val_accuracy: 0.9489 - val_loss: 0.1375\n",
            "Epoch 10/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.1824 - val_accuracy: 0.9591 - val_loss: 0.1269\n",
            "Epoch 11/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.1857 - val_accuracy: 0.9611 - val_loss: 0.1242\n",
            "Epoch 12/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.1801 - val_accuracy: 0.9387 - val_loss: 0.1338\n",
            "Epoch 13/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9343 - loss: 0.1625 - val_accuracy: 0.9550 - val_loss: 0.1249\n",
            "Epoch 14/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.1820 - val_accuracy: 0.9427 - val_loss: 0.1183\n",
            "Epoch 15/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.1506 - val_accuracy: 0.9468 - val_loss: 0.1231\n",
            "Epoch 16/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9336 - loss: 0.1601 - val_accuracy: 0.9632 - val_loss: 0.1090\n",
            "Epoch 17/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9415 - loss: 0.1395 - val_accuracy: 0.9509 - val_loss: 0.1101\n",
            "Epoch 18/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9338 - loss: 0.1679 - val_accuracy: 0.9489 - val_loss: 0.1155\n",
            "Epoch 19/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1366 - val_accuracy: 0.9530 - val_loss: 0.1023\n",
            "Epoch 20/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9398 - loss: 0.1570 - val_accuracy: 0.9652 - val_loss: 0.0985\n",
            "Epoch 21/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9336 - loss: 0.1746 - val_accuracy: 0.9611 - val_loss: 0.1007\n",
            "Epoch 22/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.1523 - val_accuracy: 0.9591 - val_loss: 0.0994\n",
            "Epoch 23/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9335 - loss: 0.1633 - val_accuracy: 0.9530 - val_loss: 0.1035\n",
            "Epoch 24/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9340 - loss: 0.1527 - val_accuracy: 0.9652 - val_loss: 0.0988\n",
            "Epoch 25/25\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9335 - loss: 0.1517 - val_accuracy: 0.9611 - val_loss: 0.1007\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.9564 - loss: 0.1025\n",
            "Validation Accuracy: 0.9611\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_60, y_train_60, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf0pR68U4iPA"
      },
      "source": [
        "### 40%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4916 - loss: 0.6943 - val_accuracy: 0.5153 - val_loss: 0.6930\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5953 - loss: 0.6802 - val_accuracy: 0.6196 - val_loss: 0.6793\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7722 - loss: 0.5152 - val_accuracy: 0.8262 - val_loss: 0.5495\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8602 - loss: 0.3369 - val_accuracy: 0.8773 - val_loss: 0.4351\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8769 - loss: 0.2963 - val_accuracy: 0.8569 - val_loss: 0.3528\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 0.2659 - val_accuracy: 0.9039 - val_loss: 0.2531\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.2580 - val_accuracy: 0.9223 - val_loss: 0.2176\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8929 - loss: 0.2601 - val_accuracy: 0.9223 - val_loss: 0.1852\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2228 - val_accuracy: 0.9141 - val_loss: 0.1718\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.2135 - val_accuracy: 0.9325 - val_loss: 0.1507\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.1807 - val_accuracy: 0.9407 - val_loss: 0.1495\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.1896 - val_accuracy: 0.9468 - val_loss: 0.1461\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9339 - loss: 0.1745 - val_accuracy: 0.9489 - val_loss: 0.1289\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.1756 - val_accuracy: 0.9489 - val_loss: 0.1250\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.1534 - val_accuracy: 0.9489 - val_loss: 0.1173\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9318 - loss: 0.1659 - val_accuracy: 0.9468 - val_loss: 0.1150\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.1532 - val_accuracy: 0.9264 - val_loss: 0.1410\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.1614 - val_accuracy: 0.9407 - val_loss: 0.1452\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9372 - loss: 0.1564 - val_accuracy: 0.9468 - val_loss: 0.1174\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1382 - val_accuracy: 0.9407 - val_loss: 0.1180\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9377 - loss: 0.1400 - val_accuracy: 0.9530 - val_loss: 0.1173\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9435 - loss: 0.1382 - val_accuracy: 0.9550 - val_loss: 0.1201\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.1461 - val_accuracy: 0.9611 - val_loss: 0.1039\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.1407 - val_accuracy: 0.9530 - val_loss: 0.1111\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1338 - val_accuracy: 0.9591 - val_loss: 0.1119\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9655 - loss: 0.1020 \n",
            "Validation Accuracy: 0.9591\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_40, y_train_40, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhxS-SEE4jmq"
      },
      "source": [
        "### 20%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5453 - loss: 0.6898 - val_accuracy: 0.5153 - val_loss: 0.6927\n",
            "Epoch 2/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5424 - loss: 0.6875 - val_accuracy: 0.5542 - val_loss: 0.6928\n",
            "Epoch 3/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6195 - loss: 0.6696 - val_accuracy: 0.4888 - val_loss: 0.6932\n",
            "Epoch 4/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6720 - loss: 0.6198 - val_accuracy: 0.5481 - val_loss: 0.6860\n",
            "Epoch 5/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7541 - loss: 0.5328 - val_accuracy: 0.6953 - val_loss: 0.6441\n",
            "Epoch 6/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.3898 - val_accuracy: 0.8016 - val_loss: 0.5564\n",
            "Epoch 7/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8747 - loss: 0.3071 - val_accuracy: 0.8262 - val_loss: 0.4944\n",
            "Epoch 8/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.2614 - val_accuracy: 0.8425 - val_loss: 0.4378\n",
            "Epoch 9/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.2528 - val_accuracy: 0.8446 - val_loss: 0.3982\n",
            "Epoch 10/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.2595 - val_accuracy: 0.8528 - val_loss: 0.3681\n",
            "Epoch 11/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2364 - val_accuracy: 0.8384 - val_loss: 0.3619\n",
            "Epoch 12/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.1945 - val_accuracy: 0.8487 - val_loss: 0.3355\n",
            "Epoch 13/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2396 - val_accuracy: 0.8487 - val_loss: 0.3351\n",
            "Epoch 14/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9037 - loss: 0.2350 - val_accuracy: 0.8609 - val_loss: 0.3012\n",
            "Epoch 15/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9351 - loss: 0.1780 - val_accuracy: 0.8732 - val_loss: 0.2920\n",
            "Epoch 16/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.1889 - val_accuracy: 0.8753 - val_loss: 0.3119\n",
            "Epoch 17/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9393 - loss: 0.1682 - val_accuracy: 0.8691 - val_loss: 0.3183\n",
            "Epoch 18/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.1946 - val_accuracy: 0.8712 - val_loss: 0.3103\n",
            "Epoch 19/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.1836 - val_accuracy: 0.8793 - val_loss: 0.3000\n",
            "Epoch 20/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9242 - loss: 0.1872 - val_accuracy: 0.8630 - val_loss: 0.3367\n",
            "Epoch 21/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9303 - loss: 0.1812 - val_accuracy: 0.8691 - val_loss: 0.3557\n",
            "Epoch 22/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.2000 - val_accuracy: 0.8753 - val_loss: 0.3502\n",
            "Epoch 23/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.1530 - val_accuracy: 0.8834 - val_loss: 0.2956\n",
            "Epoch 24/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.1304 - val_accuracy: 0.8814 - val_loss: 0.3060\n",
            "Epoch 25/25\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1467 - val_accuracy: 0.8753 - val_loss: 0.3284\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.8760 - loss: 0.3410\n",
            "Validation Accuracy: 0.8753\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_20, y_train_20, epochs=25, batch_size=32, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "-dSUVFednPSD",
        "outputId": "04cc19e4-a9a7-426f-db58-3537c798b7c2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# prompt: create a plot which plots the accuracy vs the percentage of training data used\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the accuracy values for each training data percentage stored in a list\n",
        "training_data_percentages = [20, 40, 60, 80, 100]\n",
        "accuracies = [0.8753, 0.9591, 0.9611, 0.9652, 0.9714]  # Replace with your actual accuracy values\n",
        "\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(training_data_percentages, accuracies, marker='o')\n",
        "plt.xlabel('Percentage of Training Data Used')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Accuracy vs. Training Data Percentage')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c6SLKGoMju9",
        "outputId": "dd7994bf-97ce-4ebc-ded1-dc47a8973b46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))  # Embedding layer\n",
        "model.add(LSTM(16))  # LSTM layer with 16 units\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpjqkVnOMkKl",
        "outputId": "c75031e3-e74d-4fde-b319-c9977a1757d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5234 - loss: 0.6903 - val_accuracy: 0.8282 - val_loss: 0.5364\n",
            "Epoch 2/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.8592 - loss: 0.4093 - val_accuracy: 0.9530 - val_loss: 0.1810\n",
            "Epoch 3/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9562 - loss: 0.1606 - val_accuracy: 0.9468 - val_loss: 0.1258\n",
            "Epoch 4/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9688 - loss: 0.1094 - val_accuracy: 0.9611 - val_loss: 0.1005\n",
            "Epoch 5/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9711 - loss: 0.0924 - val_accuracy: 0.9632 - val_loss: 0.0873\n",
            "Epoch 6/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9771 - loss: 0.0724 - val_accuracy: 0.9734 - val_loss: 0.0764\n",
            "Epoch 7/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.9852 - loss: 0.0589 - val_accuracy: 0.9734 - val_loss: 0.0679\n",
            "Epoch 8/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.9876 - loss: 0.0493 - val_accuracy: 0.9714 - val_loss: 0.0617\n",
            "Epoch 9/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9873 - loss: 0.0461 - val_accuracy: 0.9775 - val_loss: 0.0556\n",
            "Epoch 10/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9913 - loss: 0.0394 - val_accuracy: 0.9857 - val_loss: 0.0502\n",
            "Epoch 11/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9892 - loss: 0.0388 - val_accuracy: 0.9877 - val_loss: 0.0481\n",
            "Epoch 12/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9881 - loss: 0.0362 - val_accuracy: 0.9898 - val_loss: 0.0429\n",
            "Epoch 13/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9928 - loss: 0.0303 - val_accuracy: 0.9877 - val_loss: 0.0395\n",
            "Epoch 14/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9929 - loss: 0.0281 - val_accuracy: 0.9796 - val_loss: 0.0458\n",
            "Epoch 15/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9944 - loss: 0.0250 - val_accuracy: 0.9836 - val_loss: 0.0431\n",
            "Epoch 16/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9949 - loss: 0.0250 - val_accuracy: 0.9898 - val_loss: 0.0353\n",
            "Epoch 17/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9955 - loss: 0.0210 - val_accuracy: 0.9775 - val_loss: 0.0391\n",
            "Epoch 18/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9955 - loss: 0.0201 - val_accuracy: 0.9877 - val_loss: 0.0413\n",
            "Epoch 19/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9945 - loss: 0.0190 - val_accuracy: 0.9796 - val_loss: 0.0424\n",
            "Epoch 20/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9962 - loss: 0.0176 - val_accuracy: 0.9898 - val_loss: 0.0322\n",
            "Epoch 21/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9981 - loss: 0.0140 - val_accuracy: 0.9857 - val_loss: 0.0408\n",
            "Epoch 22/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.9978 - loss: 0.0141 - val_accuracy: 0.9816 - val_loss: 0.0392\n",
            "Epoch 23/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9964 - loss: 0.0134 - val_accuracy: 0.9857 - val_loss: 0.0402\n",
            "Epoch 24/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9979 - loss: 0.0123 - val_accuracy: 0.9816 - val_loss: 0.0406\n",
            "Epoch 25/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9975 - loss: 0.0119 - val_accuracy: 0.9877 - val_loss: 0.0377\n",
            "Epoch 26/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9979 - loss: 0.0100 - val_accuracy: 0.9836 - val_loss: 0.0402\n",
            "Epoch 27/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9977 - loss: 0.0110 - val_accuracy: 0.9877 - val_loss: 0.0363\n",
            "Epoch 28/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9984 - loss: 0.0088 - val_accuracy: 0.9836 - val_loss: 0.0379\n",
            "Epoch 29/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9979 - loss: 0.0104 - val_accuracy: 0.9877 - val_loss: 0.0328\n",
            "Epoch 30/30\n",
            "\u001b[1m222/222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9998 - loss: 0.0063 - val_accuracy: 0.9918 - val_loss: 0.0338\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.9924 - loss: 0.0310\n",
            "Validation Accuracy: 0.9918200373649597\n"
          ]
        }
      ],
      "source": [
        "# Train the model using the training data and validate on the validation set\n",
        "model.fit(train_padded, train_labels, epochs=30, validation_data=(validation_padded, validation_labels))\n",
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "print(f'Validation Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,720</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m)           â”‚         \u001b[38;5;34m1,720\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚         \u001b[38;5;34m1,600\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_13 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m17\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,013</span> (39.12 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,013\u001b[0m (39.12 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,337</span> (13.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,337\u001b[0m (13.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,676</span> (26.08 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,676\u001b[0m (26.08 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n94odYqLNmjj",
        "outputId": "2a17f712-4ae2-4d93-b9e3-4804a47657b5"
      },
      "outputs": [],
      "source": [
        "%timeit\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "\n",
        "# Define the improved LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer: increases embedding dimension size for richer representation\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_len))\n",
        "\n",
        "# First LSTM layer: Bidirectional LSTM for capturing dependencies in both directions\n",
        "model.add(Bidirectional(LSTM(8, return_sequences=True)))  # Return sequences for stacking another LSTM layer\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "# Second LSTM layer: another Bidirectional LSTM layer for deeper sequential learning\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.2))  # Another dropout layer\n",
        "\n",
        "# Batch Normalization: helps with stabilizing and accelerating training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dense Layer: fully connected layer\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout for regularization\n",
        "\n",
        "# Output Layer: Sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate adjustment\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5361 - loss: 0.6747 - val_accuracy: 0.8589 - val_loss: 0.4083\n",
            "Epoch 2/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8530 - loss: 0.3557 - val_accuracy: 0.9039 - val_loss: 0.2126\n",
            "Epoch 3/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8818 - loss: 0.2893 - val_accuracy: 0.9284 - val_loss: 0.1528\n",
            "Epoch 4/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.2604 - val_accuracy: 0.9448 - val_loss: 0.1494\n",
            "Epoch 5/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8976 - loss: 0.2548 - val_accuracy: 0.9346 - val_loss: 0.1449\n",
            "Epoch 6/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2525 - val_accuracy: 0.9407 - val_loss: 0.1391\n",
            "Epoch 7/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9014 - loss: 0.2307 - val_accuracy: 0.9468 - val_loss: 0.1520\n",
            "Epoch 8/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2193 - val_accuracy: 0.9509 - val_loss: 0.1266\n",
            "Epoch 9/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2141 - val_accuracy: 0.9427 - val_loss: 0.1307\n",
            "Epoch 10/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.1814 - val_accuracy: 0.9509 - val_loss: 0.1166\n",
            "Epoch 11/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9363 - loss: 0.1590 - val_accuracy: 0.9571 - val_loss: 0.0992\n",
            "Epoch 12/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9354 - loss: 0.1579 - val_accuracy: 0.9571 - val_loss: 0.0927\n",
            "Epoch 13/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9411 - loss: 0.1541 - val_accuracy: 0.9530 - val_loss: 0.1215\n",
            "Epoch 14/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.1370 - val_accuracy: 0.9652 - val_loss: 0.0870\n",
            "Epoch 15/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9506 - loss: 0.1269 - val_accuracy: 0.9509 - val_loss: 0.0985\n",
            "Epoch 16/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9532 - loss: 0.1307 - val_accuracy: 0.9673 - val_loss: 0.0867\n",
            "Epoch 17/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9593 - loss: 0.1070 - val_accuracy: 0.9652 - val_loss: 0.0774\n",
            "Epoch 18/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9621 - loss: 0.0981 - val_accuracy: 0.9509 - val_loss: 0.0910\n",
            "Epoch 19/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9594 - loss: 0.1074 - val_accuracy: 0.9775 - val_loss: 0.0671\n",
            "Epoch 20/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9621 - loss: 0.0963 - val_accuracy: 0.9591 - val_loss: 0.0791\n",
            "Epoch 21/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9636 - loss: 0.0929 - val_accuracy: 0.9611 - val_loss: 0.0792\n",
            "Epoch 22/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.0774 - val_accuracy: 0.9673 - val_loss: 0.0618\n",
            "Epoch 23/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.0869 - val_accuracy: 0.9755 - val_loss: 0.0756\n",
            "Epoch 24/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0810 - val_accuracy: 0.9775 - val_loss: 0.0643\n",
            "Epoch 25/25\n",
            "\u001b[1m443/443\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.0719 - val_accuracy: 0.9734 - val_loss: 0.0671\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x318bdc090>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Train the model using the train set and validate on the validation set\n",
        "model.fit(train_padded, train_labels, epochs=25, batch_size=16, validation_data=(validation_padded, validation_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,720</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_20                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_21                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_10          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_12 (\u001b[38;5;33mEmbedding\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m)           â”‚         \u001b[38;5;34m1,720\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_20                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          â”‚         \u001b[38;5;34m1,088\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBidirectional\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_21                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBidirectional\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_10          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_22 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              â”‚           \u001b[38;5;34m264\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_23 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚             \u001b[38;5;34m9\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,173</span> (86.62 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,173\u001b[0m (86.62 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,369</span> (28.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,369\u001b[0m (28.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,740</span> (57.58 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m14,740\u001b[0m (57.58 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfxGjdppPGSF",
        "outputId": "b11276c0-e90d-489d-9b55-4573d8fe49d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9689 - loss: 0.0762\n",
            "Validation Accuracy: 0.9734\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(validation_padded, validation_labels)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
